# =============================================================================
# Document Generation from Outline (Parallel Validation Edition)
# =============================================================================
#
# A multi-stage recipe for generating documentation from a structured outline.
# Implements BFS (breadth-first) traversal and PARALLEL validation phases.
#
# Design Principles:
#   - BASH for: File ops, JSON read/write via jq, simple checks
#   - AGENT for: Parsing, understanding, reasoning, content generation
#   - jq for JSON: Clean, readable JSON manipulation in bash steps
#   - Parallel checks: Independent validations run concurrently
#   - Combined fixes: Single fix step addresses all issues holistically
#   - FILE-BASED DATA: Complex JSON passed via files, not template variables
#   - AGENT-WRITES-FILE: Agents write document content directly to files
#   - ROBUST FALLBACKS: Three-way logic handles agent failures gracefully
#
# Validation Groupings:
#   Group 1 (Sequential - must be first):
#     - structural: ensures sections exist before content checks
#   
#   Group 2 (Parallel - content validation):
#     - accuracy: claims traceable to sources
#     - completeness: prompts fully addressed
#     - instructions: format/template followed
#   
#   Group 3 (Parallel - quality validation):
#     - depth: level-appropriate detail
#     - coherence: flow, transitions, duplication
#     - crossrefs: internal references valid
#     - consistency: terminology, style uniform
#     - tone: audience/purpose fit
#
# Version Flow:
#   v0 → [structural] → v1 → [content checks parallel] → v2 → 
#        [quality checks parallel] → v3 → final
#
# Usage:
#   amplifier run "execute document-generation-parallel.yaml with outline_path=./outline.json"
#
#   With existing document (for updates/revisions):
#   amplifier run "execute document-generation-parallel.yaml with outline_path=./outline.json existing_document_path=./current-doc.md"
#
# Requirements:
#   - foundation bundle (provides zen-architect, explorer agents)
#   - Python 3 installed
#   - Write access to working directory
#
# =============================================================================

# =============================================================================
# CHANGELOG
# =============================================================================
#
# v8.1.0 (2026-01-30):
#   - NEW FEATURE: Design Intelligence Feedback (EXPERIMENTAL)
#     * Adds observational feedback from DI agents at TWO stages:
#       - After v0 generation (before validation) 
#       - After v3 quality (final document)
#     * voice-strategist reviews document for voice/tone/clarity
#     * layout-architect reviews document structure and information architecture
#     * layout-architect also reviews the original outline quality (final only)
#     * All feedback is purely observational - NO changes made to document
#     * Feedback included in final generation report for evaluation
#     * v0 vs v3 comparison shows validation effectiveness
#     * Purpose: Understand if DI perspective adds value to document review
#   - New steps after generation (v0 feedback):
#     * di-v0-voice-feedback: Voice & tone analysis of initial generation
#     * di-v0-structure-feedback: IA analysis of initial generation
#     * save-di-v0-feedback: Saves to di_v0_feedback.json
#   - New steps in finalization stage (v3/final feedback):
#     * di-voice-feedback: Voice & tone analysis of final document
#     * di-structure-feedback: Information architecture analysis
#     * di-outline-feedback: Outline quality analysis
#     * save-di-feedback: Combines all feedback into di_feedback.json
#   - Updated generate-summary-report to include:
#     * v0 DI feedback section
#     * v3 DI feedback section
#     * v0 → v3 comparison section
#   - New output files:
#     * state/di_v0_feedback.json (initial generation feedback)
#     * state/di_feedback.json (final document feedback)
#   - Technical: JSON save steps use temp files + jq --slurpfile to avoid
#     bash quoting issues with complex JSON containing parentheses/quotes
#
# v8.0.0 (2026-01-28):
#   - MERGED RELEASE: Combined features from multiple development branches
#   - From v7.5.x (existing doc support):
#     * CODE BLOCK AWARE PARSING in section extraction
#     * DETERMINISTIC SECTION RESTORE after validation fixes
#     * COMPREHENSIVE ANALYSIS including content AND quality checks
#     * DETERMINISTIC PRESERVATION of unchanged sections
#     * EXISTING DOCUMENT INPUT support (existing_document_path)
#   - From v7.2.x (provider preferences):
#     * PROVIDER PREFERENCES with fallback chains on all agent steps
#     * MODEL SELECTION: Haiku for parsing, Sonnet for analysis, Opus for generation
#     * COST REDUCTION: ~20-30% vs all-Sonnet baseline
#   - From v7.1.x (parallel metrics):
#     * PARALLEL TIMING METRICS tracking in validation phases
#     * Efficiency reporting (wall_clock_time, parallelism_efficiency)
#
# v7.5.0 (2026-01-27):
#   - CODE BLOCK AWARE PARSING: Fixed bug where # comments inside code blocks
#     were misinterpreted as markdown headings, causing content truncation
#     * parse_markdown_sections now tracks in_code_block state
#     * find_section_boundaries also handles code blocks correctly
#   - Ensures 100% of original section content is captured during extraction
#
# v7.4.0 (2026-01-27):
#   - DETERMINISTIC SECTION RESTORE: LLM can't be trusted to skip preserved sections
#     * restore-preserved-after-content-fix: Python restores sections after content fix
#     * restore-preserved-after-quality-fix: Python restores sections after quality fix
#     * Uses heading matching to find and replace sections with original content
#   - Ensures 100% preservation of unchanged sections regardless of LLM behavior
#
# v7.3.0 (2026-01-27):
#   - COMPREHENSIVE ANALYSIS: Analysis now includes content AND quality checks
#     * Source alignment (gaps, stale content)
#     * Content quality (accuracy, completeness, instructions)
#     * Quality aspects (depth, coherence, consistency, tone)
#   - VALIDATION SKIP FOR PRESERVED: Sections marked "none" skip validation entirely
#     * preserved_sections.json tracks which sections to skip
#     * fix-content-issues and fix-quality-issues skip preserved sections
#     * Only LLM-generated sections go through validation fixes
#   - Analysis is now the single source of truth for what needs work
#
# v7.2.0 (2026-01-27):
#   - DETERMINISTIC PRESERVATION: Sections with action_needed="none" are now
#     copied directly via bash - NO LLM involvement
#     * copy-preserved-sections: Bash step copies existing content to tracker
#     * get-sections-for-llm: Filters BFS order to only sections needing changes
#     * generate-section foreach now only processes sections needing LLM work
#   - Source-driven analysis: Only flag changes when sources indicate them
#     * action_needed: "none" | "add" | "remove" | "update"
#     * Identifies source_gaps (content to add) and stale_content (to remove)
#   - Significantly faster when updating existing docs with few changes
#
# v7.1.0 (2026-01-27):
#   - NEW FEATURE: Existing Document Input
#     * Optional existing_document_path parameter
#     * Analyzes existing document structure and maps to outline sections
#     * Extracts per-section content with quality assessment (keep/revise/replace)
#     * Generation steps use existing content as starting point when available
#     * Preserves good content, revises outdated content, replaces poor content
#     * Significantly faster for document updates/revisions
#   - New initialization steps:
#     * check-existing-document: Detects if existing doc provided
#     * copy-existing-document: Copies to working directory
#     * analyze-existing-document: Maps content to outline sections
#     * set-existing-doc-flag: Sets flag for downstream steps
#   - Updated generate-section prompt to leverage existing content
#
# v7.2.0-providers (2026-01-27):
#   - PROVIDER PREFERENCES: Uses new provider_preferences list with fallback chains
#     * Each step specifies ordered provider/model preferences
#     * System tries each provider in order until one is available
#     * Enables resilience across different provider configurations
#   - FALLBACK STRATEGY:
#     * Haiku steps: anthropic haiku → openai gpt-4o-mini
#     * Sonnet steps: anthropic sonnet → openai gpt-4o → azure gpt-4o
#     * Opus steps: anthropic opus → openai gpt-4o → azure gpt-4o
#   - BACKWARD COMPATIBLE: Works with older foundation versions (uses first preference)
#
# v7.1.0-models (2026-01-27):
#   - MODEL SELECTION: Per-step provider/model optimization for cost/speed
#     * Haiku (4 steps): parse-outline-structure, extract-source-paths, 
#       check-structural-issues, generate-summary-report
#     * Sonnet (6 steps): compute-section-relationships, assemble-document,
#       fix-structural-issues, run-content-checks, run-quality-checks, 
#       final-quality-check
#     * Opus (3 steps): generate-section, fix-content-issues, fix-quality-issues
#   - COST REDUCTION: ~20-30% vs all-Sonnet baseline
#   - SPEED IMPROVEMENT: ~15-25% (Haiku steps complete faster)
#
# v7.0.0 (2026-01-27):
#   - REDESIGN: Parallel validation phases
#     * Validation checks grouped by dependencies
#     * Group 2 (content): accuracy, completeness, instructions run in parallel
#     * Group 3 (quality): depth, coherence, crossrefs, consistency, tone run in parallel
#     * Combined fix steps address all issues from parallel checks at once
#   - VERSION SIMPLIFICATION: v0, v1, v2, v3, final (was v0-v9, final)
#   - FEWER STAGES: 6 stages with approval gates (was 12)
#   - PERFORMANCE: ~30-40% faster due to parallel execution
#   - Based on v6.1.1 sequential version
#
#
# v6.1.1 (2026-01-21):
#   - BUGFIX: Tracker state persistence in save-vN steps
#     * ROOT CAUSE: Template variables like {{structural_issues.passed}} resolve
#       to Python booleans (True/False with capital letters), but jq's --argjson
#       flag expects JSON booleans (true/false lowercase)
#     * SYMPTOM: Tracker only recorded v0 and v_final; validation_results empty
#     * FIX: Added explicit boolean conversion in all 9 save steps
#     * All version_history entries and validation_results now persist correctly
#
# v6.1.0 (2026-01-21):
#   - REFACTOR: Replaced all Python inline JSON manipulation with jq
#     * 20+ Python blocks converted to clean jq expressions
#     * More readable, follows recipe-author best practices
#     * Consistent pattern: jq '...' file.json > file.json.tmp && mv ...
#   - Design principle updated: "jq for JSON" replaces "No jq"
#
# v6.0.2 (2026-01-21):
#   - IMPROVEMENT: Default output path changed to temp/<filename>
#     * Enables easy side-by-side comparison between original and generated docs
#   - User can still specify explicit output_path to write directly to target location
#
# v6.0.0 (2026-01-20):
#   - MERGED: Combined best practices from v4.1.0 and v5.0.0 branches
#   - Agent-writes-file pattern: All document content written directly by agents
#   - Three-way fallback logic: Handles unreliable agent file writing gracefully
#   - File-based reads: Agents read documents from file paths, not template vars
#   - Verification steps: Check agent actually wrote expected files
#   - File copy for final save: No heredoc template variable issues
#   - Consistent JSON schema: All validation outputs include issue_count field
#   - Improvements from outline-generation recipe patterns (v6.0.1):
#     * JSON helper utility with clean_json_control_chars() and safe_parse_json()
#     * Retry logic with exponential backoff on critical agent steps
#     * File size validation to detect truncated files
#     * printf '%s' replaced echo for template variable outputs
#
# v5.0.0 (2026-01-16) [Branch B]:
#   - CRITICAL FIX: File-based data passing for all complex JSON objects
#   - CRITICAL FIX: Newline handling in bash outputs (printf instead of echo)
#   - CRITICAL FIX: Source path resolution relative to repo root
#   - IMPROVEMENT: Robust three-way fallbacks for validation stages
#
# v4.1.0 (2026-01-16) [Branch A]:
#   - BUGFIX: Undefined variable errors when validation stages pass
#   - BUGFIX: Bash syntax errors when fixed content contains special characters
#   - BUGFIX: Python syntax errors due to trailing newlines
#
# v4.0.0 (2026-01-15):
#   - Initial multi-stage implementation with BFS traversal
#   - 12 stages: initialization, generation, 8 validation stages, finalization
#   - Approval gates between stages for human-in-loop control
#   - Per-section state tracking with checkpoints
#   - Version saves after each validation stage (v0-v9)
#
# v3.0.0 (2026-01-15):
#   - Complete rewrite based on conversation-driven design
#   - Implemented BFS traversal for section generation
#   - Added 9-stage validation pipeline
#
# v2.0.0 (2026-01-15):
#   - Added context relationships for section generation
#   - Implemented per-section state tracking
#   - Added metadata extraction (definitions, examples introduced)
#
# v1.0.0 (2026-01-14):
#   - Initial recipe structure from conversation design
#
#
# =============================================================================

name: "document-generation"
description: "Generate documentation from an outline with BFS traversal, parallel validation, provider preferences, and Design Intelligence feedback"
version: "8.1.0"
author: "Amplifier Recipes Collection"
tags: ["documentation", "generation", "outline", "bfs", "validation", "staged", "resumable", "parallel"]

context:
  # Required: Path to the outline JSON file
  outline_path: ""
  
  # Optional: Output path for the generated document
  output_path: ""
  
  # Optional: Working directory for state and versions
  working_dir: "./.docgen"
  
  # Optional: Skip approval gates (for automated runs)
  auto_approve: false
  
  # Optional: Path to an existing document to use as reference
  # When provided, the recipe will:
  #   - Analyze the existing document structure
  #   - Extract content mapped to outline sections
  #   - Use existing content as starting point for generation
  #   - Preserve good content while addressing gaps
  existing_document_path: ""

# Rate limiting for LLM calls - controls parallel execution
rate_limiting:
  max_concurrent_llm: 3
  min_delay_ms: 500
  backoff:
    enabled: true
    initial_delay_ms: 2000
    max_delay_ms: 60000

# Recursion limits for safety
recursion:
  max_depth: 5
  max_total_steps: 1000

stages:
  # ==========================================================================
  # STAGE 1: INITIALIZATION
  # Setup workspace, check resume state, read outline, fetch sources,
  # compute structure, initialize tracker
  # ==========================================================================
  - name: "initialization"
    steps:
      # ---- WORKSPACE SETUP ----
      
      - id: "create-directories"
        type: "bash"
        command: |
          set -euo pipefail
          mkdir -p "{{working_dir}}/versions"
          mkdir -p "{{working_dir}}/sources"
          mkdir -p "{{working_dir}}/state"
          mkdir -p "{{working_dir}}/sections"
          echo "Directories created at {{working_dir}}"
        output: "dirs_created"

      # ---- JSON HELPER SETUP ----
      
      - id: "setup-json-helper"
        type: "bash"
        command: |
          set -euo pipefail
          
          cat > "{{working_dir}}/state/json_helper.py" << 'HELPER_EOF'
          import json
          import re
          import sys

          def clean_json_control_chars(json_str):
              """Clean control characters inside JSON string values."""
              if not json_str:
                  return json_str
              
              result = []
              in_string = False
              i = 0
              n = len(json_str)
              
              while i < n:
                  c = json_str[i]
                  
                  if in_string:
                      if c == '\\' and i + 1 < n:
                          result.append(c)
                          result.append(json_str[i + 1])
                          i += 2
                          continue
                      elif c == '"':
                          j = i + 1
                          while j < n and json_str[j] in ' \t\n\r':
                              j += 1
                          next_char = json_str[j] if j < n else ''
                          
                          if next_char in ':,}]' or next_char == '':
                              in_string = False
                              result.append(c)
                          else:
                              result.append('\\"')
                      elif c == '\n':
                          result.append('\\n')
                      elif c == '\r':
                          result.append('\\r')
                      elif c == '\t':
                          result.append('\\t')
                      elif ord(c) < 32:
                          result.append(f'\\u{ord(c):04x}')
                      else:
                          result.append(c)
                  else:
                      if c == '"':
                          in_string = True
                      result.append(c)
                  
                  i += 1
              
              return ''.join(result)

          def safe_parse_json(json_str, name="input"):
              """Parse JSON with error recovery for common LLM issues."""
              if not json_str or json_str.strip() == '':
                  raise ValueError(f"{name} is empty")
              
              if isinstance(json_str, dict):
                  return json_str
              
              cleaned = clean_json_control_chars(json_str)
              try:
                  return json.loads(cleaned)
              except json.JSONDecodeError:
                  pass
              
              code_match = re.search(r'```(?:json)?\s*\n(.*?)\n```', json_str, re.DOTALL)
              if code_match:
                  try:
                      return json.loads(clean_json_control_chars(code_match.group(1).strip()))
                  except json.JSONDecodeError:
                      pass
              
              first_brace = json_str.find('{')
              if first_brace >= 0:
                  potential = json_str[first_brace:]
                  depth = 0
                  in_str = False
                  escape_next = False
                  for i, c in enumerate(potential):
                      if escape_next:
                          escape_next = False
                          continue
                      if c == '\\':
                          escape_next = True
                          continue
                      if c == '"' and not escape_next:
                          in_str = not in_str
                      if not in_str:
                          if c == '{': depth += 1
                          elif c == '}': depth -= 1
                          if depth == 0:
                              try:
                                  return json.loads(clean_json_control_chars(potential[:i+1]))
                              except json.JSONDecodeError:
                                  break
              
              raise ValueError(f"Could not parse {name} as JSON. Preview: {json_str[:200]}")
          HELPER_EOF
          
          echo "JSON helper installed at {{working_dir}}/state/json_helper.py"
        output: "json_helper_ready"

      - id: "record-start-time"
        type: "bash"
        command: |
          set -euo pipefail
          date -Iseconds > "{{working_dir}}/state/started_at"
          printf '%s' "$(cat "{{working_dir}}/state/started_at")"
        output: "start_time"

      # ---- RESUME STATE CHECK ----
      
      - id: "check-tracker-exists"
        type: "bash"
        command: |
          set -euo pipefail
          tracker_file="{{working_dir}}/state/tracker.json"
          if [ -f "$tracker_file" ]; then
            printf '%s' "true"
          else
            printf '%s' "false"
          fi
        output: "tracker_exists"

      - id: "read-resume-info"
        type: "bash"
        command: |
          set -euo pipefail
          
          if [ "{{tracker_exists}}" = "true" ]; then
            jq '{
              resuming: true,
              status: (.status // "unknown"),
              current_stage: (.current_stage // "unknown"),
              sections_completed: (.sections_completed // [] | length),
              sections_pending: (.sections_pending // [] | length),
              last_completed_section: (if (.sections_completed // [] | length) > 0 then .sections_completed[-1] else "none" end),
              tracker_exists: true
            }' "{{working_dir}}/state/tracker.json"
          else
            echo '{"resuming": false, "status": "new", "current_stage": "initialization", "sections_completed": 0, "sections_pending": 0, "last_completed_section": "none", "tracker_exists": false}'
          fi
        output: "resume_state"
        parse_json: true

      # ---- READ AND VALIDATE OUTLINE ----
      
      - id: "check-outline-exists"
        type: "bash"
        command: |
          set -euo pipefail
          if [ -f "{{outline_path}}" ]; then
            echo "true"
          else
            echo "ERROR: Outline file not found at {{outline_path}}" >&2
            exit 1
          fi
        output: "outline_exists"

      - id: "read-outline-raw"
        type: "bash"
        command: |
          set -euo pipefail
          cp "{{outline_path}}" "{{working_dir}}/state/outline.json"
          echo "Outline saved to {{working_dir}}/state/outline.json"
        output: "outline_saved"

      - id: "parse-outline-structure"
        agent: "foundation:explorer"
        provider_preferences:
          - provider: anthropic
            model: claude-haiku-*
          - provider: openai
            model: gpt-4o-mini
        prompt: |
          Parse the outline JSON file and extract its structure.
          
          Read the outline from: {{working_dir}}/state/outline.json
          
          Return a JSON object with:
          1. **meta**: All metadata fields (purpose, audience, style, etc.)
          2. **document**: Document-level info (title, output path, etc.)
          3. **sections**: The full section tree structure
          4. **section_count**: Total number of sections (including nested)
          5. **max_depth**: Maximum nesting depth found
          
          Validate that:
          - Required fields are present (meta, document, sections)
          - Each section has at least: heading, prompt
          
          IMPORTANT: Save your parsed result to: {{working_dir}}/state/parsed_outline.json
          
          After saving, return a brief confirmation message with the section_count and max_depth.
        output: "outline_parsed_status"
        timeout: 120
        retry:
          max_attempts: 3
          backoff: "exponential"
          initial_delay: 2

      # ---- EXTRACT AND RESOLVE SOURCE PATHS ----
      
      - id: "get-outline-directory"
        type: "bash"
        command: |
          set -euo pipefail
          outline_full_path="$(realpath "{{outline_path}}")"
          outline_dir="$(dirname "$outline_full_path")"
          repo_root="$(dirname "$outline_dir")"
          printf '%s' "$repo_root"
        output: "outline_dir"

      - id: "extract-source-paths"
        agent: "foundation:explorer"
        provider_preferences:
          - provider: anthropic
            model: claude-haiku-*
          - provider: openai
            model: gpt-4o-mini
        prompt: |
          Extract ALL unique source file references from the parsed outline.
          
          Read the parsed outline from: {{working_dir}}/state/parsed_outline.json
          
          Sources in the outline are relative file paths (e.g., "docs/LOCAL_DEVELOPMENT.md").
          
          For each source found, extract:
          - file_path: The relative path as specified in the outline
          - sections: List of section IDs that reference this source
          
          Create a JSON manifest with this structure:
          {
            "sources": [
              {
                "file_path": "docs/LOCAL_DEVELOPMENT.md",
                "sections": ["1", "1.1", "2.3"]
              }
            ],
            "total_sources": number,
            "sections_with_sources": number,
            "sections_without_sources": number
          }
          
          IMPORTANT: Save this manifest to: {{working_dir}}/state/source_manifest.json
          
          After saving, return a confirmation with the total_sources count.
        output: "source_manifest_status"
        timeout: 120
        retry:
          max_attempts: 3
          backoff: "exponential"
          initial_delay: 2

      # ---- FETCH LOCAL SOURCES ----
      
      - id: "fetch-local-sources"
        type: "bash"
        command: |
          set -euo pipefail
          
          outline_dir="{{outline_dir}}"
          sources_dir="{{working_dir}}/sources"
          manifest_file="{{working_dir}}/state/source_manifest.json"
          result_file="{{working_dir}}/state/sources_result.json"
          
          fetched_json="[]"
          failed_json="[]"
          
          while IFS= read -r file_path; do
            [ -z "$file_path" ] && continue
            
            abs_path="$outline_dir/$file_path"
            safe_name=$(echo "$file_path" | tr '/' '_' | tr '\\' '_')
            dest_path="$sources_dir/$safe_name"
            
            if [ -f "$abs_path" ]; then
              cp -p "$abs_path" "$dest_path" 2>/dev/null && {
                size_bytes=$(wc -c < "$dest_path")
                line_count=$(wc -l < "$dest_path")
                fetched_json=$(echo "$fetched_json" | jq --arg src "$file_path" \
                  --arg lp "$dest_path" --argjson sz "$size_bytes" --argjson lc "$line_count" \
                  '. + [{"source": $src, "local_path": $lp, "size_bytes": $sz, "line_count": $lc}]')
              } || {
                failed_json=$(echo "$failed_json" | jq --arg src "$file_path" \
                  --arg err "Copy failed: $abs_path" \
                  '. + [{"source": $src, "error": $err}]')
              }
            else
              failed_json=$(echo "$failed_json" | jq --arg src "$file_path" \
                --arg err "File not found: $abs_path" \
                '. + [{"source": $src, "error": $err}]')
            fi
          done < <(jq -r '.sources[]?.file_path // empty' "$manifest_file")
          
          total_fetched=$(echo "$fetched_json" | jq 'length')
          total_failed=$(echo "$failed_json" | jq 'length')
          
          jq -n --argjson fetched "$fetched_json" --argjson failed "$failed_json" \
            --argjson tf "$total_fetched" --argjson tfl "$total_failed" '{
              fetched: $fetched,
              failed: $failed,
              success: ($tfl == 0),
              total_fetched: $tf,
              total_failed: $tfl
            }' > "$result_file"
          
          cat "$result_file"
        output: "sources_result"
        parse_json: true

      - id: "verify-all-sources-fetched"
        type: "bash"
        command: |
          set -euo pipefail
          
          fetched_count=$(ls -1 "{{working_dir}}/sources/" 2>/dev/null | wc -l)
          
          if [ "$fetched_count" -eq 0 ]; then
              echo "ERROR: No source files were fetched" >&2
              exit 1
          fi
          
          echo "Successfully fetched $fetched_count source files"
          ls -la "{{working_dir}}/sources/"
        output: "sources_verified"

      # ---- COMPUTE STRUCTURAL CONTEXT ----
      
      - id: "compute-section-relationships"
        agent: "foundation:zen-architect"
        mode: "ANALYZE"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          Analyze the outline structure and compute traversal context for ALL sections.
          
          Read the parsed outline from: {{working_dir}}/state/parsed_outline.json
          Read the source manifest from: {{working_dir}}/state/source_manifest.json
          
          For EACH section (including nested), compute:
          
          1. **id**: Unique identifier (e.g., "1", "1.1", "1.1.1")
          2. **heading**: The section heading
          3. **depth**: Nesting level (1 for top-level, 2 for children, etc.)
          4. **parent_id**: ID of parent section (null for top-level)
          5. **ancestor_ids**: FULL ancestor chain from root
          6. **children_ids**: Direct child section IDs
          7. **sibling_ids**: Sibling section IDs
          8. **prompt**: The section's generation instruction
          9. **source_files**: List of source file paths for this section
          
          Also compute:
          - **bfs_order**: Section IDs in BFS traversal order
          - **levels**: Sections grouped by depth level
          - **full_outline**: Text representation of ALL headings showing structure
          - **source_sharing**: Map of which sources are shared between sections
          - **max_depth**: Maximum nesting depth
          - **document_purpose**: Extracted from meta
          
          IMPORTANT: Save this structure to: {{working_dir}}/state/structure.json
          
          After saving, return a confirmation with bfs_order length and max_depth.
        output: "structure_status"
        timeout: 300
        retry:
          max_attempts: 3
          backoff: "exponential"
          initial_delay: 2

      # ---- EXISTING DOCUMENT HANDLING ----
      
      - id: "check-existing-document"
        type: "bash"
        command: |
          set -euo pipefail
          
          existing_path="{{existing_document_path}}"
          
          if [ -z "$existing_path" ]; then
            echo '{"provided": false, "exists": false, "path": ""}'
          elif [ -f "$existing_path" ]; then
            echo '{"provided": true, "exists": true, "path": "'"$existing_path"'"}'
          else
            echo '{"provided": true, "exists": false, "path": "'"$existing_path"'"}'
            echo "WARNING: Existing document path provided but file not found: $existing_path" >&2
          fi
        output: "existing_doc_status"
        parse_json: true

      - id: "copy-existing-document"
        condition: "{{existing_doc_status.exists}} == true"
        type: "bash"
        command: |
          set -euo pipefail
          
          cp "{{existing_doc_status.path}}" "{{working_dir}}/state/existing_document.md"
          
          bytes=$(wc -c < "{{working_dir}}/state/existing_document.md")
          lines=$(wc -l < "{{working_dir}}/state/existing_document.md")
          
          echo "Existing document copied: $bytes bytes, $lines lines"
        output: "existing_doc_copied"

      - id: "analyze-existing-document"
        condition: "{{existing_doc_status.exists}} == true"
        agent: "foundation:zen-architect"
        mode: "ANALYZE"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          Analyze the existing document and determine what updates are needed.
          
          The existing document is our BASELINE - we want to preserve it unless there
          are clear reasons to change it.
          
          Read the following files:
          - Existing document: {{working_dir}}/state/existing_document.md
          - Outline structure: {{working_dir}}/state/structure.json
          - Parsed outline: {{working_dir}}/state/parsed_outline.json
          - Source manifest: {{working_dir}}/state/source_manifest.json
          - Source files: {{working_dir}}/sources/
          
          Your task:
          1. Parse the existing document's structure (headings, sections)
          2. Map existing content to outline sections by matching headings
          3. For EACH outline section, perform a COMPREHENSIVE ANALYSIS:
          
             **A. Source Alignment Check:**
             - Does the section content reflect the current source files?
             - Are there gaps (source content not in section)?
             - Is there stale content (section content not backed by sources)?
          
             **B. Content Quality Check:**
             - Accuracy: Are claims factually correct per sources?
             - Completeness: Does it address the outline's prompt for this section?
             - Instructions: Does it follow any format/template requirements?
          
             **C. Quality Check:**
             - Depth: Is detail level appropriate for the section's depth in hierarchy?
             - Coherence: Does it flow logically? Good transitions?
             - Consistency: Terminology and style consistent with document?
             - Tone: Matches intended audience?
          
          4. Determine action_needed based on ALL checks:
             - "none": Section passes ALL checks - LEAVE COMPLETELY ALONE
             - "add": Missing content from sources needs to be added
             - "remove": Stale/incorrect content needs removal
             - "update": Content or quality issues require revision
          
          Create a JSON mapping with this structure:
          {
            "existing_document": {
              "title": "...",
              "total_sections": <number>,
              "total_words": <number>
            },
            "section_mappings": {
              "<section_id>": {
                "matching_heading": "...",
                "existing_content": "...",
                "source_files": ["list of source files for this section"],
                "action_needed": "none|add|remove|update",
                "action_details": "specific description of what needs to change, or empty if none",
                "source_gaps": ["content in sources not reflected in section"],
                "stale_content": ["content in section not backed by sources"],
                "quality_issues": ["any content or quality issues found, empty if none"]
              }
            },
            "unmapped_existing_sections": ["headings in existing doc not matched to outline"],
            "update_summary": {
              "sections_no_change_needed": <number>,
              "sections_need_additions": <number>,
              "sections_need_removals": <number>,
              "sections_need_updates": <number>,
              "sections_without_match": <number>
            }
          }
          
          IMPORTANT: Be conservative - only flag changes when there are CLEAR issues.
          If a section is "good enough", mark it as "none". The goal is minimal edits.
          
          Sections marked "none" will be PRESERVED EXACTLY and SKIP all validation.
          Only flag issues that genuinely need fixing.
          
          IMPORTANT: Save this mapping to: {{working_dir}}/state/existing_content_map.json
          
          After saving, return a brief confirmation with the update_summary.
        output: "existing_doc_analysis"
        timeout: 300
        retry:
          max_attempts: 2
          backoff: "exponential"
          initial_delay: 2

      # ---- EXTRACT ACTUAL CONTENT FROM EXISTING DOC (deterministic) ----
      # The agent analysis provides heading matches; this step extracts real content
      - id: "extract-existing-content"
        condition: "{{existing_doc_status.exists}} == true"
        type: "bash"
        command: |
          set -euo pipefail
          
          existing_doc="{{working_dir}}/state/existing_document.md"
          content_map="{{working_dir}}/state/existing_content_map.json"
          
          # Run Python with paths passed as arguments
          python3 - "$existing_doc" "$content_map" << 'PYEOF'
          import json
          import re
          import sys
          
          existing_doc = sys.argv[1]
          content_map_path = sys.argv[2]
          
          def parse_markdown_sections(md_content):
              """Parse markdown into sections based on headings.
              
              Properly handles code blocks - doesn't treat # inside code blocks as headings.
              """
              lines = md_content.split('\n')
              sections = []
              current_heading = None
              current_content = []
              current_level = 0
              in_code_block = False
              
              for line in lines:
                  # Track code block boundaries (``` or ~~~)
                  if line.strip().startswith('```') or line.strip().startswith('~~~'):
                      in_code_block = not in_code_block
                      current_content.append(line)
                      continue
                  
                  # Only treat as heading if NOT inside a code block
                  heading_match = re.match(r'^(#{1,6})\s+(.+)$', line) if not in_code_block else None
                  
                  if heading_match:
                      if current_heading is not None:
                          sections.append({
                              'heading': current_heading,
                              'level': current_level,
                              'content': '\n'.join(current_content).strip()
                          })
                      current_level = len(heading_match.group(1))
                      current_heading = line
                      current_content = []
                  else:
                      current_content.append(line)
              
              if current_heading is not None:
                  sections.append({
                      'heading': current_heading,
                      'level': current_level,
                      'content': '\n'.join(current_content).strip()
                  })
              
              return sections
          
          def normalize_heading(heading):
              """Normalize heading for comparison."""
              return re.sub(r'^#+\s*', '', heading).strip().lower()
          
          # Read files
          with open(existing_doc, 'r') as f:
              md_content = f.read()
          
          with open(content_map_path, 'r') as f:
              content_map = json.load(f)
          
          # Parse the existing document
          sections = parse_markdown_sections(md_content)
          
          # Create lookup by normalized heading
          section_lookup = {}
          for sec in sections:
              normalized = normalize_heading(sec['heading'])
              section_lookup[normalized] = sec
          
          # Update each section_mapping with actual content
          updated_count = 0
          for section_id, mapping in content_map.get('section_mappings', {}).items():
              matching_heading = mapping.get('matching_heading', '')
              if matching_heading:
                  normalized = normalize_heading(matching_heading)
                  if normalized in section_lookup:
                      actual_section = section_lookup[normalized]
                      # Store full content including the heading
                      full_content = actual_section['heading'] + '\n\n' + actual_section['content']
                      mapping['existing_content'] = full_content
                      mapping['content_extracted'] = True
                      updated_count += 1
                  else:
                      mapping['content_extracted'] = False
              else:
                  mapping['content_extracted'] = False
          
          # Save updated map
          with open(content_map_path, 'w') as f:
              json.dump(content_map, f, indent=2)
          
          print(f"Extracted actual content for {updated_count} sections")
          PYEOF
        output: "content_extracted"

      - id: "set-existing-doc-flag"
        type: "bash"
        command: |
          set -euo pipefail
          
          # Create a simple flag file indicating whether existing doc is available
          # Note: Template may render boolean as "True" or "true", so check both
          exists_value="{{existing_doc_status.exists}}"
          if [ "$exists_value" = "true" ] || [ "$exists_value" = "True" ]; then
            echo "true" > "{{working_dir}}/state/has_existing_document"
            echo "Existing document analysis complete - will use as reference"
          else
            echo "false" > "{{working_dir}}/state/has_existing_document"
            echo "No existing document - generating from scratch"
          fi
        output: "existing_doc_flag_set"

      # ---- INITIALIZE TRACKER ----
      
      - id: "create-tracker-file"
        type: "bash"
        command: |
          set -euo pipefail
          
          tracker_file="{{working_dir}}/state/tracker.json"
          
          if [ "{{resume_state.resuming}}" = "true" ]; then
            echo "Resuming from existing tracker - skipping creation"
          else
            jq --arg start_time "{{start_time}}" '{
              status: "initialized",
              started_at: ($start_time | gsub("^\\s+|\\s+$"; "")),
              current_stage: "initialization",
              sections_completed: [],
              sections_pending: (.bfs_order // []),
              generated_content: {},
              content_summaries: {},
              examples_introduced: [],
              definitions_established: [],
              source_extractions: {},
              validation_results: {},
              version_history: []
            }' "{{working_dir}}/state/structure.json" > "{{working_dir}}/state/tracker.json"
            
            sections=$(jq '.sections_pending | length' "{{working_dir}}/state/tracker.json")
            echo "Tracker initialized with $sections sections"
          fi
        output: "tracker_created"

      - id: "update-tracker-bfs-order"
        type: "bash"
        command: |
          set -euo pipefail
          
          jq --slurpfile structure "{{working_dir}}/state/structure.json" '
            ($structure[0].bfs_order // []) as $bfs_order |
            (.sections_completed // []) as $completed |
            .sections_pending = [$bfs_order[] | select(. as $s | $completed | index($s) | not)]
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          completed=$(jq '.sections_completed | length' "{{working_dir}}/state/tracker.json")
          pending=$(jq '.sections_pending | length' "{{working_dir}}/state/tracker.json")
          echo "BFS order set: $completed completed, $pending pending"
        output: "tracker_bfs_set"

      - id: "set-tracker-status-ready"
        type: "bash"
        command: |
          set -euo pipefail
          
          jq '.status = "ready_for_generation" | .current_stage = "initialization_complete"' \
            "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          echo "Tracker status set to ready_for_generation"
        output: "tracker_ready"

      - id: "get-bfs-order"
        type: "bash"
        command: |
          set -euo pipefail
          jq '.bfs_order // []' "{{working_dir}}/state/structure.json"
        output: "bfs_order"
        parse_json: true

  # ==========================================================================
  # STAGE 2: GENERATION
  # For each section in BFS order: generate content, update tracker
  # Sections with action_needed="none" are copied directly (no LLM)
  # Only sections needing changes go through LLM generation
  # ==========================================================================
  - name: "generation"
    approval:
      required: true
      prompt: |
        INITIALIZATION COMPLETE
        
        Resume state: {{resume_state}}
        Sources fetched: {{sources_result.total_fetched}} files
        BFS order: Ready for generation
        
        Generation will proceed in BFS order (all level 1 first, then level 2, etc.).
        Sections marked "action_needed: none" will be copied directly (no LLM).
        
        Approve to begin section generation.
      timeout: 0
      default: "deny"
    
    steps:
      # ---- DETERMINISTIC: Copy sections that need no changes ----
      - id: "copy-preserved-sections"
        type: "bash"
        command: |
          set -euo pipefail
          
          working_dir="{{working_dir}}"
          tracker_file="$working_dir/state/tracker.json"
          structure_file="$working_dir/state/structure.json"
          existing_map="$working_dir/state/existing_content_map.json"
          has_existing="$working_dir/state/has_existing_document"
          
          # Check if we have existing document analysis
          if [ ! -f "$has_existing" ] || [ "$(cat "$has_existing")" != "true" ]; then
            echo '{"preserved_count": 0, "sections_for_llm": [], "message": "No existing document - all sections need LLM generation"}'
            exit 0
          fi
          
          if [ ! -f "$existing_map" ]; then
            echo '{"preserved_count": 0, "sections_for_llm": [], "message": "No existing content map - all sections need LLM generation"}'
            exit 0
          fi
          
          # Get BFS order
          bfs_order=$(jq -r '.bfs_order // []' "$structure_file")
          
          # Identify sections to preserve (action_needed = "none") vs sections needing LLM
          preserved_sections=$(jq -r '
            .section_mappings | to_entries 
            | map(select(.value.action_needed == "none")) 
            | map(.key)
          ' "$existing_map")
          
          sections_for_llm=$(jq -r '
            .section_mappings | to_entries 
            | map(select(.value.action_needed != "none")) 
            | map(.key)
          ' "$existing_map")
          
          # Also add sections not in the mapping (new sections) to the LLM list
          all_mapped=$(jq -r '.section_mappings | keys' "$existing_map")
          unmapped_sections=$(jq -n --argjson bfs "$bfs_order" --argjson mapped "$all_mapped" '
            $bfs | map(select(. as $s | $mapped | index($s) | not))
          ')
          
          # Combine: sections needing changes + unmapped sections = sections for LLM
          final_llm_list=$(jq -n --argjson needs_change "$sections_for_llm" --argjson unmapped "$unmapped_sections" '
            ($needs_change + $unmapped) | unique
          ')
          
          preserved_count=$(echo "$preserved_sections" | jq 'length')
          
          # For each preserved section, copy existing content to tracker
          if [ "$preserved_count" -gt 0 ]; then
            echo "Copying $preserved_count sections with action_needed=none directly to tracker..." >&2
            
            # Build a jq script to update tracker with preserved content
            for section_id in $(echo "$preserved_sections" | jq -r '.[]'); do
              # Get existing content and heading from the map
              existing_content=$(jq -r --arg sid "$section_id" '.section_mappings[$sid].existing_content // ""' "$existing_map")
              matching_heading=$(jq -r --arg sid "$section_id" '.section_mappings[$sid].matching_heading // ""' "$existing_map")
              
              # Get the full section content from the existing document
              # We need to extract the actual markdown content, not just the summary
              # For now, use the existing_content field (which should have the full content)
              
              # Create a summary (first 100 chars)
              summary=$(echo "$existing_content" | head -c 200 | tr '\n' ' ')
              
              # Update tracker with this section
              jq --arg sid "$section_id" \
                 --arg content "$existing_content" \
                 --arg heading "$matching_heading" \
                 --arg summary "$summary" '
                .sections_completed += [$sid] |
                .sections_completed |= unique |
                .sections_pending = ([.sections_pending[] | select(. != $sid)]) |
                .generated_content[$sid] = $content |
                .content_summaries[$sid] = $summary
              ' "$tracker_file" > "$tracker_file.tmp" && mv "$tracker_file.tmp" "$tracker_file"
              
              echo "  - Preserved section $section_id: $matching_heading" >&2
            done
          fi
          
          # Save preserved sections list to state file (for validation to skip)
          echo "$preserved_sections" > "$working_dir/state/preserved_sections.json"
          echo "Saved preserved sections list to state file" >&2
          
          # Output the results
          jq -n \
            --argjson preserved_count "$preserved_count" \
            --argjson preserved "$preserved_sections" \
            --argjson for_llm "$final_llm_list" \
            '{
              preserved_count: $preserved_count,
              preserved_sections: $preserved,
              sections_for_llm: $for_llm,
              llm_count: ($for_llm | length),
              message: (
                if $preserved_count > 0 then
                  "\($preserved_count) sections preserved from existing doc, \($for_llm | length) sections need LLM generation"
                else
                  "All sections need LLM generation"
                end
              )
            }'
        output: "preservation_result"
        parse_json: true

      # ---- Filter BFS order to only sections needing LLM ----
      - id: "get-sections-for-llm"
        type: "bash"
        command: |
          set -euo pipefail
          
          # Get the filtered list from preservation_result, maintaining BFS order
          bfs_order=$(jq -r '.bfs_order // []' "{{working_dir}}/state/structure.json")
          sections_for_llm='{{preservation_result.sections_for_llm}}'
          
          # Filter BFS order to only include sections needing LLM, preserving order
          jq -n --argjson bfs "$bfs_order" --argjson for_llm "$sections_for_llm" '
            $bfs | map(select(. as $s | $for_llm | index($s)))
          '
        output: "llm_bfs_order"
        parse_json: true

      # ---- LLM GENERATION: Only for sections needing changes or new sections ----
      # NOTE: Sections with action_needed="none" are already copied by copy-preserved-sections
      # This foreach only processes sections that need LLM work
      - id: "generate-section"
        foreach: "{{llm_bfs_order}}"
        as: "section_id"
        agent: "foundation:zen-architect"
        provider_preferences:
          - provider: anthropic
            model: claude-opus-4-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          ## SECTION GENERATION: {{section_id}}
          
          You are generating/updating content for section "{{section_id}}" of the document.
          
          **NOTE**: This section was identified as needing LLM work (not "action_needed: none").
          Sections that needed no changes were already preserved automatically.
          
          Working directory: {{working_dir}}
          
          ---
          
          ### STEP 1: Read Current State
          
          Read the following files:
          - Tracker: {{working_dir}}/state/tracker.json
          - Structure: {{working_dir}}/state/structure.json
          - Parsed outline: {{working_dir}}/state/parsed_outline.json
          - Existing content map (if exists): {{working_dir}}/state/existing_content_map.json
          
          ---
          
          ### STEP 2: Check If Already Done
          
          If "{{section_id}}" is already in sections_completed, return:
          ```json
          {"status": "skipped", "reason": "already_complete", "section_id": "{{section_id}}"}
          ```
          
          Otherwise, continue.
          
          ---
          
          ### STEP 3: Build Context
          
          From structure.json, look up section "{{section_id}}" to get heading, depth, 
          parent_id, ancestor_ids, sibling_ids, prompt, and source_files.
          
          Build context from tracker:
          - Ancestor content from generated_content
          - Sibling summaries from content_summaries
          - Established definitions and examples
          
          Read source files from: {{working_dir}}/sources/
          
          **Check existing_content_map.json for this section** (if file exists):
          Look up section_mappings["{{section_id}}"] to determine the action:
          - If action_needed is "add": Keep existing_content, ADD content from source_gaps
          - If action_needed is "remove": Keep existing_content, REMOVE items in stale_content
          - If action_needed is "update": Revise existing_content per action_details
          - If no mapping exists: Generate from scratch using sources
          
          ---
          
          ### STEP 4: Generate/Update Content
          
          **If existing content needs modification (add/remove/update):**
          - Start with the existing_content as your base
          - Make ONLY the specific changes indicated
          - Preserve the existing style, tone, and structure
          - Do NOT rewrite - make targeted edits
          
          **If generating from scratch (no existing content):**
          Write the section content with:
          - Depth-appropriate detail
          - Accumulated context awareness (no redefinitions)
          - Source integration
          - Proper heading level
          
          ---
          
          ### STEP 5: Update Tracker
          
          Update {{working_dir}}/state/tracker.json:
          1. Add "{{section_id}}" to sections_completed
          2. Remove "{{section_id}}" from sections_pending
          3. Store content in generated_content["{{section_id}}"]
          4. Store summary in content_summaries["{{section_id}}"]
          5. Append new definitions and examples
          
          ---
          
          ### STEP 6: Return Result
          
          Return JSON with status, section_id, heading, content, summary, and:
            action_taken: "added|removed|updated|generated_new"
        output: "section_result"
        parse_json: true
        timeout: 600
        retry:
          max_attempts: 2
          backoff: "exponential"
          initial_delay: 3
        collect: "all_section_results"

      - id: "set-generation-complete-status"
        type: "bash"
        command: |
          set -euo pipefail
          
          timestamp=$(date -Iseconds)
          jq --arg ts "$timestamp" '
            .status = "generation_complete" |
            .current_stage = "generation" |
            .generation_completed_at = $ts
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          sections=$(jq '.sections_completed | length' "{{working_dir}}/state/tracker.json")
          echo "Generation complete: $sections sections"
        output: "generation_status_set"

      - id: "assemble-document-from-tracker"
        agent: "foundation:zen-architect"
        mode: "ARCHITECT"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          Assemble the complete document from all generated sections.
          
          Read:
          - Tracker: {{working_dir}}/state/tracker.json
          - Structure: {{working_dir}}/state/structure.json
          - Parsed outline: {{working_dir}}/state/parsed_outline.json
          
          Tasks:
          1. Extract content for each section from tracker's generated_content
          2. Arrange sections in proper HIERARCHICAL order (not BFS order)
          3. Add document title from metadata
          4. Ensure heading levels are consistent
          
          IMPORTANT: Write the complete assembled document to:
          {{working_dir}}/versions/v0_generated.md
          
          Return: {"assembled": true, "output_file": "v0_generated.md", "sections_included": <count>}
        output: "assemble_result"
        parse_json: true
        timeout: 300

      - id: "save-v0-generated"
        type: "bash"
        command: |
          set -euo pipefail
          
          version_file="{{working_dir}}/versions/v0_generated.md"
          
          if [ ! -f "$version_file" ]; then
            echo "ERROR: Agent failed to write v0_generated.md" >&2
            exit 1
          fi
          
          timestamp=$(date -Iseconds)
          jq --arg ts "$timestamp" --arg file "{{working_dir}}/versions/v0_generated.md" '
            .version_history += [{
              "version": "v0_generated",
              "stage": "generation",
              "timestamp": $ts,
              "file": $file
            }]
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          bytes=$(wc -c < "$version_file")
          lines=$(wc -l < "$version_file")
          echo "Saved v0_generated: $bytes bytes, $lines lines"
        output: "v0_saved"

      # ========================================================================
      # DESIGN INTELLIGENCE FEEDBACK ON v0 (Initial Generation)
      # ========================================================================
      # These steps capture DI perspective on the RAW generated document
      # BEFORE any validation fixes are applied. This lets us compare:
      # - What DI sees in the initial generation
      # - How that changes after validation stages complete
      # ========================================================================

      - id: "di-v0-voice-feedback"
        agent: "design-intelligence:voice-strategist"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
        prompt: |
          DESIGN INTELLIGENCE FEEDBACK: Voice & Tone Review (INITIAL GENERATION)
          
          You are providing OBSERVATIONAL FEEDBACK ONLY on the INITIAL generated document
          (v0) BEFORE any validation fixes have been applied. This feedback will be
          compared against feedback on the final document to understand how validation
          affects the document.
          
          Read the document from: {{working_dir}}/versions/v0_generated.md
          
          Provide feedback on these dimensions (from a voice strategist perspective):
          
          1. **Voice Consistency**
             - Is the voice/tone consistent throughout?
             - Does it match the apparent audience?
             - Are there shifts in formality or style?
          
          2. **Clarity of Messaging**
             - Are concepts explained clearly?
             - Is technical jargon appropriate for the audience?
             - Are there confusing or ambiguous passages?
          
          3. **Readability**
             - Is sentence structure varied and engaging?
             - Are paragraphs well-organized?
             - Does the document flow naturally?
          
          4. **Incidental Findings**
             - Note any contradictions or inconsistencies you observe
             - Flag any content that seems out of place
             - Highlight particularly effective passages
          
          IMPORTANT: This is feedback only. Do NOT rewrite or fix anything.
          
          Return ONLY this JSON:
          {
            "voice_consistency": {
              "score": "<1-10>",
              "observations": ["..."],
              "notable_sections": ["section names with issues or strengths"]
            },
            "clarity": {
              "score": "<1-10>",
              "observations": ["..."],
              "unclear_passages": ["brief descriptions"]
            },
            "readability": {
              "score": "<1-10>",
              "observations": ["..."]
            },
            "incidental_findings": ["any contradictions, dead content, or notable observations"],
            "overall_voice_assessment": "<brief summary of voice/tone quality>"
          }
        output: "di_v0_voice_feedback"
        parse_json: true
        timeout: 300

      - id: "di-v0-structure-feedback"
        agent: "design-intelligence:layout-architect"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
        prompt: |
          DESIGN INTELLIGENCE FEEDBACK: Structure Review (INITIAL GENERATION)
          
          You are providing OBSERVATIONAL FEEDBACK ONLY on the INITIAL generated document
          (v0) BEFORE any validation fixes have been applied. This feedback will be
          compared against feedback on the final document to understand how validation
          affects the document.
          
          Read the document from: {{working_dir}}/versions/v0_generated.md
          
          Provide feedback on these dimensions (from a layout architect perspective):
          
          1. **Information Architecture**
             - Is the hierarchy clear and logical?
             - Are sections organized in a sensible order?
             - Is the depth of nesting appropriate?
          
          2. **Content Flow**
             - Does the document follow a clear narrative arc?
             - Are transitions between sections smooth?
             - Is there a logical progression of ideas?
          
          3. **Navigation & Wayfinding**
             - Would readers know where they are in the document?
             - Are section headings descriptive and helpful?
             - Is the structure predictable and scannable?
          
          4. **Incidental Findings**
             - Note any structural issues (orphaned sections, missing context)
             - Flag any content that seems misplaced
             - Highlight particularly effective organizational choices
          
          IMPORTANT: This is feedback only. Do NOT restructure or fix anything.
          
          Return ONLY this JSON:
          {
            "information_architecture": {
              "score": "<1-10>",
              "observations": ["..."],
              "hierarchy_issues": ["any issues with section hierarchy"]
            },
            "content_flow": {
              "score": "<1-10>",
              "observations": ["..."],
              "flow_breaks": ["sections where flow is disrupted"]
            },
            "navigation": {
              "score": "<1-10>",
              "observations": ["..."]
            },
            "incidental_findings": ["structural issues, misplaced content, notable observations"],
            "overall_structure_assessment": "<brief summary of structural quality>"
          }
        output: "di_v0_structure_feedback"
        parse_json: true
        timeout: 300

      - id: "save-di-v0-feedback"
        type: "bash"
        command: |
          set -euo pipefail
          
          timestamp=$(date -Iseconds)
          
          # Write JSON values to temp files to avoid bash quoting issues
          cat > "{{working_dir}}/state/tmp_v0_voice.json" << 'VOICE_EOF'
          {{di_v0_voice_feedback}}
          VOICE_EOF
          
          cat > "{{working_dir}}/state/tmp_v0_structure.json" << 'STRUCTURE_EOF'
          {{di_v0_structure_feedback}}
          STRUCTURE_EOF
          
          # Combine using jq with slurpfile (reads JSON from files safely)
          jq -n --arg ts "$timestamp" \
             --slurpfile voice "{{working_dir}}/state/tmp_v0_voice.json" \
             --slurpfile structure "{{working_dir}}/state/tmp_v0_structure.json" '
            {
              "timestamp": $ts,
              "version": "v0_generated",
              "purpose": "Design Intelligence feedback on INITIAL generation (before validation)",
              "note": "Compare this against final (v3) feedback to see validation impact",
              "voice_feedback": $voice[0],
              "structure_feedback": $structure[0]
            }
          ' > "{{working_dir}}/state/di_v0_feedback.json"
          
          # Clean up temp files
          rm -f "{{working_dir}}/state/tmp_v0_voice.json" "{{working_dir}}/state/tmp_v0_structure.json"
          
          echo "Design Intelligence v0 feedback saved to {{working_dir}}/state/di_v0_feedback.json"
        output: "di_v0_feedback_saved"

      # ========================================================================
      # END DESIGN INTELLIGENCE FEEDBACK ON v0
      # ========================================================================

  # ==========================================================================
  # STAGE 3: VALIDATION - STRUCTURAL (Sequential, must be first)
  # ==========================================================================
  - name: "validation-structural"
    approval:
      required: true
      prompt: |
        GENERATION COMPLETE - v0_generated saved
        
        {{v0_saved}}
        
        Ready for STRUCTURAL INTEGRITY validation:
        - All sections from outline present
        - Headings match specification
        - Hierarchy is correct
        
        This check must run first before content/quality checks.
        
        Approve to run structural validation.
      timeout: 0
      default: "deny"
    
    steps:
      - id: "check-structural-issues"
        agent: "foundation:zen-architect"
        mode: "REVIEW"
        provider_preferences:
          - provider: anthropic
            model: claude-haiku-*
          - provider: openai
            model: gpt-4o-mini
        prompt: |
          Check the document for STRUCTURAL issues.
          
          Read the document from: {{working_dir}}/versions/v0_generated.md
          Read the expected structure from: {{working_dir}}/state/structure.json
          
          Check for:
          1. Missing sections (in outline but not in document)
          2. Wrong headings (text doesn't match outline)
          3. Wrong hierarchy (section at wrong nesting level)
          4. Extra sections (in document but not in outline)
          
          Return ONLY this JSON:
          {
            "issues": [
              {
                "type": "missing_section|wrong_heading|wrong_hierarchy|extra_section",
                "section_id": "...",
                "expected": "...",
                "found": "...",
                "severity": "critical|major|minor"
              }
            ],
            "issue_count": <number>,
            "passed": true/false
          }
        output: "structural_issues"
        parse_json: true
        timeout: 300

      - id: "fix-structural-issues"
        condition: "{{structural_issues.passed}} == false"
        agent: "foundation:zen-architect"
        mode: "ARCHITECT"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          Fix STRUCTURAL issues in the document.
          
          Read the current document from: {{working_dir}}/versions/v0_generated.md
          Read the expected structure from: {{working_dir}}/state/structure.json
          
          Issues to fix:
          {{structural_issues.issues}}
          
          Fix all structural issues.
          
          IMPORTANT: Write the fixed document directly to:
          {{working_dir}}/versions/v1_structural.md
          
          Return: {"fixed": true, "issues_fixed": <count>, "output_file": "v1_structural.md"}
        output: "structural_fix_result"
        parse_json: true
        timeout: 600

      - id: "save-v1-structural"
        type: "bash"
        command: |
          set -euo pipefail
          
          version_file="{{working_dir}}/versions/v1_structural.md"
          prev_version="{{working_dir}}/versions/v0_generated.md"
          
          # Three-way logic with size validation
          if [ "{{structural_issues.passed}}" = "true" ] || [ "{{structural_issues.passed}}" = "True" ]; then
            cp "$prev_version" "$version_file"
            echo "Validation passed - copied previous version"
          elif [ -f "$version_file" ]; then
            file_size=$(wc -c < "$version_file")
            prev_size=$(wc -c < "$prev_version")
            min_expected=$((prev_size / 2))
            
            if [ "$file_size" -lt "$min_expected" ]; then
              echo "WARNING: Agent wrote small file ($file_size < $min_expected bytes)" >&2
              cp "$prev_version" "$version_file"
            else
              echo "Agent wrote fixed version ($file_size bytes)"
            fi
          else
            echo "WARNING: Agent did not write fixed file, using previous" >&2
            cp "$prev_version" "$version_file"
          fi
          
          timestamp=$(date -Iseconds)
          if [ "{{structural_issues.passed}}" = "true" ] || [ "{{structural_issues.passed}}" = "True" ]; then
            passed_json="true"
          else
            passed_json="false"
          fi
          jq --arg ts "$timestamp" --arg file "$version_file" --argjson passed "$passed_json" '
            .version_history += [{
              "version": "v1_structural",
              "stage": "validation-structural",
              "timestamp": $ts,
              "validation_passed": $passed,
              "file": $file
            }] |
            .validation_results.structural = $passed
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          echo "Saved v1_structural (passed: $passed_json)"
        output: "v1_saved"

  # ==========================================================================
  # STAGE 4: VALIDATION - CONTENT (Parallel: accuracy, completeness, instructions)
  # ==========================================================================
  - name: "validation-content"
    approval:
      required: true
      prompt: |
        STRUCTURAL VALIDATION COMPLETE
        
        {{v1_saved}}
        
        Ready for CONTENT VALIDATION phase (PARALLEL EXECUTION):
        
        The following 3 checks will run IN PARALLEL:
        - Accuracy: Claims traceable to sources, no hallucinated content
        - Completeness: Prompts fully addressed, no significant omissions
        - Instructions: Format/template followed, required elements present
        
        Issues from all checks will be aggregated and fixed together.
        
        Approve to run content validation.
      timeout: 0
      default: "deny"
    
    steps:
      # Define content check configurations
      - id: "define-content-checks"
        type: "bash"
        command: |
          cat << 'EOF'
          [
            {
              "type": "accuracy",
              "focus": "Verify all claims are traceable to sources. Check for hallucinated or inaccurate content.",
              "check_items": ["factual claims", "code examples", "technical details", "statistics"],
              "issue_types": ["hallucinated", "inaccurate", "unsupported", "misrepresented"]
            },
            {
              "type": "completeness",
              "focus": "Verify each section's prompt was fully addressed. Check for significant omissions.",
              "check_items": ["prompt requirements", "source coverage", "topic breadth", "key concepts"],
              "issue_types": ["omission", "incomplete", "missing_topic", "shallow_coverage"]
            },
            {
              "type": "instructions",
              "focus": "Verify sections followed their instructions. Check format and template compliance.",
              "check_items": ["format requirements", "template usage", "required elements", "style guidelines"],
              "issue_types": ["format_violation", "template_mismatch", "missing_element", "style_deviation"]
            }
          ]
          EOF
        output: "content_check_definitions"
        parse_json: true

      # Run all content checks in parallel
      - id: "run-content-checks"
        foreach: "{{content_check_definitions}}"
        as: "check"
        parallel: 3
        agent: "foundation:zen-architect"
        mode: "REVIEW"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          ## {{check.type}} VALIDATION
          
          Perform {{check.type}} validation on the document.
          
          Read the document from: {{working_dir}}/versions/v1_structural.md
          Read sources from: {{working_dir}}/sources/
          Read section details from: {{working_dir}}/state/structure.json
          
          **Focus:** {{check.focus}}
          
          **Check items:** {{check.check_items}}
          
          **Issue types to identify:** {{check.issue_types}}
          
          For each issue found, include:
          - location: section or line description
          - issue_type: one of {{check.issue_types}}
          - description: what's wrong
          - evidence: what you found vs what was expected
          - severity: critical, major, or minor
          
          Return ONLY this JSON:
          {
            "check_type": "{{check.type}}",
            "issues": [
              {
                "location": "...",
                "issue_type": "...",
                "description": "...",
                "evidence": "...",
                "severity": "critical|major|minor"
              }
            ],
            "items_checked": <number>,
            "issue_count": <number>,
            "passed": true/false
          }
        output: "check_result"
        parse_json: true
        timeout: 600
        collect: "content_check_results"

      # Aggregate all content issues
      - id: "aggregate-content-issues"
        type: "bash"
        command: |
          set -euo pipefail
          
          # Write results to file for jq processing
          cat > "{{working_dir}}/state/content_check_results.json" << 'RESULTS_EOF'
          {{content_check_results}}
          RESULTS_EOF
          
          # Aggregate issues from all checks
          jq '{
            all_issues: [.[] | .issues[]] | flatten,
            checks_summary: [.[] | {check_type, passed, issue_count, items_checked}],
            all_passed: (map(.passed) | all),
            total_issue_count: ([.[] | .issue_count] | add // 0),
            critical_count: ([.[] | .issues[] | select(.severity == "critical")] | length),
            major_count: ([.[] | .issues[] | select(.severity == "major")] | length),
            minor_count: ([.[] | .issues[] | select(.severity == "minor")] | length)
          }' "{{working_dir}}/state/content_check_results.json"
        output: "aggregated_content_issues"
        parse_json: true

      # Combined fix step for all content issues
      - id: "fix-content-issues"
        condition: "{{aggregated_content_issues.all_passed}} == false"
        agent: "foundation:zen-architect"
        mode: "ARCHITECT"
        provider_preferences:
          - provider: anthropic
            model: claude-opus-4-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          ## FIX CONTENT VALIDATION ISSUES
          
          Multiple content validation checks identified issues that need fixing.
          Address ALL issues in a single, coherent pass.
          
          Read the current document from: {{working_dir}}/versions/v1_structural.md
          Read sources from: {{working_dir}}/sources/
          Read section details from: {{working_dir}}/state/structure.json
          
          **IMPORTANT - PRESERVED SECTIONS:**
          Read: {{working_dir}}/state/preserved_sections.json
          
          This file lists section IDs that were PRESERVED from the existing document.
          These sections were already validated during analysis and marked as needing
          no changes. DO NOT modify preserved sections - skip any issues in them.
          
          **Checks Summary:**
          {{aggregated_content_issues.checks_summary}}
          
          **Total Issues:** {{aggregated_content_issues.total_issue_count}}
          - Critical: {{aggregated_content_issues.critical_count}}
          - Major: {{aggregated_content_issues.major_count}}
          - Minor: {{aggregated_content_issues.minor_count}}
          
          **All Issues to Fix:**
          {{aggregated_content_issues.all_issues}}
          
          **Instructions:**
          1. SKIP issues in preserved sections (already validated)
          2. Address remaining issues holistically - changes for one may affect others
          3. For accuracy issues: correct facts, add citations, remove unsupported claims
          4. For completeness issues: add missing content from sources
          5. For instruction issues: fix format/template compliance
          6. Prioritize: critical > major > minor
          
          IMPORTANT: Write the complete fixed document to:
          {{working_dir}}/versions/v2_content.md
          
          Return: {
            "fixed": true,
            "issues_addressed": <count>,
            "issues_skipped_preserved": <count>,
            "by_type": {"accuracy": N, "completeness": N, "instructions": N},
            "output_file": "v2_content.md"
          }
        output: "content_fix_result"
        parse_json: true
        timeout: 900

      # Restore preserved sections after content fix (deterministic - LLM can't be trusted to skip)
      - id: "restore-preserved-after-content-fix"
        condition: "{{aggregated_content_issues.all_passed}} == false"
        type: "bash"
        command: |
          set -euo pipefail
          
          working_dir="{{working_dir}}"
          version_file="$working_dir/versions/v2_content.md"
          preserved_file="$working_dir/state/preserved_sections.json"
          content_map="$working_dir/state/existing_content_map.json"
          
          # Skip if no preserved sections file
          if [ ! -f "$preserved_file" ]; then
            echo "No preserved sections file - skipping restore"
            exit 0
          fi
          
          preserved_count=$(jq 'length' "$preserved_file")
          if [ "$preserved_count" -eq 0 ]; then
            echo "No preserved sections - skipping restore"
            exit 0
          fi
          
          # Skip if version file doesn't exist
          if [ ! -f "$version_file" ]; then
            echo "Version file not created yet - skipping restore"
            exit 0
          fi
          
          echo "Restoring $preserved_count preserved sections..."
          
          # Use Python to restore preserved sections
          python3 - "$version_file" "$content_map" "$preserved_file" << 'PYEOF'
          import json
          import re
          import sys
          
          version_file = sys.argv[1]
          content_map_path = sys.argv[2]
          preserved_file = sys.argv[3]
          
          # Read files
          with open(version_file, 'r') as f:
              doc_content = f.read()
          
          with open(content_map_path, 'r') as f:
              content_map = json.load(f)
          
          with open(preserved_file, 'r') as f:
              preserved_ids = json.load(f)
          
          def normalize_heading(heading):
              """Normalize heading for comparison."""
              return re.sub(r'^#+\s*', '', heading).strip().lower()
          
          def find_section_boundaries(content, heading):
              """Find the start and end positions of a section by its heading.
              
              Properly handles code blocks - doesn't treat # inside code blocks as headings.
              """
              lines = content.split('\n')
              normalized_target = normalize_heading(heading)
              
              start_idx = None
              start_level = None
              in_code_block = False
              
              for i, line in enumerate(lines):
                  # Track code block boundaries
                  if line.strip().startswith('```') or line.strip().startswith('~~~'):
                      in_code_block = not in_code_block
                      continue
                  
                  # Only treat as heading if NOT inside a code block
                  heading_match = re.match(r'^(#{1,6})\s+(.+)$', line) if not in_code_block else None
                  
                  if heading_match:
                      level = len(heading_match.group(1))
                      normalized = normalize_heading(line)
                      
                      if start_idx is None:
                          # Looking for start
                          if normalized == normalized_target:
                              start_idx = i
                              start_level = level
                      else:
                          # Looking for end (next heading of same or higher level)
                          if level <= start_level:
                              return start_idx, i
              
              # If we found start but no end, section goes to end of doc
              if start_idx is not None:
                  return start_idx, len(lines)
              
              return None, None
          
          restored_count = 0
          lines = doc_content.split('\n')
          
          # Process each preserved section (in reverse order to maintain indices)
          sections_to_restore = []
          for section_id in preserved_ids:
              mapping = content_map.get('section_mappings', {}).get(section_id, {})
              matching_heading = mapping.get('matching_heading', '')
              original_content = mapping.get('existing_content', '')
              
              if matching_heading and original_content:
                  start, end = find_section_boundaries(doc_content, matching_heading)
                  if start is not None:
                      sections_to_restore.append({
                          'section_id': section_id,
                          'heading': matching_heading,
                          'start': start,
                          'end': end,
                          'original': original_content
                      })
          
          # Sort by start position descending (so we can replace from bottom up)
          sections_to_restore.sort(key=lambda x: x['start'], reverse=True)
          
          for section in sections_to_restore:
              # Replace lines from start to end with original content
              original_lines = section['original'].split('\n')
              lines = lines[:section['start']] + original_lines + lines[section['end']:]
              restored_count += 1
              print(f"  Restored: {section['heading']}", file=sys.stderr)
          
          # Write restored content
          with open(version_file, 'w') as f:
              f.write('\n'.join(lines))
          
          print(f"Restored {restored_count} preserved sections")
          PYEOF
        output: "content_restore_result"

      # Save v2 with content fixes
      - id: "save-v2-content"
        type: "bash"
        command: |
          set -euo pipefail
          
          version_file="{{working_dir}}/versions/v2_content.md"
          prev_version="{{working_dir}}/versions/v1_structural.md"
          
          # Three-way logic with size validation
          if [ "{{aggregated_content_issues.all_passed}}" = "true" ] || [ "{{aggregated_content_issues.all_passed}}" = "True" ]; then
            cp "$prev_version" "$version_file"
            echo "All content checks passed - copied previous version"
          elif [ -f "$version_file" ]; then
            file_size=$(wc -c < "$version_file")
            prev_size=$(wc -c < "$prev_version")
            min_expected=$((prev_size / 2))
            
            if [ "$file_size" -lt "$min_expected" ]; then
              echo "WARNING: Agent wrote small file ($file_size < $min_expected bytes)" >&2
              cp "$prev_version" "$version_file"
            else
              echo "Agent wrote fixed version ($file_size bytes)"
            fi
          else
            echo "WARNING: Agent did not write fixed file, using previous" >&2
            cp "$prev_version" "$version_file"
          fi
          
          timestamp=$(date -Iseconds)
          if [ "{{aggregated_content_issues.all_passed}}" = "true" ] || [ "{{aggregated_content_issues.all_passed}}" = "True" ]; then
            passed_json="true"
          else
            passed_json="false"
          fi
          
          # Record all check results in tracker
          jq --arg ts "$timestamp" --arg file "$version_file" --argjson passed "$passed_json" \
             --argjson total "{{aggregated_content_issues.total_issue_count}}" '
            .version_history += [{
              "version": "v2_content",
              "stage": "validation-content",
              "timestamp": $ts,
              "validation_passed": $passed,
              "issues_fixed": $total,
              "checks": ["accuracy", "completeness", "instructions"],
              "file": $file
            }] |
            .validation_results.content = {
              "passed": $passed,
              "checks_run": ["accuracy", "completeness", "instructions"],
              "parallel": true
            }
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          echo "Saved v2_content (all_passed: $passed_json, issues: {{aggregated_content_issues.total_issue_count}})"
        output: "v2_saved"

  # ==========================================================================
  # STAGE 5: VALIDATION - QUALITY (Parallel: depth, coherence, crossrefs, consistency, tone)
  # ==========================================================================
  - name: "validation-quality"
    approval:
      required: true
      prompt: |
        CONTENT VALIDATION COMPLETE
        
        {{v2_saved}}
        
        Ready for QUALITY VALIDATION phase (PARALLEL EXECUTION):
        
        The following 5 checks will run IN PARALLEL:
        - Depth: Level-appropriate detail (intro broad, deep sections detailed)
        - Coherence: Flow, transitions, no unnecessary duplication
        - Cross-references: Internal references accurate, sections exist
        - Consistency: Terminology uniform, style consistent
        - Tone: Matches intended audience and document purpose
        
        Issues from all checks will be aggregated and fixed together.
        
        Approve to run quality validation.
      timeout: 0
      default: "deny"
    
    steps:
      # Define quality check configurations
      - id: "define-quality-checks"
        type: "bash"
        command: |
          cat << 'EOF'
          [
            {
              "type": "depth",
              "focus": "Verify depth-appropriate detail: level 1 sections should be broad overviews, deeper sections should have more detail.",
              "check_items": ["level 1 breadth", "level 2 detail", "leaf section depth", "detail consistency"],
              "issue_types": ["too_shallow", "too_deep", "inconsistent_depth", "missing_detail"]
            },
            {
              "type": "coherence",
              "focus": "Verify document flow and coherence: smooth transitions, no duplication, logical progression.",
              "check_items": ["section transitions", "content duplication", "logical flow", "narrative coherence"],
              "issue_types": ["poor_flow", "missing_transition", "duplication", "gap", "bad_order"]
            },
            {
              "type": "crossrefs",
              "focus": "Verify internal references are valid: referenced sections exist, claims match target content.",
              "check_items": ["section references", "see also links", "above/below references", "internal links"],
              "issue_types": ["section_not_found", "content_mismatch", "ambiguous_reference", "broken_link"]
            },
            {
              "type": "consistency",
              "focus": "Verify terminology and style consistency: same concepts use same names, formatting uniform.",
              "check_items": ["terminology usage", "naming conventions", "abbreviations", "formatting patterns"],
              "issue_types": ["terminology_variance", "style_inconsistency", "naming_mismatch", "format_deviation"]
            },
            {
              "type": "tone",
              "focus": "Verify tone matches audience and purpose: appropriate formality, technicality, voice.",
              "check_items": ["audience fit", "purpose alignment", "formality level", "technicality level"],
              "issue_types": ["too_technical", "too_casual", "too_formal", "inconsistent_tone", "audience_mismatch"]
            }
          ]
          EOF
        output: "quality_check_definitions"
        parse_json: true

      # Run all quality checks in parallel
      - id: "run-quality-checks"
        foreach: "{{quality_check_definitions}}"
        as: "check"
        parallel: 3
        agent: "foundation:zen-architect"
        mode: "REVIEW"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          ## {{check.type}} VALIDATION
          
          Perform {{check.type}} validation on the document.
          
          Read the document from: {{working_dir}}/versions/v2_content.md
          Read metadata from: {{working_dir}}/state/parsed_outline.json
          Read section details from: {{working_dir}}/state/structure.json
          
          **Focus:** {{check.focus}}
          
          **Check items:** {{check.check_items}}
          
          **Issue types to identify:** {{check.issue_types}}
          
          For each issue found, include:
          - location: section or specific text
          - issue_type: one of {{check.issue_types}}
          - description: what's wrong
          - suggestion: how to fix it
          - severity: critical, major, or minor
          
          Return ONLY this JSON:
          {
            "check_type": "{{check.type}}",
            "issues": [
              {
                "location": "...",
                "issue_type": "...",
                "description": "...",
                "suggestion": "...",
                "severity": "critical|major|minor"
              }
            ],
            "items_checked": <number>,
            "issue_count": <number>,
            "passed": true/false
          }
        output: "check_result"
        parse_json: true
        timeout: 600
        collect: "quality_check_results"

      # Aggregate all quality issues
      - id: "aggregate-quality-issues"
        type: "bash"
        command: |
          set -euo pipefail
          
          # Write results to file for jq processing
          cat > "{{working_dir}}/state/quality_check_results.json" << 'RESULTS_EOF'
          {{quality_check_results}}
          RESULTS_EOF
          
          # Aggregate issues from all checks
          jq '{
            all_issues: [.[] | .issues[]] | flatten,
            checks_summary: [.[] | {check_type, passed, issue_count, items_checked}],
            all_passed: (map(.passed) | all),
            total_issue_count: ([.[] | .issue_count] | add // 0),
            critical_count: ([.[] | .issues[] | select(.severity == "critical")] | length),
            major_count: ([.[] | .issues[] | select(.severity == "major")] | length),
            minor_count: ([.[] | .issues[] | select(.severity == "minor")] | length)
          }' "{{working_dir}}/state/quality_check_results.json"
        output: "aggregated_quality_issues"
        parse_json: true

      # Combined fix step for all quality issues
      - id: "fix-quality-issues"
        condition: "{{aggregated_quality_issues.all_passed}} == false"
        agent: "foundation:zen-architect"
        mode: "ARCHITECT"
        provider_preferences:
          - provider: anthropic
            model: claude-opus-4-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          ## FIX QUALITY VALIDATION ISSUES
          
          Multiple quality validation checks identified issues that need fixing.
          Address ALL issues in a single, coherent pass.
          
          Read the current document from: {{working_dir}}/versions/v2_content.md
          Read metadata from: {{working_dir}}/state/parsed_outline.json
          
          **IMPORTANT - PRESERVED SECTIONS:**
          Read: {{working_dir}}/state/preserved_sections.json
          
          This file lists section IDs that were PRESERVED from the existing document.
          These sections were already validated during analysis and marked as needing
          no changes. DO NOT modify preserved sections - skip any issues in them.
          
          **Checks Summary:**
          {{aggregated_quality_issues.checks_summary}}
          
          **Total Issues:** {{aggregated_quality_issues.total_issue_count}}
          - Critical: {{aggregated_quality_issues.critical_count}}
          - Major: {{aggregated_quality_issues.major_count}}
          - Minor: {{aggregated_quality_issues.minor_count}}
          
          **All Issues to Fix:**
          {{aggregated_quality_issues.all_issues}}
          
          **Instructions:**
          1. SKIP issues in preserved sections (already validated)
          2. Address remaining issues holistically - changes for one may affect others
          3. For depth issues: expand shallow sections or consolidate overly detailed intros
          4. For coherence issues: add transitions, remove duplication, improve flow
          5. For crossref issues: fix references or update referenced content
          6. For consistency issues: standardize terminology, formatting, style
          7. For tone issues: adjust formality and technicality to match audience
          8. Prioritize: critical > major > minor
          
          IMPORTANT: Write the complete fixed document to:
          {{working_dir}}/versions/v3_quality.md
          
          Return: {
            "fixed": true,
            "issues_addressed": <count>,
            "issues_skipped_preserved": <count>,
            "by_type": {"depth": N, "coherence": N, "crossrefs": N, "consistency": N, "tone": N},
            "output_file": "v3_quality.md"
          }
        output: "quality_fix_result"
        parse_json: true
        timeout: 900

      # Restore preserved sections after quality fix (deterministic - LLM can't be trusted to skip)
      - id: "restore-preserved-after-quality-fix"
        condition: "{{aggregated_quality_issues.all_passed}} == false"
        type: "bash"
        command: |
          set -euo pipefail
          
          working_dir="{{working_dir}}"
          version_file="$working_dir/versions/v3_quality.md"
          preserved_file="$working_dir/state/preserved_sections.json"
          content_map="$working_dir/state/existing_content_map.json"
          
          # Skip if no preserved sections file
          if [ ! -f "$preserved_file" ]; then
            echo "No preserved sections file - skipping restore"
            exit 0
          fi
          
          preserved_count=$(jq 'length' "$preserved_file")
          if [ "$preserved_count" -eq 0 ]; then
            echo "No preserved sections - skipping restore"
            exit 0
          fi
          
          # Skip if version file doesn't exist
          if [ ! -f "$version_file" ]; then
            echo "Version file not created yet - skipping restore"
            exit 0
          fi
          
          echo "Restoring $preserved_count preserved sections..."
          
          # Use Python to restore preserved sections
          python3 - "$version_file" "$content_map" "$preserved_file" << 'PYEOF'
          import json
          import re
          import sys
          
          version_file = sys.argv[1]
          content_map_path = sys.argv[2]
          preserved_file = sys.argv[3]
          
          # Read files
          with open(version_file, 'r') as f:
              doc_content = f.read()
          
          with open(content_map_path, 'r') as f:
              content_map = json.load(f)
          
          with open(preserved_file, 'r') as f:
              preserved_ids = json.load(f)
          
          def normalize_heading(heading):
              """Normalize heading for comparison."""
              return re.sub(r'^#+\s*', '', heading).strip().lower()
          
          def find_section_boundaries(content, heading):
              """Find the start and end positions of a section by its heading.
              
              Properly handles code blocks - doesn't treat # inside code blocks as headings.
              """
              lines = content.split('\n')
              normalized_target = normalize_heading(heading)
              
              start_idx = None
              start_level = None
              in_code_block = False
              
              for i, line in enumerate(lines):
                  # Track code block boundaries
                  if line.strip().startswith('```') or line.strip().startswith('~~~'):
                      in_code_block = not in_code_block
                      continue
                  
                  # Only treat as heading if NOT inside a code block
                  heading_match = re.match(r'^(#{1,6})\s+(.+)$', line) if not in_code_block else None
                  
                  if heading_match:
                      level = len(heading_match.group(1))
                      normalized = normalize_heading(line)
                      
                      if start_idx is None:
                          # Looking for start
                          if normalized == normalized_target:
                              start_idx = i
                              start_level = level
                      else:
                          # Looking for end (next heading of same or higher level)
                          if level <= start_level:
                              return start_idx, i
              
              # If we found start but no end, section goes to end of doc
              if start_idx is not None:
                  return start_idx, len(lines)
              
              return None, None
          
          restored_count = 0
          lines = doc_content.split('\n')
          
          # Process each preserved section (in reverse order to maintain indices)
          sections_to_restore = []
          for section_id in preserved_ids:
              mapping = content_map.get('section_mappings', {}).get(section_id, {})
              matching_heading = mapping.get('matching_heading', '')
              original_content = mapping.get('existing_content', '')
              
              if matching_heading and original_content:
                  start, end = find_section_boundaries(doc_content, matching_heading)
                  if start is not None:
                      sections_to_restore.append({
                          'section_id': section_id,
                          'heading': matching_heading,
                          'start': start,
                          'end': end,
                          'original': original_content
                      })
          
          # Sort by start position descending (so we can replace from bottom up)
          sections_to_restore.sort(key=lambda x: x['start'], reverse=True)
          
          for section in sections_to_restore:
              # Replace lines from start to end with original content
              original_lines = section['original'].split('\n')
              lines = lines[:section['start']] + original_lines + lines[section['end']:]
              restored_count += 1
              print(f"  Restored: {section['heading']}", file=sys.stderr)
          
          # Write restored content
          with open(version_file, 'w') as f:
              f.write('\n'.join(lines))
          
          print(f"Restored {restored_count} preserved sections")
          PYEOF
        output: "quality_restore_result"

      # Save v3 with quality fixes
      - id: "save-v3-quality"
        type: "bash"
        command: |
          set -euo pipefail
          
          version_file="{{working_dir}}/versions/v3_quality.md"
          prev_version="{{working_dir}}/versions/v2_content.md"
          
          # Three-way logic with size validation
          if [ "{{aggregated_quality_issues.all_passed}}" = "true" ] || [ "{{aggregated_quality_issues.all_passed}}" = "True" ]; then
            cp "$prev_version" "$version_file"
            echo "All quality checks passed - copied previous version"
          elif [ -f "$version_file" ]; then
            file_size=$(wc -c < "$version_file")
            prev_size=$(wc -c < "$prev_version")
            min_expected=$((prev_size / 2))
            
            if [ "$file_size" -lt "$min_expected" ]; then
              echo "WARNING: Agent wrote small file ($file_size < $min_expected bytes)" >&2
              cp "$prev_version" "$version_file"
            else
              echo "Agent wrote fixed version ($file_size bytes)"
            fi
          else
            echo "WARNING: Agent did not write fixed file, using previous" >&2
            cp "$prev_version" "$version_file"
          fi
          
          timestamp=$(date -Iseconds)
          if [ "{{aggregated_quality_issues.all_passed}}" = "true" ] || [ "{{aggregated_quality_issues.all_passed}}" = "True" ]; then
            passed_json="true"
          else
            passed_json="false"
          fi
          
          # Record all check results in tracker
          jq --arg ts "$timestamp" --arg file "$version_file" --argjson passed "$passed_json" \
             --argjson total "{{aggregated_quality_issues.total_issue_count}}" '
            .version_history += [{
              "version": "v3_quality",
              "stage": "validation-quality",
              "timestamp": $ts,
              "validation_passed": $passed,
              "issues_fixed": $total,
              "checks": ["depth", "coherence", "crossrefs", "consistency", "tone"],
              "file": $file
            }] |
            .validation_results.quality = {
              "passed": $passed,
              "checks_run": ["depth", "coherence", "crossrefs", "consistency", "tone"],
              "parallel": true
            }
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          echo "Saved v3_quality (all_passed: $passed_json, issues: {{aggregated_quality_issues.total_issue_count}})"
        output: "v3_saved"

  # ==========================================================================
  # STAGE 6: FINALIZATION
  # ==========================================================================
  - name: "finalization"
    approval:
      required: true
      prompt: |
        ALL VALIDATIONS COMPLETE
        
        {{v3_saved}}
        
        Validation Summary:
        - Structural: Completed
        - Content (parallel): accuracy + completeness + instructions
        - Quality (parallel): depth + coherence + crossrefs + consistency + tone
        
        Ready to finalize:
        1. Final verification pass
        2. Save to output path
        3. Generate summary report
        
        Approve to finalize and save.
      timeout: 0
      default: "deny"
    
    steps:
      - id: "final-quality-check"
        agent: "foundation:zen-architect"
        mode: "REVIEW"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
          - provider: azure
            model: gpt-4o
        prompt: |
          FINAL VERIFICATION of the document.
          
          Read the document from: {{working_dir}}/versions/v3_quality.md
          
          Do a complete read-through and verify:
          1. All validations addressed
          2. Ready for intended audience
          3. No obvious errors remain
          
          Return ONLY this JSON:
          {
            "ready": true/false,
            "final_issues": ["any remaining issues"],
            "quality_assessment": {
              "overall_score": "<1-10>",
              "strengths": ["..."],
              "areas_for_improvement": ["..."]
            },
            "recommendation": "publish|needs_more_work|major_revision_needed"
          }
        output: "final_check"
        parse_json: true
        timeout: 300

      # ========================================================================
      # DESIGN INTELLIGENCE FEEDBACK (Observational Only)
      # ========================================================================
      # These steps provide design perspective feedback for inclusion in the
      # final report. This is purely observational - no changes are made to
      # the document. The goal is to understand if DI feedback adds value.
      # ========================================================================

      - id: "di-voice-feedback"
        agent: "design-intelligence:voice-strategist"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
        prompt: |
          DESIGN INTELLIGENCE FEEDBACK: Voice & Tone Review
          
          You are providing OBSERVATIONAL FEEDBACK ONLY. Do NOT suggest fixes.
          Your feedback will be included in the final generation report to help
          understand if design intelligence perspective adds value to document review.
          
          Read the document from: {{working_dir}}/versions/v3_quality.md
          
          Provide feedback on these dimensions (from a voice strategist perspective):
          
          1. **Voice Consistency**
             - Is the voice/tone consistent throughout?
             - Does it match the apparent audience?
             - Are there shifts in formality or style?
          
          2. **Clarity of Messaging**
             - Are concepts explained clearly?
             - Is technical jargon appropriate for the audience?
             - Are there confusing or ambiguous passages?
          
          3. **Readability**
             - Is sentence structure varied and engaging?
             - Are paragraphs well-organized?
             - Does the document flow naturally?
          
          4. **Incidental Findings**
             - Note any contradictions or inconsistencies you observe
             - Flag any content that seems out of place
             - Highlight particularly effective passages
          
          IMPORTANT: This is feedback only. Do NOT rewrite or fix anything.
          
          Return ONLY this JSON:
          {
            "voice_consistency": {
              "score": "<1-10>",
              "observations": ["..."],
              "notable_sections": ["section names with issues or strengths"]
            },
            "clarity": {
              "score": "<1-10>",
              "observations": ["..."],
              "unclear_passages": ["brief descriptions"]
            },
            "readability": {
              "score": "<1-10>",
              "observations": ["..."]
            },
            "incidental_findings": ["any contradictions, dead content, or notable observations"],
            "overall_voice_assessment": "<brief summary of voice/tone quality>"
          }
        output: "di_voice_feedback"
        parse_json: true
        timeout: 300

      - id: "di-structure-feedback"
        agent: "design-intelligence:layout-architect"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
        prompt: |
          DESIGN INTELLIGENCE FEEDBACK: Information Architecture Review
          
          You are providing OBSERVATIONAL FEEDBACK ONLY. Do NOT suggest fixes.
          Your feedback will be included in the final generation report to help
          understand if design intelligence perspective adds value to document review.
          
          Read the document from: {{working_dir}}/versions/v3_quality.md
          
          Provide feedback on these dimensions (from a layout architect perspective):
          
          1. **Information Architecture**
             - Is the hierarchy clear and logical?
             - Are sections organized in a sensible order?
             - Is the depth of nesting appropriate?
          
          2. **Content Flow**
             - Does the document follow a clear narrative arc?
             - Are transitions between sections smooth?
             - Is there a logical progression of ideas?
          
          3. **Navigation & Wayfinding**
             - Would readers know where they are in the document?
             - Are section headings descriptive and helpful?
             - Is the structure predictable and scannable?
          
          4. **Incidental Findings**
             - Note any structural issues (orphaned sections, missing context)
             - Flag any content that seems misplaced
             - Highlight particularly effective organizational choices
          
          IMPORTANT: This is feedback only. Do NOT restructure or fix anything.
          
          Return ONLY this JSON:
          {
            "information_architecture": {
              "score": "<1-10>",
              "observations": ["..."],
              "hierarchy_issues": ["any issues with section hierarchy"]
            },
            "content_flow": {
              "score": "<1-10>",
              "observations": ["..."],
              "flow_breaks": ["sections where flow is disrupted"]
            },
            "navigation": {
              "score": "<1-10>",
              "observations": ["..."]
            },
            "incidental_findings": ["structural issues, misplaced content, notable observations"],
            "overall_structure_assessment": "<brief summary of structural quality>"
          }
        output: "di_structure_feedback"
        parse_json: true
        timeout: 300

      - id: "di-outline-feedback"
        agent: "design-intelligence:layout-architect"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
        prompt: |
          DESIGN INTELLIGENCE FEEDBACK: Outline Review
          
          You are providing OBSERVATIONAL FEEDBACK on the ORIGINAL OUTLINE that
          was used to generate this document. This helps understand if the outline
          itself had structural issues that propagated to the final document.
          
          Read the parsed outline from: {{working_dir}}/state/parsed_outline.json
          
          Provide feedback on the outline's information architecture:
          
          1. **Outline Structure**
             - Is the outline well-organized?
             - Are sections at appropriate hierarchy levels?
             - Is the scope appropriate for the document type?
          
          2. **Completeness Signals**
             - Are there obvious gaps in coverage?
             - Are any sections likely to be too thin or too dense?
             - Is the balance between sections reasonable?
          
          3. **Generation Readiness**
             - Was this outline sufficiently detailed for generation?
             - Were section prompts clear about expectations?
             - Were dependencies between sections clear?
          
          IMPORTANT: This is feedback only. The outline was already used.
          
          Return ONLY this JSON:
          {
            "outline_structure": {
              "score": "<1-10>",
              "observations": ["..."]
            },
            "completeness": {
              "score": "<1-10>",
              "observations": ["..."],
              "potential_gaps": ["areas that might be underspecified"]
            },
            "generation_readiness": {
              "score": "<1-10>",
              "observations": ["..."]
            },
            "overall_outline_assessment": "<brief summary of outline quality>"
          }
        output: "di_outline_feedback"
        parse_json: true
        timeout: 300

      - id: "save-di-feedback"
        type: "bash"
        command: |
          set -euo pipefail
          
          timestamp=$(date -Iseconds)
          
          # Write JSON values to temp files to avoid bash quoting issues
          cat > "{{working_dir}}/state/tmp_voice.json" << 'VOICE_EOF'
          {{di_voice_feedback}}
          VOICE_EOF
          
          cat > "{{working_dir}}/state/tmp_structure.json" << 'STRUCTURE_EOF'
          {{di_structure_feedback}}
          STRUCTURE_EOF
          
          cat > "{{working_dir}}/state/tmp_outline.json" << 'OUTLINE_EOF'
          {{di_outline_feedback}}
          OUTLINE_EOF
          
          # Combine using jq with slurpfile (reads JSON from files safely)
          jq -n --arg ts "$timestamp" \
             --slurpfile voice "{{working_dir}}/state/tmp_voice.json" \
             --slurpfile structure "{{working_dir}}/state/tmp_structure.json" \
             --slurpfile outline "{{working_dir}}/state/tmp_outline.json" '
            {
              "timestamp": $ts,
              "purpose": "Design Intelligence observational feedback for document generation",
              "note": "This feedback is purely observational - no changes were made based on it",
              "voice_feedback": $voice[0],
              "structure_feedback": $structure[0],
              "outline_feedback": $outline[0]
            }
          ' > "{{working_dir}}/state/di_feedback.json"
          
          # Clean up temp files
          rm -f "{{working_dir}}/state/tmp_voice.json" \
                "{{working_dir}}/state/tmp_structure.json" \
                "{{working_dir}}/state/tmp_outline.json"
          
          echo "Design Intelligence feedback saved to {{working_dir}}/state/di_feedback.json"
        output: "di_feedback_saved"

      # ========================================================================
      # END DESIGN INTELLIGENCE FEEDBACK
      # ========================================================================

      - id: "determine-output-path"
        type: "bash"
        command: |
          set -euo pipefail
          
          if [ -n "{{output_path}}" ]; then
            printf '%s' "{{output_path}}"
          else
            target_path=$(jq -r '.document.output // "output.md"' "{{working_dir}}/state/parsed_outline.json")
            filename=$(basename "$target_path")
            printf '%s' "temp/$filename"
          fi
        output: "final_output_path"

      - id: "create-output-directory"
        type: "bash"
        command: |
          set -euo pipefail
          mkdir -p "$(dirname "{{final_output_path}}")"
          echo "Output directory ready"
        output: "output_dir_ready"

      - id: "save-final-document"
        type: "bash"
        command: |
          set -euo pipefail
          
          cp "{{working_dir}}/versions/v3_quality.md" "{{final_output_path}}"
          
          echo "Final document saved to {{final_output_path}}"
        output: "final_doc_saved"

      - id: "save-v-final-version"
        type: "bash"
        command: |
          set -euo pipefail
          
          cp "{{final_output_path}}" "{{working_dir}}/versions/v_final.md"
          echo "v_final saved to {{working_dir}}/versions/v_final.md"
        output: "v_final_saved"

      - id: "update-tracker-complete"
        type: "bash"
        command: |
          set -euo pipefail
          
          timestamp=$(date -Iseconds)
          jq --arg ts "$timestamp" \
             --arg output_path "{{final_output_path}}" \
             --arg file "{{working_dir}}/versions/v_final.md" '
            .status = "complete" |
            .completed_at = $ts |
            .current_stage = "finalization" |
            .output_path = $output_path |
            .version_history += [{
              "version": "v_final",
              "stage": "finalization",
              "timestamp": $ts,
              "file": $file,
              "output_path": $output_path
            }]
          ' "{{working_dir}}/state/tracker.json" > "{{working_dir}}/state/tracker.json.tmp" \
            && mv "{{working_dir}}/state/tracker.json.tmp" "{{working_dir}}/state/tracker.json"
          
          echo "Tracker updated: status=complete"
        output: "tracker_complete"

      - id: "read-final-tracker"
        type: "bash"
        command: |
          cat "{{working_dir}}/state/tracker.json"
        output: "final_tracker"
        parse_json: true

      - id: "generate-summary-report"
        agent: "foundation:zen-architect"
        mode: "ANALYZE"
        provider_preferences:
          - provider: anthropic
            model: claude-sonnet-*
          - provider: openai
            model: gpt-4o
        prompt: |
          Generate a summary report of the document generation process.
          
          Read:
          - Tracker: {{working_dir}}/state/tracker.json
          - Parsed outline: {{working_dir}}/state/parsed_outline.json
          - DI Feedback (v0): {{working_dir}}/state/di_v0_feedback.json
          - DI Feedback (final): {{working_dir}}/state/di_feedback.json
          
          Final quality check results:
          - Ready: {{final_check.ready}}
          - Recommendation: {{final_check.recommendation}}
          - Score: {{final_check.quality_assessment.overall_score}}
          
          Output path: {{final_output_path}}
          
          Include:
          
          1. **Document Generated**
             - Title, sections, output path
          
          2. **Process Summary**
             - Time taken
             - Sources fetched
             - Stages completed
          
          3. **Validation Results**
             - Parallel validation phases used
             - Content checks (accuracy, completeness, instructions)
             - Quality checks (depth, coherence, crossrefs, consistency, tone)
             - Issues found and fixed
          
          4. **Version History**
             - v0_generated, v1_structural, v2_content, v3_quality, v_final
          
          5. **Quality Assessment**
             - Overall score
             - Strengths and improvements
          
          6. **Design Intelligence Feedback** (EXPERIMENTAL)
             This section contains observational feedback from Design Intelligence
             agents. This feedback was NOT used to modify the document - it is
             included here to evaluate whether DI perspective adds value.
             
             **6.1 Initial Generation Feedback (v0)**
             Include from di_v0_feedback.json - this is feedback on the RAW generated
             document BEFORE any validation fixes were applied:
             
             - Voice & Tone (v0): scores and key observations
             - Structure & IA (v0): scores and key observations
             - Notable issues identified in the initial generation
             
             **6.2 Final Document Feedback (v3)**
             Include from di_feedback.json - this is feedback on the FINAL document
             AFTER all validation passes:
             
             **Voice & Tone Feedback** (from voice-strategist):
             - Voice consistency score and observations
             - Clarity score and observations
             - Readability score and observations
             - Overall voice assessment
             - Any incidental findings (contradictions, dead content, etc.)
             
             **Structure & IA Feedback** (from layout-architect):
             - Information architecture score and observations
             - Content flow score and observations
             - Navigation/wayfinding score and observations
             - Overall structure assessment
             - Any incidental findings
             
             **Outline Quality Feedback** (from layout-architect):
             - Outline structure score and observations
             - Completeness signals
             - Generation readiness assessment
             
             **6.3 v0 → v3 Comparison** (CRITICAL FOR EVALUATION)
             Compare the v0 and v3 feedback to understand:
             - Which issues identified in v0 were addressed by validation?
             - Which issues persisted through validation?
             - Did validation introduce any new concerns?
             - Score changes: Show before/after scores for each dimension
             
             **6.4 DI Feedback Summary**:
             Provide a brief assessment of:
             - Whether DI feedback revealed anything the validation pipeline missed
             - Whether the v0→v3 comparison shows validation effectiveness
             - Overall value of including DI perspective in document generation
          
          IMPORTANT: Write the report to:
          {{working_dir}}/generation_report.md
          
          Return: {"report_saved": true, "output_file": "generation_report.md"}
        output: "report_result"
        parse_json: true
        timeout: 300

      - id: "print-completion-summary"
        type: "bash"
        command: |
          set -euo pipefail
          
          echo ""
          echo "=== DOCUMENT GENERATION COMPLETE (Parallel Validation) ==="
          echo ""
          echo "Output: {{final_output_path}}"
          echo "Report: {{working_dir}}/generation_report.md"
          echo ""
          
          jq -r '"Sections: \(.sections_completed | length)\nVersions: \(.version_history | length)\nStarted: \(.started_at // "unknown")\nCompleted: \(.completed_at // "unknown")"' \
            "{{working_dir}}/state/tracker.json"
          
          echo ""
          echo "Validation approach: PARALLEL"
          echo "- Content phase: accuracy + completeness + instructions (parallel)"
          echo "- Quality phase: depth + coherence + crossrefs + consistency + tone (parallel)"
          echo ""
          cat "{{working_dir}}/generation_report.md"
        output: "completion_message"

# ==========================================================================
# OUTPUT SUMMARY
# ==========================================================================
#
# After successful execution:
#
# Working directory ({{working_dir}}):
#   state/
#     outline.json              - Raw outline (copied from input)
#     parsed_outline.json       - Parsed structure from agent
#     source_manifest.json      - Sources to fetch
#     structure.json            - Section relationships, BFS order
#     sources_result.json       - Result of source fetching
#     tracker.json              - Full state (supports resumability)
#     content_check_results.json - Parallel content check results
#     quality_check_results.json - Parallel quality check results
#     di_v0_feedback.json        - DI feedback on v0 (before validation)
#     di_feedback.json          - DI feedback on v3 (after validation)
#     has_existing_document     - Flag: "true" if existing doc was provided
#     existing_document.md      - Copy of existing doc (if provided)
#     existing_content_map.json - Section mappings from existing doc (if provided)
#   sources/
#     <files>                   - Fetched source files
#   versions/
#     v0_generated.md           - Initial generation
#     v1_structural.md          - After structural validation
#     v2_content.md             - After content validation (parallel)
#     v3_quality.md             - After quality validation (parallel)
#     v_final.md                - Final version
#   generation_report.md        - Summary report
#
# Resumability:
#   If interrupted, re-run same command. The recipe will:
#   - Detect existing tracker.json
#   - Skip completed sections
#   - Resume from last incomplete stage
#
# Performance:
#   - ~30-40% faster than sequential validation
#   - Content checks run in parallel (3 concurrent)
#   - Quality checks run in parallel (5 checks, 3 concurrent via rate_limiting)
#
# ==========================================================================
