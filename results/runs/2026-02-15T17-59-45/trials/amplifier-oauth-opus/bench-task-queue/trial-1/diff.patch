diff --git a/.amplifier-stdout.log b/.amplifier-stdout.log
new file mode 100644
index 0000000..95add66
--- /dev/null
+++ b/.amplifier-stdout.log
@@ -0,0 +1,1511 @@
+Preparing bundle 'foundation'...
+Bundle 'foundation' prepared successfully
+
+Session ID: abdc0228-5d1c-42a2-b1d5-64e38303ab72
+Bundle: foundation | Provider: Anthropic | claude-opus-4-6
+
+[90m============================================================[0m
+[90mThinking:[0m
+[90m------------------------------------------------------------[0m
+[2mThe user wants me to build a fully-featured in-memory task  
+queue system in TypeScript, growing through 12 phases. Let  
+me start by exploring the project structure to understand   
+what's already there, then plan and implement each phase.   
+
+Let me first explore the workspace to understand the        
+structure, then read all the phase requirements.[0m
+[90m============================================================[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 37,263 (96% cached) | Output: 593 | Total: 37,856[0m
+
+[36mğŸ”§ Using tool: todo[0m
+   [2maction: create[0m
+   [2mtodos:[0m
+   [2m- content: Explore project structure and read all phase requirements[0m
+   [2m  status: in_progress[0m
+   [2m  activeForm: Exploring project structure and reading requirements[0m
+   [2m... (39 more lines)[0m
+[36mâœ… Tool result: todo[0m
+[2m   status: created
+   count: 14
+   todos:
+   - content: Explore project structure and read all phase requirements
+     status: in_progress
+   ... (40 more lines)[0m
+
+
+[2;37mâ”Œâ”€ Todo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [1;36mâ–¶[0m [1;36mExploring project structure and reading requirements[0m     [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 1: Basic Queue[0m                                     [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 2: Named Queues[0m                                    [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 3: Priority[0m                                        [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 4: Delayed Tasks[0m                                   [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 5: Retry with Backoff[0m                              [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 6: Dead Letter Queue[0m                               [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 7: Task Dependencies[0m                               [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 8: Concurrency Control[0m                             [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 9: Progress and Cancellation[0m                       [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 10: Recurring Tasks[0m                                [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 11: Middleware[0m                                     [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mPhase 12: Graceful Shutdown[0m                              [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mFinal validation - build, lint, and comprehensive testiâ€¦[0m [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [32m[0m[2;37mâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘[0m 0/14                              [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[0m
+
+[38;5;110mâ–¸[0m [38;5;188mLet me start by exploring the project structure and reading [0m
+  [38;5;188mall the phase requirements.[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 38,467 (93% cached) | Output: 87 | Total: 38,554[0m
+
+[36mğŸ”§ Using tool: glob[0m
+   [2mpattern: **/*[0m
+   [2mpath: /workspace[0m
+[36mâœ… Tool result: glob[0m
+[2m   pattern: **/*
+   base_path: /workspace
+   total_files: 26
+   count: 26
+   matches:
+   ... (78 more lines)[0m
+
+
+[38;5;110mâ–¸[0m [38;5;188mLet me read all the phase requirements and config files in  [0m
+  [38;5;188mparallel.[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 39,241 (91% cached) | Output: 816 | Total: 40,057[0m
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-01.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-01.md
+   content: |
+            1	# Phase 1: Basic FIFO Queue
+            2	
+            3	Implement the core of the task queue: the ability to add tasks and retrieve them in first-in, first-out order.
+   ... (12 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-02.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-02.md
+   content: |
+            1	# Phase 2: Named Queues
+            2	
+            3	Extend the system to support multiple independent queues, each identified by a name.
+   ... (13 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-03.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-03.md
+   content: |
+            1	# Phase 3: Priority
+            2	
+            3	Add priority support so that more urgent tasks are processed before less urgent ones.
+   ... (12 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-04.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-04.md
+   content: |
+            1	# Phase 4: Delayed and Scheduled Tasks
+            2	
+            3	Add the ability to defer tasks so they only become available for processing after a specified time.
+   ... (12 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-05.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-05.md
+   content: |
+            1	# Phase 5: Retry with Backoff
+            2	
+            3	Add automatic retry functionality so that failed tasks can be re-attempted with increasing delays.
+   ... (14 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-06.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-06.md
+   content: |
+            1	# Phase 6: Dead Letter Queue
+            2	
+            3	Add a dead letter queue (DLQ) to capture tasks that have permanently failed after exhausting all retries.
+   ... (12 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-07.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-07.md
+   content: |
+            1	# Phase 7: Task Dependencies
+            2	
+            3	Add the ability for tasks to declare dependencies on other tasks, so they only become available once their prerequisites are done.
+   ... (13 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-08.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-08.md
+   content: |
+            1	# Phase 8: Concurrency Control
+            2	
+            3	Add per-queue limits on how many tasks can be processed at the same time.
+   ... (12 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-09.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-09.md
+   content: |
+            1	# Phase 9: Progress Tracking and Cancellation
+            2	
+            3	Add the ability to report progress on running tasks and to cancel tasks.
+   ... (14 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-10.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-10.md
+   content: |
+            1	# Phase 10: Recurring Tasks
+            2	
+            3	Add the ability to schedule tasks that recur on a regular interval using simple cron-like expressions.
+   ... (15 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-11.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-11.md
+   content: |
+            1	# Phase 11: Middleware Pipeline
+            2	
+            3	Add a middleware system that can intercept and transform tasks as they are processed.
+   ... (14 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/phases/phase-12.md[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/phases/phase-12.md
+   content: |
+            1	# Phase 12: Graceful Shutdown
+            2	
+            3	Add the ability to shut down the task queue system in an orderly fashion.
+   ... (14 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/package.json[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/package.json
+   content: |
+            1	{
+            2	  "name": "bench-task-queue",
+            3	  "version": "1.0.0",
+   ... (20 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/tsconfig.json[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/tsconfig.json
+   content: |
+            1	{
+            2	  "compilerOptions": {
+            3	    "target": "ES2022",
+   ... (19 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/.eslintrc.cjs[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/.eslintrc.cjs
+   content: |
+            1	module.exports = {
+            2	  parser: '@typescript-eslint/parser',
+            3	  plugins: ['@typescript-eslint'],
+   ... (16 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/vitest.config.ts[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/vitest.config.ts
+   content: |
+            1	import { defineConfig } from 'vitest/config';
+            2	
+            3	export default defineConfig({
+   ... (8 more lines)[0m
+
+
+[36mğŸ”§ Using tool: read_file[0m
+   [2mfile_path: /workspace/src[0m
+[36mâœ… Tool result: read_file[0m
+[2m   file_path: /workspace/src
+   content: |
+       Directory: /workspace/src
+       
+         FILE .gitkeep
+   ... (2 more lines)[0m
+
+
+[90m============================================================[0m
+[90mThinking:[0m
+[90m------------------------------------------------------------[0m
+[2mNow I have a complete understanding of all 12 phases. Let me
+plan the architecture carefully before implementing, since  
+later phases will force rethinking early decisions. Let me  
+design with extensibility in mind.                          
+
+Key design decisions:                                       
+
+ 1 Task object needs: id (UUID), status, createdAt, payload,
+   priority, queue name, delay/availableAt, retry info,     
+   dependencies, progress, metadata                         
+ 2 TaskQueue class manages named queues internally          
+ 3 Need to think about how all features interact            
+
+Let me design the full system architecture and then         
+implement it. Given the complexity, I'll implement this as a
+well-structured set of modules.                             
+
+Architecture:                                               
+
+ â€¢ src/types.ts - All type definitions                      
+ â€¢ src/task.ts - Task class/creation                        
+ â€¢ src/queue.ts - Individual queue logic                    
+ â€¢ src/scheduler.ts - Cron/recurring tasks                  
+ â€¢ src/middleware.ts - Middleware pipeline                  
+ â€¢ src/TaskQueueSystem.ts - Main system coordinating        
+   everything                                               
+ â€¢ src/index.ts - Public API exports                        
+
+Now I'm thinking through the data model for tasks, starting 
+with the core fields like id, status, payload, timestamps,  
+and priority.                                               
+
+For the task schema itself, I need to account for retry     
+logic with maxRetries and retryCount, delayed execution via 
+availableAt, dependency tracking, progress reporting, and   
+flexible metadata storage.                                  
+
+When retrieving tasks from the queue, I should filter for   
+pending status first, exclude delayed tasks that aren't     
+ready yet, skip any with unresolved dependencies, then order
+by priority level followed by creation time for FIFO        
+ordering within the same priority tier, and finally respect 
+concurrency limits.                                         
+
+For delayed tasks that become available, the ordering should
+prioritize availableAt timestamp first, then fall back to   
+priority, then FIFOâ€”though I'm reconsidering whether        
+priority should actually take precedence since once a       
+delayed task becomes available it should probably be treated
+the same as non-delayed tasks.                              
+
+Let me reconsider the spec more carefully: all available    
+tasks (whether non-delayed or delayed tasks that have passed
+their availability time) should be sorted by priority first,
+then by their availableAt or createdAt timestamp, then by   
+FIFO order. Hmm, but the phase says "availability time, then
+priority, then FIFO". That means availability time takes    
+precedence over priority for delayed tasks. But that seems  
+like it would conflict with priority...                     
+
+Let me just implement it as: priority first, then           
+availableAt, then FIFO (createdAt). This is the most natural
+interpretation. The phase 4 wording about "availability     
+time, then priority" might be specifically about ordering   
+among delayed tasks that are becoming available at the same 
+time.                                                       
+
+Actually, I'll re-read: "When multiple delayed tasks become 
+available simultaneously, they should be ordered by         
+availability time, then priority, then FIFO."               
+
+I think this is only about delayed tasks competing among    
+themselves, not delayed versus non-delayed. So the overall  
+ordering should be: priority across all tasks, then for     
+same-priority tasks, use createdAt for non-delayed and      
+availableAt for delayed tasks, with insertion order as a    
+final tiebreaker.                                           
+
+I'll use a sequence number for true FIFO ordering to avoid  
+createdAt ties. Now I need to implement the full system.    
+I'll organize it into a few files: types, the main          
+TaskQueueSystem class, and an index for re-exports.         
+
+Defining the type system... Defining the schedule and       
+shutdown interfaces...                                      
+
+Now I'm thinking through the TaskQueueSystem architectureâ€”I 
+need internal data structures to track pending tasks per    
+queue, a global task registry by ID, dead letter queues,    
+concurrency limits, middleware, handlers, progress          
+listeners, and schedules. For retrieving tasks efficiently, 
+a simple sorted scan works fine since this is in-memory and 
+shouldn't grow too large. I'm sketching out the class       
+structure with maps for tasks, queues, and dead letter      
+queues...                                                   
+
+Building the class structure...                             
+
+Actually, I'm reconsidering whether I need a separate array 
+for pending tasksâ€”maybe I should consolidate the storage    
+approach.                                                   
+
+I'm thinking through the core operations I need: adding     
+tasks to a queue, retrieving the next available task with   
+proper filtering and sorting, marking tasks as complete or  
+failed, and managing concurrency limits. A simpler design   
+would store all tasks in a single Map and maintain just task
+IDs per queue, then filter and sort on retrieval. Even      
+though this is O(n) per lookup, it's acceptable for         
+in-memory queue sizes and avoids the complexity of keeping  
+multiple data structures in sync.                           
+
+Let me implement this approach.                             
+
+Setting up the class structure... Still writing task        
+initialization... Still writing task scheduling logic...    
+Writing task completion logic... Writing task queue         
+methods... Writing queue management methods...              
+
+I'm realizing the circular dependency check is tricky since 
+we're validating a new task before it's added to the        
+mapâ€”nothing can depend on it yet, so I need to verify that  
+the new task's dependencies don't form a cycle back through 
+existing tasks. ]), and now we add Task C that depends on A.
+There's no cycle here since each task can only depend on    
+previously created tasks, which should make cycles          
+impossibleâ€”but the spec explicitly asks for cycle detection,
+so maybe it's a safeguard or there's an edge case I'm       
+missing. Let me implement the check anyway: I'll traverse   
+the dependency graph from the new task and see if we ever   
+loop back to it, though theoretically that shouldn't happen 
+since the new task isn't in the map yet. Implementing cycle 
+detection...                                                
+
+Now I need to handle the dependency status retrieval, which 
+will check how many of a task's dependencies are completed  
+versus still pending. Still writing task management         
+methods... Writing task management methods... Writing the   
+scheduler tick logic... Still writing cron parser...        
+Building the middleware chain...                            
+
+Now I'm setting up the shutdown lifecycleâ€”registering       
+callbacks that can run during shutdown, then implementing   
+the actual shutdown sequence that executes all registered   
+callbacks within a timeout window.                          
+
+I'm checking for any tasks still in progress and waiting for
+them to complete, with a timeout mechanism that polls every 
+50 milliseconds to see if processing has finished.          
+
+Now I'm counting how many of those originally processing    
+tasks have reached a terminal state, then force-cancelling  
+any that are still stuck in progress and returning the final
+counts along with elapsed time. But wait, I need to         
+reconsider what "skipped" actually means in the middleware  
+contextâ€”if middleware doesn't call next, does that mean the 
+task never reaches completion, or does it get marked as     
+skipped?                                                    
+
+Let me think through this more carefully. When processTask  
+runs, it takes a task already in processing state, runs it  
+through the middleware chain, and executes the handler at   
+the end. If middleware short-circuits by not calling next,  
+the handler never runs, but the task itself could still be  
+completed or failed by the middleware, or it could remain in
+processing state depending on what the middleware does.     
+
+For the retry logic in Phase 5, when a task fails I need to 
+check if retryCount is still below maxRetriesâ€”if so, reset  
+it back to pending with a backoff delay applied, otherwise  
+it's permanently failed.                                    
+
+Looking at the spec more carefully, "default maximum number 
+of retries is 3" with exponential backoff means 3 retry     
+attempts after the original attempt, so 4 total attempts.   
+The delay formula baseDelay * 2^(attempt - 1) gives me      
+baseDelay on the first retry, then 2baseDelay, then         
+4baseDelay. After those 3 retries are exhausted, the task   
+goes to the DLQ.                                            
+
+In my implementation, I'm incrementing retryCount before    
+checking if it's still less than maxRetriesâ€”so with         
+maxRetries=3, the first failure increments to 1 and retries 
+with a 1000ms delay, the second failure goes to 2 and       
+retries with 2000ms delay, the third failure goes to 3 and  
+stops retrying since 3 is not less than 3, sending it to the
+DLQ.                                                        
+
+But that gives only 2 retries when maxRetries=3 suggests 3  
+retries should happen. I think I need to reconsider what    
+retryCount actually representsâ€”whether it's the number of   
+retry attempts made so far, or the total number of          
+processing attempts including the original one. I'm settling
+on using retryCount to track how many times a task has been 
+retried, starting at zero, and comparing it against         
+maxRetries to decide whether to retry or send to the dead   
+letter queue. For the exponential backoff, I'm using the    
+formula baseDelay * 2^(attempt - 1) where attempt is        
+1-indexed, so the first attempt gets no delay multiplier,   
+the second gets doubled, and so on. maxRetries=3, after 3   
+retries, DLQ.                                               
+
+So I'll track retryCount (starts at 0). When a task fails:  
+
+ 1 If retryCount < maxRetries:                              
+    â€¢ delay = baseDelay * 2^retryCount                      
+    â€¢ retryCount++                                          
+    â€¢ Set to pending with delay                             
+ 2 Else: DLQ                                                
+
+ â€¢ Fail 1: retryCount=0, 0 < 3, delay=1000*2^0=1000,        
+   retryCount becomes 1                                     
+ â€¢ Fail 2: retryCount=1, 1 < 3, delay=1000*2^1=2000,        
+   retryCount becomes 2                                     
+ â€¢ Fail 3: retryCount=2, 2 < 3, delay=1000*2^2=4000,        
+   retryCount becomes 3                                     
+ â€¢ Fail 4: retryCount=3, 3 < 3 = false, DLQ                 
+
+So 3 retries plus the original attempt gives 4 total        
+attempts. For tracking attempts, I can just expose          
+retryCount where total attempts equals retryCount + 1. I    
+could also track attempts directly instead, incrementing on 
+each failure and checking if attempts < maxRetries + 1      
+before retrying, but retryCount is cleaner.                 
+
+Actually, let me simplify: I'll use retryCount to track     
+retries performed, and when a task fails, I check if        
+retryCount < maxRetries. If so, increment retryCount,       
+calculate the exponential backoff delay, and re-queue.      
+Otherwise, send to DLQ.                                     
+
+This gives exactly maxRetries retries plus the original     
+attempt. The backoff formula baseDelay * 2^retryCount       
+produces the right delays: 1000ms, 2000ms, 4000ms for       
+retries 0, 1, 2.                                            
+
+Cancelled tasks skip failTask entirely, so they're never    
+retried. Now I need to think through the progress updates   
+mechanism for Phase 9.                                      
+
+For shutdown in Phase 12, the tricky part is that tasks are 
+processed externallyâ€”the caller fetches them via            
+getNextTask, does the work, then reports back. So shutdown  
+has to wait for those external processes to complete, with a
+timeout that force-cancels anything still running.          
+
+On the API design side, I'm debating how to handle the      
+internal _seq field on Task objects. Using a plain property 
+works but feels unclean. A WeakMap approach would keep the  
+API cleaner, though it adds complexity.                     
+
+For the file structure, I'm thinking of splitting this into 
+separate modules for types, cron parsing, the main          
+TaskQueueSystem class, and the public exports. That keeps   
+things organized and makes the API cleaner. I need to be    
+careful about what gets exposed versus what stays internal. 
+
+I'm realizing that when tasks are returned to callers, they 
+get direct references to the same objects, so any status    
+updates are immediately visible to them. This could be a    
+concern for encapsulation, but it's actually convenient for 
+the caller, so I'll keep it simple and go with that         
+approach.                                                   
+
+Defining the core types now... Defining the schedule and    
+shutdown interfaces...                                      
+
+Actually, I'm overcomplicating thisâ€”let me just write the   
+full implementation. The readonly modifiers won't actually  
+prevent mutations since I need to mutate internally, so I'll
+use a regular interface or class instead. I think the       
+cleanest approach is to have an internal task type with all 
+fields including the sequence number, then expose an        
+external Task type that omits it, returning the same objects
+but typed as the public interface. For the cron parsing, I  
+only need to support three patterns: every N minutes, every 
+hour, and daily.                                            
+
+Now I need to implement the tick() method to check if the   
+current time has passed the next scheduled run, enqueue the 
+task if so, and recalculate the next run time. For          
+getNextCronTime(), I need to handle each pattern            
+carefullyâ€”finding the next minute boundary where the cron   
+should fire, the next hour at :00, or the next midnight. The
+tricky part is making sure that if the current time is      
+exactly on a boundary where the cron should fire, the next  
+occurrence is actually the next one, not the current time   
+itself.                                                     
+
+I'm also noticing a potential conflict in the task ordering 
+requirements. Phase 4 says delayed tasks should be ordered  
+by availability time first, then priority, but phase 3      
+established priority ordering for the general case. I think 
+the resolution is that non-delayed tasks follow             
+priority-then-FIFO ordering, while delayed tasks use        
+availability-time-then-priority-then-FIFO, with non-delayed 
+tasks taking precedence overall.                            
+
+Writing the implementation...                               
+
+Actually, thinking through this more carefully: once a      
+delayed task becomes available, it should compete equally   
+with non-delayed tasks based on priority. The availability  
+time ordering is really just for breaking ties among delayed
+tasks that became available at different times. So the      
+cleanest approach is to filter for available tasks, sort by 
+priority, then by availability time, then by creation       
+orderâ€”this naturally handles both delayed and non-delayed   
+tasks correctly. I need to reconsider the ordering rules    
+from phase 4 - it explicitly states that for delayed tasks, 
+availability time takes precedence over priority, which is  
+different from what I initially thought. The spec is clear  
+that when multiple delayed tasks become available, they're  
+ordered by availableAt first, then priority, then FIFO, so I
+should follow that specific ordering for delayed tasks      
+rather than applying a general priority-first rule across   
+all task types. I'm realizing the practical difference: if I
+process tasks after a long delay, should I prioritize the   
+one that's been waiting longest (availableAt first) or the  
+one with highest priority? The availableAt-first approach   
+seems fairer since it respects the original scheduling      
+intentâ€”a task meant to run at 3 seconds shouldn't be delayed
+just because a higher-priority task was scheduled for later.
+
+So I need to reconcile this with the phase 3 behavior where 
+priority comes first for immediately available tasks. The   
+cleanest solution is to sort by priority as the primary key,
+then availableAt as secondary, then sequence number for FIFO
+orderingâ€”this keeps priority as the main feature while      
+letting availableAt act as a tiebreaker for delayed tasks   
+that often share the same default priority. I'm realizing   
+the phase 4 statement about "availability time, then        
+priority, then FIFO" only applies when comparing delayed    
+tasks at the same priority levelâ€”priority itself must remain
+the primary sort key across all tasks, otherwise it         
+contradicts phase 3's core requirement.                     
+
+So the correct ordering is priority first, then availability
+time for same-priority tasks, then sequence number for      
+tiebreaking. Now I need to implement this, but I'm also     
+thinking through the cron logic for */N intervalsâ€”when      
+calculating the next occurrence from a given timestamp, I   
+need to handle the case where we're already at a boundary   
+(like minute 0) and ensure we advance to the actual next    
+interval rather than staying at the current time. Writing   
+the cron parser... Finishing the cron parsing logic for     
+midnight boundaries, then realizing there's a potential     
+issue with how JavaScript's Date object handles minute      
+rollovers at the 59-minute markâ€”it should automatically     
+advance to the next hour, which is good, but I need to      
+verify the edge case where the from timestamp might already 
+be past the calculated time.                                
+
+When a schedule is initialized at time T, the first nextRun 
+should be strictly after T, so if from lands exactly on a   
+matching boundary (like 12:05:00 for a */5 cron), we        
+correctly skip to 12:10. This ensures tasks only run once   
+per interval.                                               
+
+Now I'm thinking through how cancelTask interacts with      
+failTaskâ€”the spec says cancelled tasks should never be      
+retried, so I need to make sure that once a task is         
+cancelled, it's removed from any retry queue.               
+
+For the shutdown implementation, I need to figure out how   
+the system knows when all processing tasks are complete,    
+since the work happens externally through getNextTask,      
+completeTask, and failTask calls.                           
+
+The shutdown process would set a flag to prevent new tasks, 
+wait for all currently processing tasks to finish within a  
+timeout window, force-cancel anything still in progress, and
+return a summary of what happened.                          
+
+Now I'm writing out the complete implementation with clean  
+type definitions, the main task queue class, and the        
+exports. I'm also reconsidering the processTask convenience 
+method from earlierâ€”it should probably automatically call   
+completeTask when the middleware pipeline succeeds, so the  
+user doesn't have to handle that manually.                  
+
+Actually, let me reconsider whether auto-completing makes   
+sense. The spec doesn't explicitly require it, and the      
+handler itself might already be completing the task. I think
+it's better to let the handler or middleware decide when to 
+complete, rather than having processTask do it              
+automatically.                                              
+
+But then there's an asymmetryâ€”errors get auto-failed by     
+processTask, so success should probably auto-complete for   
+consistency. The real issue is handling the case where      
+middleware doesn't call next, which would skip the handler  
+entirely. I need a way to track whether the pipeline        
+actually completed fully versus being interrupted.          
+
+Implementing a completion flag...                           
+
+Still writing task processing logic...                      
+
+Actually, I need to reconsider the auto-completion behavior.
+The spec says errors should fail automatically, but I'm not 
+sure completion should work the same wayâ€”maybe the handler  
+needs to explicitly mark tasks as done. Let me check what   
+the spec actually says about handler responsibilities.      
+
+Reading more carefully, the handler is the final step after 
+all middleware run, so if it completes successfully, the    
+task should be marked as completed. If middleware skips     
+calling next, the task stays in processing state for the    
+caller to handle. If there's an error anywhere, it          
+auto-fails.                                                 
+
+Now I'm ready to implement this. One more thing about the   
+dead-letter queueâ€”I need to preserve the error information  
+and track how many times a task failed (the retry count),   
+then make sure dead-lettered tasks can be moved back into   
+the queue.                                                  
+
+When moving a task back from the DLQ, I'll reset the retry  
+count to 0 and restore the original max retries so it gets a
+fresh round of attempts.                                    
+
+I'm going to write this as a single class in                
+TaskQueueSystem.ts with types separated into types.ts and   
+exports in index.ts. I also need to handle skipping tasks   
+with cancelled status when getNextTask is called, and for   
+tasks with dependencies, I'll just check if dependencies are
+met at retrieval time rather than proactively managing them.
+
+Writing the complete implementation... Now I'm thinking     
+through what to export from the main entry pointâ€”the        
+TaskQueueSystem class and all the type definitions. I need  
+to make sure the imports use .js extensions since I'm using 
+Node16 module resolution. Let me write out the full         
+implementation now, starting with the types and then the    
+main system class, followed by comprehensive tests.         
+
+Defining the types and implementation... Defining the main  
+TaskQueueSystem class... I'm defining the TaskQueueSystem   
+class with a method to add tasks, checking for shutdown     
+state and validating priority levels before calculating the 
+availability time based on any specified delay.             
+
+Still writing task initialization... Writing task scheduling
+logic... Continuing with the failure handling logic...      
+
+Now I'm implementing the retry mechanism with exponential   
+backoffâ€”if retries remain, the task goes back to pending    
+with a calculated delay, otherwise it's marked as failed and
+moved to the dead letter queue.                             
+
+Implementing dead letter queue retrieval and retry logic... 
+Writing task queue methods... Writing task management       
+methods... Writing the schedule management methods... Still 
+writing task processing logic...                            
+
+Now I'm moving into the shutdown phase, setting up callbacks
+and a graceful shutdown mechanism that tracks whether the   
+system is currently shutting down and returns a promise to  
+handle the async shutdown process.                          
+
+Defining helper methods... I'm implementing the dead letter 
+queue logic to store failed tasks, then moving into cron    
+expression parsing to handle different scheduling patterns  
+like interval-based, hourly, and daily tasks. Writing cron  
+scheduling logic... Writing shutdown logic...               
+
+Now I'm checking the cron scheduling, specifically the      
+hourly caseâ€”there might be an issue with how the next       
+execution time is being calculated. Let me trace through    
+another scenario where the input is 12:59 to verify the     
+logic holds up. Now checking the hourly case where the      
+condition is trueâ€”when the current time equals the boundary,
+I increment the hour to get the next occurrence. For the    
+daily case, I'm resetting to midnight and checking if that's
+already passed the reference time; if so, I move to the next
+day's midnight.                                             
+
+For interval-based scheduling with a */5 pattern, I'm       
+testing how the minute calculation works: starting from     
+12:03, I round up to 12:04, then since 4 isn't divisible by 
+5, I keep advancing until hitting 12:05 where the modulo    
+check passes. In the second scenario starting from 12:05,   
+I'm verifying the same logic continuesâ€”incrementing through 
+minutes until reaching one that satisfies the interval      
+constraint.                                                 
+
+Now I'm thinking about potential edge cases, particularly   
+whether the minute counter could exceed 60 and cause an     
+infinite loop, but with reasonable interval values like     
+1-59, the algorithm should always find a valid match within 
+the hour. I'm also considering what happens with less common
+intervals like 7, where the matching pattern becomes more   
+sparse. of next hour, so the modulo check correctly         
+identifies minute 0 as divisible by 7 at the start of each  
+hour. The cron logic checks out. Now I'm thinking about the 
+task queue implementationâ€”specifically that we're returning 
+references to the same task objects rather than deep copies,
+which means callers could mutate the state directly. That's 
+acceptable for an in-memory model since we're not building a
+production system. I'm also starting to consider the retry  
+logic for dead-lettered tasks, but that thought got cut off.
+
+Looking at the retryDeadLetterTask method, it resets the    
+sequence number so retried tasks go to the back of the queue
+as a fresh attempt. For error handling in processTask, I    
+need to decide whether middleware errors should propagate to
+the caller or just mark the task as failed internally. The  
+spec only requires marking the task as failed, but the      
+caller probably needs to know something went wrong, so I'm  
+leaning toward not re-throwing since the error is already   
+handled by the failure mechanism.                           
+
+Actually, I should throw the error so the caller can decide 
+how to respondâ€”they might want to log it or take additional 
+action. I'm sketching out how the caller would use it with a
+try-catch block around processTask.                         
+
+But there's a problem: if I throw after already failing the 
+task internally, the caller might mistakenly try to fail it 
+again. So maybe I shouldn't throw, and instead let the      
+caller check the task status to see if processing succeeded.
+That feels cleaner and avoids double-handling the failure.  
+
+Though that creates another issueâ€”if the caller doesn't know
+processing failed, they might call completeTask on a task   
+that's already been marked as failed. So the real solution  
+is to have processTask handle everything: it runs the       
+middleware and handler, auto-completes on success, and      
+auto-fails on error. The caller just checks the final task  
+status and doesn't need to do anything else.                
+
+But I need to be careful about race conditionsâ€”if something 
+else modifies the task status during async processing, I    
+shouldn't blindly overwrite it. Let me add status checks    
+before updating, and only fail the task if it's still in    
+processing state.                                           
+
+Adding status validation... I'm deciding where to put the   
+test filesâ€”since vitest finds *.test.ts files by default    
+regardless of tsconfig exclusions, I'll place them in a     
+tests directory at the root level rather than inside src.   
+tests in the root tests/ directory and import from the      
+source files using .js extensions, which vitest will resolve
+to the TypeScript files automatically. Now I'm ready to     
+write out the complete implementation with the four files I 
+need: the types, the main TaskQueueSystem class, the index  
+file, and the test file. But before I do that, I'm          
+reconsidering the auto-complete behavior in processTaskâ€”if  
+middleware chains call next() successfully and the handler  
+runs, auto-completing makes sense, but I need to think      
+through what happens when middleware doesn't call next().   
+
+If middleware skips the pipeline, the task stays in         
+processing state, which is confusing since the caller       
+expects processTask to handle the full lifecycle. I think   
+the most reasonable approach is to auto-complete the task   
+regardless of whether the handler actually ran, treating the
+middleware's decision to skip as a valid form of completion.
+I'm settling on having the task auto-complete if the entire 
+pipeline finishes (either through a handler or by reaching  
+the end), but stay in 'processing' if middleware explicitly 
+skips it by not calling nextâ€”this gives callers the         
+flexibility to decide what happens next. The                
+pipelineCompleted flag approach handles this correctly, and 
+even if there's no handler at all, the task still completes 
+since next() sets the flag in its else branch. Writing the  
+implementation now... The TaskQueueSystem class will be     
+substantial but that's fine since it's a single cohesive    
+unitâ€”I'll use section comments to keep the methods          
+organized. For the failTask method, when retrying a task by 
+resetting it to pending, I need to decide whether to update 
+its _seq. The spec says retried tasks keep their original   
+queue and priority, and since the availableAt timestamp     
+changes with exponential backoff, that'll naturally handle  
+the ordering. Though if multiple retried tasks end up with  
+the same priority and availableAt, the _seq would break     
+tiesâ€”I should probably update it to ensure they go to the   
+back of the queue.                                          
+
+Actually, keeping the original _seq is fairer since the     
+earlier-created task should go first. For                   
+retryDeadLetterTask, resetting retryCount to 0 gives the    
+task a fresh round of retries while keeping maxRetries at   
+its original value. Now I'm ready to write the complete     
+implementation, and I'll need a comprehensive test suite    
+organized by phase, using fake timers to control timing for 
+the later phases. Still writing test code...                
+
+Actually, I'm realizing the boundary condition hereâ€”when I  
+advance timers by exactly the delay amount, Date.now() will 
+equal availableAt, and since the check uses > rather than   
+>=, the task should become available at that exact moment.  
+
+For the shutdown tests with fake timers, I need to handle   
+the async polling carefully. The shutdown function waits on 
+a promise that resolves via setTimeout, so I'll need to     
+advance time to trigger those timeouts and then let the     
+pending timers resolve before awaiting the shutdown result. 
+
+Actually, using real timers with small timeout values might 
+be cleaner for these tests to avoid the complexity of       
+juggling fake timer advancement.                            
+
+Now I'm mapping out the test coverage across all seven      
+phases: basic operations like FIFO ordering and empty queue 
+handling, multi-queue management, priority queuing, delayed 
+task scheduling, task completion and retry logic with       
+backoff, dead letter queue functionality, and dependency    
+resolution including circular dependency detection.         
+
+I should also cover concurrency limits, progress listeners  
+with cancellation, scheduled tasks with cron patterns,      
+middleware execution and error handling, and graceful       
+shutdown behavior.                                          
+
+That's a comprehensive test suite. Let me start writing the 
+actual tests now.                                           
+
+One clarification on the handler registrationâ€”the spec      
+indicates handlers are registered per queue, not per        
+individual task, which aligns with my current implementation
+using a map keyed by queue name.                            
+
+Each queue maintains its own middleware pipeline as well, so
+I need to ensure that's properly isolated in the tests.     
+
+Now I'll write the implementation. I should follow the      
+ESLint configuration that allows unused variables prefixed  
+with underscore, use Node's built-in crypto module for UUID 
+generation, and stick with ESM module format since the      
+package is configured for that.                             
+
+Let me finalize the test structure one more time to ensure  
+the tests will properly validate all the interactions       
+between components.                                         
+
+Writing implementation files... I'm settling on using a     
+WeakMap to store sequence numbers separately from the Task  
+objects, which keeps the public type definition clean while 
+still allowing proper ordering. This approach avoids the    
+complexity of type casting and maintains a clear separation 
+between the public API and internal implementation details. 
+
+Now I'm working through the cron scheduling logic,          
+specifically how to handle the */N pattern for minutes and  
+ensure the algorithm correctly advances to the next valid   
+interval. I'm checking how this logic handles non-standard  
+cron intervals like */120 â€” since minutes only go 0-59, we'd
+only ever match at minute 0, effectively running hourly,    
+which is technically correct even if unconventional.        
+
+Now I'm ready to actually write the implementation. I'm     
+planning out the file structure: types, the main            
+TaskQueueSystem class, an index file, and comprehensive     
+tests covering all the phases. That's roughly 830 lines     
+total, which is reasonable.                                 
+
+Writing the implementation... test's expect for assertions. 
+Vitest has globals: true configured, so describe, it, and   
+expect should be available without imports, and I've got the
+coverage package in devDependencies already.                
+
+For the imports in tests, I'll use the .js extension since  
+vitest handles the TypeScript resolution automatically with 
+Node16 module resolution.                                   
+
+Now I'm thinking through the Task type definition and which 
+fields should be mutable versus immutable. Fields like      
+progress, metadata, retryCount, lastError, and status change
+throughout the task lifecycle, while id, payload, queueName,
+priority, createdAt, maxRetries, backoffDelay, and          
+dependencies are set once and shouldn't change. I could use 
+readonly on the interface to prevent external mutations, but
+that would require casting internally when I need to update 
+values, which feels messy. I'll keep everything mutable in  
+the type definition for simplicityâ€”the API design makes it  
+clear what's intended to be stable.                         
+
+Now I'm actually writing the test file. I'm organizing tests
+by phase, starting with basic FIFO queue behavior, then     
+moving into named queues. Each test is focused and clear,   
+with setup using beforeEach to create a fresh queue instance
+for isolation.                                              
+
+I'm realizing there's a subtle issue with how failTask      
+handles retries. When a task fails and has retries left, I  
+reset it to pending status with a delay before it's         
+available again, and I clear its progress. The spec says    
+retried tasks keep their original queue and priority, which 
+I'm already doing by maintaining those properties. But I    
+need to think through whether the _seq should be updatedâ€”a  
+retried task with a delay will naturally sort later in the  
+queue due to its availableAt timestamp, so the existing FIFO
+ordering within the same priority level should handle it    
+correctly.                                                  
+
+There's an edge case where a retried task and a non-retried 
+task could have the same availableAt time, and in that      
+scenario the _seq would be the tiebreaker. Keeping the      
+original _seq means the retried task would go first if it   
+was created earlier, which seems reasonable.                
+
+Now I'm double-checking the retry logic itselfâ€”when I       
+increment retryCount before comparing it against maxRetries,
+I need to make sure the math works out correctly for the    
+exponential backoff calculation.                            
+
+Looking at the sequence: with maxRetries = 3, the first     
+failure increments to 1, which is less than 3 so it retries 
+with a 1000ms delay. The second failure increments to 2,    
+still less than 3, so it retries with a 2000ms delay. The   
+third failure increments to 3, which fails the comparison,  
+so it goes to the DLQ. That means only 2 retries happen,    
+giving 3 total attemptsâ€”but the spec says the default       
+maximum is 3 retries, which should mean 4 total attempts.   
+
+I need to adjust the comparison to check retryCount <       
+maxRetries after incrementing, or change how I'm thinking   
+about the relationship between maxRetries and the actual    
+retry count.                                                
+
+Fixing the retry condition... Working through the           
+exponential backoff calculation to verify it matches the    
+expected behaviorâ€”after three retries with a 1000ms base    
+delay, the delays are 1000ms, 2000ms, and 4000ms            
+respectively, then the fourth failure triggers the dead     
+letter queue since we've exhausted our retry limit.         
+
+Now I'm clarifying what "failed count" means for the DLQ    
+specâ€”whether it should be the total number of times the task
+failed (4: the original attempt plus 3 retries) or just the 
+retry count itself (3). The distinction matters because the 
+spec asks for "how many times they failed," which           
+technically means every invocation that resulted in failure,
+so that would be retryCount + 1.                            
+
+But I need to trace through my actual code logic to see     
+what's happening. When the fourth failure occurs, retryCount
+is still 3 from the previous retry, and the check if        
+(task.retryCount < task.maxRetries) evaluates to 3 < 3 which
+is false, sending it to the DLQâ€”but I haven't incremented   
+retryCount for this final failure yet.                      
+
+Let me walk through the sequence: on the first failure,     
+retryCount starts at 0, the condition passes, I increment it
+to 1 and reschedule. On the second failure, retryCount is 1,
+the condition passes again, I increment to 2 and reschedule.
+On the third failure, retryCount is 2, the condition passes,
+I increment to 3 and reschedule. Then on the fourth failure,
+retryCount is 3, the condition fails, and the task goes to  
+the dead letter queue without incrementing the counter.     
+
+So the final retryCount in the DLQ is 3, which actually     
+represents that the task was retried 3 times before the     
+final failure. The spec asks for a count of failures, and   
+having retryCount=3 with maxRetries=3 already makes it clear
+that all retries were exhaustedâ€”I think this is acceptable. 
+I see the issue nowâ€”for the DLQ, "how many times they       
+failed" should be the total failure count, which means I    
+need to increment retryCount even on the final failure when 
+we're moving to the dead letter queue. So if maxRetries is  
+3, the task fails 4 times total (initial attempt + 3        
+retries), and retryCount should be 4 by the time it reaches 
+the DLQ. I'm adjusting the logic to always increment        
+retryCount first, then check if we still have retries       
+available or if we've exhausted them.                       
+
+Updating the failure handler... I'm realizing the semantics 
+matter hereâ€”if retryCount represents total failures, it'll  
+exceed maxRetries, which is confusing. Let me reconsider:   
+retryCount should track the number of retry attempts        
+performed, so the condition becomes retryCount < maxRetries,
+and I'm tracing through the logic again to verify this      
+approach works correctly. I'm realizing the spec actually   
+asks for two things: tracking attempts and counting         
+failures. With maxRetries=3, a task gets attempted 4 times  
+total but I need to decide whether to track retries         
+separately or just use a single count for both. I think the 
+simplest approach is to use retryCount as the total attempt 
+count rather than splitting it into separate fields.        
+
+Writing the failTask implementation... Now I'm implementing 
+the retry logic with exponential backoffâ€”calculating the    
+delay based on the retry count, incrementing it, and setting
+the task back to pending for another attempt. If we've      
+exhausted all retries, the task moves to failed status and  
+gets added to the dead letter queue. Let me trace through an
+example with maxRetries=3 to verify the timing works out    
+correctly. ^(attempt-1)`:                                   
+
+ â€¢ When retryCount is being read (before increment), it     
+   represents the 0-indexed retry number.                   
+ â€¢ Retry 0 (first retry): delay = baseDelay * 2^0 =         
+   baseDelay                                                
+ â€¢ Retry 1 (second retry): delay = baseDelay * 2^1 =        
+   2*baseDelay                                              
+ â€¢ Retry 2 (third retry): delay = baseDelay * 2^2 =         
+   4*baseDelay                                              
+
+This matches the spec's formula where "attempt" = retryCount
++ 1:                                                        
+
+ â€¢ attempt 1: 2^(1-1) = 2^0 = 1 â†’ delay = baseDelay         
+ â€¢ attempt 2: 2^(2-1) = 2^1 = 2 â†’ delay = 2*baseDelay       
+ â€¢ attempt 3                                                
+
+So the exponential backoff formula using retryCount directly
+as the exponent aligns with the specification's             
+attempt-based formula.                                      
+
+Now I'm ready to write the actual implementation. Actually, 
+I just realized I can simplify the approach by tracking     
+sequence numbers in a separate Map instead of wrapping tasks
+in an InternalTask class, which avoids unnecessary casting  
+when storing and retrieving tasks.                          
+
+Writing the task queue implementation...                    
+
+I need to make sure the ESM imports use .js extensions in   
+both source and test files. Now I'm thinking through the    
+error handling in processTask â€” when middleware throws an   
+error, I catch it and call failTask to mark the task as     
+failed, which might re-queue it with a delay, but the       
+function returns normally without re-throwing so the caller 
+can check the task status. There's an edge case though: what
+if failTask itself throws?                                  
+
+Adding defensive error handling...                          
+
+Actually, the middleware spec is clearâ€”if middleware or     
+handlers throw, the task should be marked failed and        
+processTask returns normally without re-throwing. Since     
+failTask only throws if the task isn't in 'processing' state
+(which I'm checking), it should be safe, so I'll skip the   
+extra error handling and let errors propagate naturally.    
+
+Now I'm ready to write the implementation. I'll create the  
+type definitions, the main TaskQueueSystem class, the index 
+file, and a test suite to verify everything works as        
+expectedâ€”starting with the source files, then running build 
+and lint checks.                                            
+
+For the async shutdown polling, I'm using a 50ms delay      
+between checks, which means at most 600 iterations with the 
+default 30-second timeout. In tests with fake timers this   
+becomes problematic since setTimeout won't resolve until    
+timers advance, so I'll use real timers with shorter        
+timeouts for the shutdown test instead.                     
+
+For testing the force-cancel scenario, I can create a task, 
+move it to processing, call shutdown with a 100ms timeout,  
+and verify it gets force-cancelled since the task is still  
+running. With real timers this works cleanly.               
+
+The trickier case is testing graceful shutdown where tasks  
+completeâ€”the polling loop with setTimeout creates a timing  
+issue where synchronous task completion can't interleave    
+with the awaited shutdown, so I need a different approach   
+for that test scenario.                                     
+
+I can work around this by not awaiting the shutdown promise 
+immediately. Instead, I'll start the shutdown, call         
+completeTask synchronously to mark it as done, then await   
+the shutdown promise. Since the polling loop checks every   
+50ms, the next iteration will see no processing tasks and   
+resolve.                                                    
+
+Now I'm confident this approach will work with real timers. 
+Let me write out all the source files and then build and    
+test everything.[0m
+[90m============================================================[0m
+
+
+[38;5;103mâ–[0m [38;5;145mI've now read all 12 phase requirements and understand the  [0m
+[38;5;103mâ–[0m [38;5;145mproject structure. The src/ directory is empty except for   [0m
+[38;5;103mâ–[0m [38;5;145m.gitkeep. Let me design the full system with all 12 phases  [0m
+[38;5;103mâ–[0m [38;5;145min mind, then implement it incrementally.[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 44,887 (80% cached) | Output: 36,912 | Total: 81,799[0m
+
+[36mğŸ”§ Using tool: todo[0m
+   [2maction: update[0m
+   [2mtodos:[0m
+   [2m- content: Explore project structure and read all phase requirements[0m
+   [2m  status: completed[0m
+   [2m  activeForm: Exploring project structure and reading requirements[0m
+   [2m... (9 more lines)[0m
+[36mâœ… Tool result: todo[0m
+[2m   status: updated
+   count: 4
+   pending: 2
+   in_progress: 1
+   completed: 1[0m
+
+
+[2;37mâ”Œâ”€ Todo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mExplore project structure and read all phase requiremenâ€¦[0m [2;37mâ”‚[0m
+[2;37mâ”‚[0m [1;36mâ–¶[0m [1;36mImplementing core types and TaskQueueSystem[0m              [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mWrite test suite for all phases[0m                          [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mRun build, lint, and tests - fix any issues[0m              [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m[2;37mâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘[0m 1/4                               [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[0m
+
+[38;5;103mâ–[0m [38;5;145mNow I have a complete understanding of all 12 phases and the[0m
+[38;5;103mâ–[0m [38;5;145mproject setup. Let me implement the full system. I've       [0m
+[38;5;103mâ–[0m [38;5;145mdesigned the architecture with all phases in mind from the  [0m
+[38;5;103mâ–[0m [38;5;145mstart to avoid rework.[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 80,943 (44% cached) | Output: 598 | Total: 81,541[0m
+
+[36mğŸ”§ Using tool: write_file[0m
+   [2mfile_path: /workspace/src/types.ts[0m
+   [2mcontent: |[0m
+   [2m    export type TaskStatus = 'pending' | 'processing' | 'completed' | 'failed' | 'cancelled';[0m
+   [2m    [0m
+   [2m    export interface TaskOptions {[0m
+   [2m... (61 more lines)[0m
+[36mâœ… Tool result: write_file[0m
+[2m   file_path: /workspace/src/types.ts
+   bytes: 1501[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 81,580 (44% cached) | Output: 5,558 | Total: 87,138[0m
+
+[36mğŸ”§ Using tool: write_file[0m
+   [2mfile_path: /workspace/src/TaskQueueSystem.ts[0m
+   [2mcontent: |[0m
+   [2m    import { randomUUID } from 'node:crypto';[0m
+   [2m    import type {[0m
+   [2m      Task,[0m
+   [2m... (615 more lines)[0m
+[36mâœ… Tool result: write_file[0m
+[2m   file_path: /workspace/src/TaskQueueSystem.ts
+   bytes: 17729[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 87,183 (41% cached) | Output: 163 | Total: 87,346[0m
+
+[36mğŸ”§ Using tool: write_file[0m
+   [2mfile_path: /workspace/src/index.ts[0m
+   [2mcontent: |[0m
+   [2m    export { TaskQueueSystem } from './TaskQueueSystem.js';[0m
+   [2m    export type {[0m
+   [2m      Task,[0m
+   [2m... (11 more lines)[0m
+[36mâœ… Tool result: write_file[0m
+[2m   file_path: /workspace/src/index.ts
+   bytes: 245[0m
+
+
+[90m============================================================[0m
+[90mThinking:[0m
+[90m------------------------------------------------------------[0m
+[2mLet me now build and lint to check for compilation issues,  
+then write tests.[0m
+[90m============================================================[0m
+
+
+[38;5;110mâ–¸[0m [38;5;188mNow let me verify the build compiles and lint passes:[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 87,384 (41% cached) | Output: 150 | Total: 87,534[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm run build 2>&1[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm run lint 2>&1[0m
+[36mâŒ Tool result: bash[0m
+[2m   
+   > bench-task-queue@1.0.0 lint
+   > eslint src/
+   
+   sh: 1: eslint: not found
+   ... (1 more lines)[0m
+
+[36mâŒ Tool result: bash[0m
+[2m   
+   > bench-task-queue@1.0.0 build
+   > tsc
+   
+   sh: 1: tsc: not found
+   ... (1 more lines)[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 87,683 (41% cached) | Output: 66 | Total: 87,749[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm install 2>&1 | tail -5[0m
+[36mâœ… Tool result: bash[0m
+[2m   
+   To address all issues (including breaking changes), run:
+     npm audit fix --force
+   
+   Run `npm audit` for details.
+   ... (1 more lines)[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 87,815 (41% cached) | Output: 106 | Total: 87,921[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm run build 2>&1[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm run lint 2>&1[0m
+[36mâœ… Tool result: bash[0m
+[2m   
+   > bench-task-queue@1.0.0 lint
+   > eslint src/
+   
+   [0m
+
+[36mâœ… Tool result: bash[0m
+[2m   
+   > bench-task-queue@1.0.0 build
+   > tsc
+   
+   [0m
+
+
+[90m============================================================[0m
+[90mThinking:[0m
+[90m------------------------------------------------------------[0m
+[2mBuild and lint both pass cleanly. Now let me write the test 
+suite and run it to verify everything works correctly.[0m
+[90m============================================================[0m
+
+
+[38;5;110mâ–¸[0m [38;5;188mBuild and lint both pass cleanly. Now let me write the      [0m
+  [38;5;188mcomprehensive test suite.[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 88,059 (40% cached) | Output: 268 | Total: 88,327[0m
+
+[36mğŸ”§ Using tool: todo[0m
+   [2maction: update[0m
+   [2mtodos:[0m
+   [2m- content: Explore project structure and read all phase requirements[0m
+   [2m  status: completed[0m
+   [2m  activeForm: Exploring project structure and reading requirements[0m
+   [2m... (9 more lines)[0m
+[36mâœ… Tool result: todo[0m
+[2m   status: updated
+   count: 4
+   pending: 1
+   in_progress: 1
+   completed: 2[0m
+
+
+[2;37mâ”Œâ”€ Todo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mExplore project structure and read all phase requiremenâ€¦[0m [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mImplement core types and TaskQueueSystem (Phases 1-12)[0m   [2;37mâ”‚[0m
+[2;37mâ”‚[0m [1;36mâ–¶[0m [1;36mWriting test suite[0m                                       [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;37mâ—‹[0m [2;37mRun build, lint, and tests - fix any issues[0m              [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m[2;37mâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘[0m 2/4                               [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[0m
+
+[90m============================================================[0m
+[90mThinking:[0m
+[90m------------------------------------------------------------[0m
+[2mI need to write the test suite now. Let me create a         
+comprehensive test file covering all 12 phases.[0m
+[90m============================================================[0m
+
+
+[38;5;110mâ–¸[0m [38;5;188mBuild and lint both pass clean. Now let me write the        [0m
+  [38;5;188mcomprehensive test suite.[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 88,356 (40% cached) | Output: 10,712 | Total: 99,068[0m
+
+[36mğŸ”§ Using tool: write_file[0m
+   [2mfile_path: /workspace/tests/task-queue.test.ts[0m
+   [2mcontent: |[0m
+   [2m    import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';[0m
+   [2m    import { TaskQueueSystem } from '../src/index.js';[0m
+   [2m    [0m
+   [2m... (1046 more lines)[0m
+[36mâœ… Tool result: write_file[0m
+[2m   file_path: /workspace/tests/task-queue.test.ts
+   bytes: 30161[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 99,091 (36% cached) | Output: 211 | Total: 99,302[0m
+
+[36mğŸ”§ Using tool: todo[0m
+   [2maction: update[0m
+   [2mtodos:[0m
+   [2m- content: Explore project structure and read all phase requirements[0m
+   [2m  status: completed[0m
+   [2m  activeForm: Exploring project structure and reading requirements[0m
+   [2m... (9 more lines)[0m
+[36mâœ… Tool result: todo[0m
+[2m   status: updated
+   count: 4
+   pending: 0
+   in_progress: 1
+   completed: 3[0m
+
+
+[2;37mâ”Œâ”€ Todo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mExplore project structure and read all phase requiremenâ€¦[0m [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mImplement core types and TaskQueueSystem (Phases 1-12)[0m   [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mWrite test suite for all phases[0m                          [2;37mâ”‚[0m
+[2;37mâ”‚[0m [1;36mâ–¶[0m [1;36mRunning build, lint, and tests[0m                           [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m[2;37mâ–‘â–‘â–‘â–‘â–‘â–‘[0m 3/4                               [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[0m
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 99,343 (36% cached) | Output: 61 | Total: 99,404[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm test 2>&1[0m
+[36mâœ… Tool result: bash[0m
+[2m   
+   > bench-task-queue@1.0.0 test
+   > vitest run
+   
+   
+   ... (10 more lines)[0m
+
+
+[38;5;110mâ–¸[0m [38;5;188mAll 89 tests pass. Let me also confirm build and lint are   [0m
+  [38;5;188mstill clean:[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 99,571 (36% cached) | Output: 90 | Total: 99,661[0m
+
+[36mğŸ”§ Using tool: bash[0m
+   [2mcommand: cd /workspace && npm run build 2>&1 && npm run lint 2>&1[0m
+[36mâœ… Tool result: bash[0m
+[2m   
+   > bench-task-queue@1.0.0 build
+   > tsc
+   
+   
+   ... (4 more lines)[0m
+
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 99,738 (36% cached) | Output: 209 | Total: 99,947[0m
+
+[36mğŸ”§ Using tool: todo[0m
+   [2maction: update[0m
+   [2mtodos:[0m
+   [2m- content: Explore project structure and read all phase requirements[0m
+   [2m  status: completed[0m
+   [2m  activeForm: Exploring project structure and reading requirements[0m
+   [2m... (9 more lines)[0m
+[36mâœ… Tool result: todo[0m
+[2m   status: updated
+   count: 4
+   pending: 0
+   in_progress: 0
+   completed: 4[0m
+
+
+[2;37mâ”Œâ”€ Todo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mExplore project structure and read all phase requiremenâ€¦[0m [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mImplement core types and TaskQueueSystem (Phases 1-12)[0m   [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mWrite test suite for all phases[0m                          [2;37mâ”‚[0m
+[2;37mâ”‚[0m [2;32mâœ“[0m [2;32mRun build, lint, and tests - fix any issues[0m              [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ”‚[0m [32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m[2;37m[0m 4/4 [1;32mâœ“ Complete[0m                    [2;37mâ”‚[0m
+[2;37mâ”‚[0m                                                            [2;37mâ”‚[0m
+[2;37mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[0m
+[2mâ”‚  ğŸ“Š Token Usage[0m
+[2mâ””â”€ Input: 99,994 (36% cached) | Output: 695 | Total: 100,689[0m
+Everything is built, passing lint, and all 89 tests pass. Here's a summary of   
+the implementation:                                                             
+
+
+Architecture                                                                    
+
+Three source files under src/:                                                  
+
+                                                                                
+ File                    Purpose                                                
+ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
+ src/types.ts            All type definitions (Task, TaskOptions, Schedule,     
+                         Middleware, etc.)                                      
+ src/TaskQueueSystem.ts  Single cohesive class implementing all 12 phases       
+ src/index.ts            Public API re-exports                                  
+                                                                                
+
+
+Phase-by-Phase Implementation                                                   
+
+Phases 1-2 (Basic Queue + Named Queues): Tasks stored in a Map<string, Task>    
+keyed by ID. A sequence counter ensures true FIFO ordering. Named queues are    
+implicit -- created on first task addition, with "default" as fallback.         
+
+Phase 3 (Priority): Tasks sorted by priority (1=highest, 10=lowest) on          
+retrieval, with FIFO as tiebreaker within the same priority level.              
+
+Phase 4 (Delayed Tasks): Each task has an availableAt timestamp. getNextTask    
+filters out tasks where availableAt > Date.now(). Ordering: priority first, then
+availability time, then FIFO.                                                   
+
+Phase 5 (Retry with Backoff): failTask() checks retryCount < maxRetries. If     
+retriable, the task goes back to pending with delay baseDelay * 2^retryCount    
+(exponential backoff). Otherwise it's permanently failed.                       
+
+Phase 6 (Dead Letter Queue): Permanently failed tasks are moved to per-queue    
+DLQs. retryDeadLetterTask() resets retry state for a fresh round.               
+
+Phase 7 (Task Dependencies): Tasks can declare dependency IDs. getNextTask skips
+tasks with unmet dependencies. Circular dependency detection via graph traversal
+at creation time.                                                               
+
+Phase 8 (Concurrency Control): Per-queue limits on processing tasks. getNextTask
+returns null when the limit is reached, even if pending tasks exist.            
+
+Phase 9 (Progress & Cancellation): updateProgress() notifies subscribed         
+listeners. cancelTask() works on pending or processing tasks. Cancelled tasks   
+are never retried.                                                              
+
+Phase 10 (Recurring Tasks): Cron schedules (*/N, hourly, daily) with a tick()   
+method that evaluates all schedules and enqueues due tasks.                     
+
+Phase 11 (Middleware Pipeline): Per-queue middleware stacks + handler.          
+processTask() runs the chain, auto-completes on success, auto-fails on error.   
+Middleware can skip by not calling next().                                      
+
+Phase 12 (Graceful Shutdown): Blocks new task additions, runs callbacks, polls  
+for processing tasks to finish, force-cancels after timeout. Idempotent --      
+multiple calls return the same promise.                                         
+
diff --git a/.amplifier/settings.local.yaml b/.amplifier/settings.local.yaml
new file mode 100644
index 0000000..64831cc
--- /dev/null
+++ b/.amplifier/settings.local.yaml
@@ -0,0 +1,11 @@
+config:
+  providers:
+  - config:
+      api_key: ${ANTHROPIC_API_KEY}
+      base_url: https://api.anthropic.com
+      default_model: claude-opus-4-6
+      enable_1m_context: 'true'
+      enable_prompt_caching: 'true'
+      priority: 1
+    module: provider-anthropic
+    source: /opt/amplifier-provider-anthropic
diff --git a/.thunderdome-metrics.json b/.thunderdome-metrics.json
new file mode 100644
index 0000000..73d3c4e
--- /dev/null
+++ b/.thunderdome-metrics.json
@@ -0,0 +1,7 @@
+{
+  "input_tokens": 63997,
+  "output_tokens": 695,
+  "cache_read_tokens": 35997,
+  "cache_creation_tokens": 0,
+  "total_cost_usd": 1.066075
+}
\ No newline at end of file
diff --git a/.thunderdome-stderr.log b/.thunderdome-stderr.log
new file mode 100644
index 0000000..98e1a70
--- /dev/null
+++ b/.thunderdome-stderr.log
@@ -0,0 +1,10 @@
+
+[36mğŸ§  Thinking...[0m
+
+[36mğŸ§  Thinking...[0m
+
+[36mğŸ§  Thinking...[0m
+
+[36mğŸ§  Thinking...[0m
+
+[36mğŸ§  Thinking...[0m
diff --git a/package-lock.json b/package-lock.json
index 1d53f39..7bfdff3 100644
--- a/package-lock.json
+++ b/package-lock.json
@@ -11,11 +11,83 @@
         "@types/node": "^25.2.3",
         "@typescript-eslint/eslint-plugin": "^7.0.0",
         "@typescript-eslint/parser": "^7.0.0",
+        "@vitest/coverage-v8": "^2.0.0",
         "eslint": "^8.56.0",
         "typescript": "^5.4.0",
         "vitest": "^2.0.0"
       }
     },
+    "node_modules/@ampproject/remapping": {
+      "version": "2.3.0",
+      "resolved": "https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz",
+      "integrity": "sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==",
+      "dev": true,
+      "license": "Apache-2.0",
+      "dependencies": {
+        "@jridgewell/gen-mapping": "^0.3.5",
+        "@jridgewell/trace-mapping": "^0.3.24"
+      },
+      "engines": {
+        "node": ">=6.0.0"
+      }
+    },
+    "node_modules/@babel/helper-string-parser": {
+      "version": "7.27.1",
+      "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.27.1.tgz",
+      "integrity": "sha512-qMlSxKbpRlAridDExk92nSobyDdpPijUq2DW6oDnUqd0iOGxmQjyqhMIihI9+zv4LPyZdRje2cavWPbCbWm3eA==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=6.9.0"
+      }
+    },
+    "node_modules/@babel/helper-validator-identifier": {
+      "version": "7.28.5",
+      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.28.5.tgz",
+      "integrity": "sha512-qSs4ifwzKJSV39ucNjsvc6WVHs6b7S03sOh2OcHF9UHfVPqWWALUsNUVzhSBiItjRZoLHx7nIarVjqKVusUZ1Q==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=6.9.0"
+      }
+    },
+    "node_modules/@babel/parser": {
+      "version": "7.29.0",
+      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.29.0.tgz",
+      "integrity": "sha512-IyDgFV5GeDUVX4YdF/3CPULtVGSXXMLh1xVIgdCgxApktqnQV0r7/8Nqthg+8YLGaAtdyIlo2qIdZrbCv4+7ww==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "@babel/types": "^7.29.0"
+      },
+      "bin": {
+        "parser": "bin/babel-parser.js"
+      },
+      "engines": {
+        "node": ">=6.0.0"
+      }
+    },
+    "node_modules/@babel/types": {
+      "version": "7.29.0",
+      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.29.0.tgz",
+      "integrity": "sha512-LwdZHpScM4Qz8Xw2iKSzS+cfglZzJGvofQICy7W7v4caru4EaAmyUuO6BGrbyQ2mYV11W0U8j5mBhd14dd3B0A==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "@babel/helper-string-parser": "^7.27.1",
+        "@babel/helper-validator-identifier": "^7.28.5"
+      },
+      "engines": {
+        "node": ">=6.9.0"
+      }
+    },
+    "node_modules/@bcoe/v8-coverage": {
+      "version": "0.2.3",
+      "resolved": "https://registry.npmjs.org/@bcoe/v8-coverage/-/v8-coverage-0.2.3.tgz",
+      "integrity": "sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==",
+      "dev": true,
+      "license": "MIT"
+    },
     "node_modules/@esbuild/aix-ppc64": {
       "version": "0.21.5",
       "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.21.5.tgz",
@@ -556,6 +628,84 @@
       "dev": true,
       "license": "BSD-3-Clause"
     },
+    "node_modules/@isaacs/cliui": {
+      "version": "8.0.2",
+      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
+      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
+      "dev": true,
+      "license": "ISC",
+      "dependencies": {
+        "string-width": "^5.1.2",
+        "string-width-cjs": "npm:string-width@^4.2.0",
+        "strip-ansi": "^7.0.1",
+        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
+        "wrap-ansi": "^8.1.0",
+        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
+      },
+      "engines": {
+        "node": ">=12"
+      }
+    },
+    "node_modules/@isaacs/cliui/node_modules/ansi-regex": {
+      "version": "6.2.2",
+      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.2.2.tgz",
+      "integrity": "sha512-Bq3SmSpyFHaWjPk8If9yc6svM8c56dB5BAtW4Qbw5jHTwwXXcTLoRMkpDJp6VL0XzlWaCHTXrkFURMYmD0sLqg==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
+      }
+    },
+    "node_modules/@isaacs/cliui/node_modules/strip-ansi": {
+      "version": "7.1.2",
+      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.2.tgz",
+      "integrity": "sha512-gmBGslpoQJtgnMAvOVqGZpEz9dyoKTCzy2nfz/n8aIFhN/jCE/rCmcxabB6jOOHV+0WNnylOxaxBQPSvcWklhA==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "ansi-regex": "^6.0.1"
+      },
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
+      }
+    },
+    "node_modules/@istanbuljs/schema": {
+      "version": "0.1.3",
+      "resolved": "https://registry.npmjs.org/@istanbuljs/schema/-/schema-0.1.3.tgz",
+      "integrity": "sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=8"
+      }
+    },
+    "node_modules/@jridgewell/gen-mapping": {
+      "version": "0.3.13",
+      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.13.tgz",
+      "integrity": "sha512-2kkt/7niJ6MgEPxF0bYdQ6etZaA+fQvDcLKckhy1yIQOzaoKjBBjSj63/aLVjYE3qhRt5dvM+uUyfCg6UKCBbA==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "@jridgewell/sourcemap-codec": "^1.5.0",
+        "@jridgewell/trace-mapping": "^0.3.24"
+      }
+    },
+    "node_modules/@jridgewell/resolve-uri": {
+      "version": "3.1.2",
+      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
+      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=6.0.0"
+      }
+    },
     "node_modules/@jridgewell/sourcemap-codec": {
       "version": "1.5.5",
       "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz",
@@ -563,6 +713,17 @@
       "dev": true,
       "license": "MIT"
     },
+    "node_modules/@jridgewell/trace-mapping": {
+      "version": "0.3.31",
+      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.31.tgz",
+      "integrity": "sha512-zzNR+SdQSDJzc8joaeP8QQoCQr8NuYx2dIIytl1QeBEZHJ9uW6hebsrYgbz8hJwUQao3TWCMtmfV8Nu1twOLAw==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "@jridgewell/resolve-uri": "^3.1.0",
+        "@jridgewell/sourcemap-codec": "^1.4.14"
+      }
+    },
     "node_modules/@nodelib/fs.scandir": {
       "version": "2.1.5",
       "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
@@ -601,6 +762,17 @@
         "node": ">= 8"
       }
     },
+    "node_modules/@pkgjs/parseargs": {
+      "version": "0.11.0",
+      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
+      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
+      "dev": true,
+      "license": "MIT",
+      "optional": true,
+      "engines": {
+        "node": ">=14"
+      }
+    },
     "node_modules/@rollup/rollup-android-arm-eabi": {
       "version": "4.57.1",
       "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.57.1.tgz",
@@ -964,7 +1136,6 @@
       "integrity": "sha512-m0jEgYlYz+mDJZ2+F4v8D1AyQb+QzsNqRuI7xg1VQX/KlKS0qT9r1Mo16yo5F/MtifXFgaofIFsdFMox2SxIbQ==",
       "dev": true,
       "license": "MIT",
-      "peer": true,
       "dependencies": {
         "undici-types": "~7.16.0"
       }
@@ -1009,7 +1180,6 @@
       "integrity": "sha512-4Z+L8I2OqhZV8qA132M4wNL30ypZGYOQVBfMgxDH/K5UX0PNqTu1c6za9ST5r9+tavvHiTWmBnKzpCJ/GlVFtg==",
       "dev": true,
       "license": "BSD-2-Clause",
-      "peer": true,
       "dependencies": {
         "@typescript-eslint/scope-manager": "7.18.0",
         "@typescript-eslint/types": "7.18.0",
@@ -1170,6 +1340,39 @@
       "dev": true,
       "license": "ISC"
     },
+    "node_modules/@vitest/coverage-v8": {
+      "version": "2.1.9",
+      "resolved": "https://registry.npmjs.org/@vitest/coverage-v8/-/coverage-v8-2.1.9.tgz",
+      "integrity": "sha512-Z2cOr0ksM00MpEfyVE8KXIYPEcBFxdbLSs56L8PO0QQMxt/6bDj45uQfxoc96v05KW3clk7vvgP0qfDit9DmfQ==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "@ampproject/remapping": "^2.3.0",
+        "@bcoe/v8-coverage": "^0.2.3",
+        "debug": "^4.3.7",
+        "istanbul-lib-coverage": "^3.2.2",
+        "istanbul-lib-report": "^3.0.1",
+        "istanbul-lib-source-maps": "^5.0.6",
+        "istanbul-reports": "^3.1.7",
+        "magic-string": "^0.30.12",
+        "magicast": "^0.3.5",
+        "std-env": "^3.8.0",
+        "test-exclude": "^7.0.1",
+        "tinyrainbow": "^1.2.0"
+      },
+      "funding": {
+        "url": "https://opencollective.com/vitest"
+      },
+      "peerDependencies": {
+        "@vitest/browser": "2.1.9",
+        "vitest": "2.1.9"
+      },
+      "peerDependenciesMeta": {
+        "@vitest/browser": {
+          "optional": true
+        }
+      }
+    },
     "node_modules/@vitest/expect": {
       "version": "2.1.9",
       "resolved": "https://registry.npmjs.org/@vitest/expect/-/expect-2.1.9.tgz",
@@ -1289,7 +1492,6 @@
       "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
       "dev": true,
       "license": "MIT",
-      "peer": true,
       "bin": {
         "acorn": "bin/acorn"
       },
@@ -1574,6 +1776,20 @@
         "node": ">=6.0.0"
       }
     },
+    "node_modules/eastasianwidth": {
+      "version": "0.2.0",
+      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
+      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
+      "dev": true,
+      "license": "MIT"
+    },
+    "node_modules/emoji-regex": {
+      "version": "9.2.2",
+      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
+      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
+      "dev": true,
+      "license": "MIT"
+    },
     "node_modules/es-module-lexer": {
       "version": "1.7.0",
       "resolved": "https://registry.npmjs.org/es-module-lexer/-/es-module-lexer-1.7.0.tgz",
@@ -1640,7 +1856,6 @@
       "deprecated": "This version is no longer supported. Please see https://eslint.org/version-support for other options.",
       "dev": true,
       "license": "MIT",
-      "peer": true,
       "dependencies": {
         "@eslint-community/eslint-utils": "^4.2.0",
         "@eslint-community/regexpp": "^4.6.1",
@@ -1955,6 +2170,23 @@
       "dev": true,
       "license": "ISC"
     },
+    "node_modules/foreground-child": {
+      "version": "3.3.1",
+      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.1.tgz",
+      "integrity": "sha512-gIXjKqtFuWEgzFRJA9WCQeSJLZDjgJUOMCMzxtvFq/37KojM1BFGufqsCy0r4qSQmYLsZYMeyRqzIWOMup03sw==",
+      "dev": true,
+      "license": "ISC",
+      "dependencies": {
+        "cross-spawn": "^7.0.6",
+        "signal-exit": "^4.0.1"
+      },
+      "engines": {
+        "node": ">=14"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/isaacs"
+      }
+    },
     "node_modules/fs.realpath": {
       "version": "1.0.0",
       "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
@@ -2090,6 +2322,13 @@
         "node": ">=8"
       }
     },
+    "node_modules/html-escaper": {
+      "version": "2.0.2",
+      "resolved": "https://registry.npmjs.org/html-escaper/-/html-escaper-2.0.2.tgz",
+      "integrity": "sha512-H2iMtd0I4Mt5eYiapRdIDjp+XzelXQ0tFE4JS7YFwFevXXMmOp9myNrUvCg0D6ws8iqkRPBfKHgbwig1SmlLfg==",
+      "dev": true,
+      "license": "MIT"
+    },
     "node_modules/ignore": {
       "version": "5.3.2",
       "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
@@ -2156,6 +2395,16 @@
         "node": ">=0.10.0"
       }
     },
+    "node_modules/is-fullwidth-code-point": {
+      "version": "3.0.0",
+      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
+      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=8"
+      }
+    },
     "node_modules/is-glob": {
       "version": "4.0.3",
       "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
@@ -2196,6 +2445,76 @@
       "dev": true,
       "license": "ISC"
     },
+    "node_modules/istanbul-lib-coverage": {
+      "version": "3.2.2",
+      "resolved": "https://registry.npmjs.org/istanbul-lib-coverage/-/istanbul-lib-coverage-3.2.2.tgz",
+      "integrity": "sha512-O8dpsF+r0WV/8MNRKfnmrtCWhuKjxrq2w+jpzBL5UZKTi2LeVWnWOmWRxFlesJONmc+wLAGvKQZEOanko0LFTg==",
+      "dev": true,
+      "license": "BSD-3-Clause",
+      "engines": {
+        "node": ">=8"
+      }
+    },
+    "node_modules/istanbul-lib-report": {
+      "version": "3.0.1",
+      "resolved": "https://registry.npmjs.org/istanbul-lib-report/-/istanbul-lib-report-3.0.1.tgz",
+      "integrity": "sha512-GCfE1mtsHGOELCU8e/Z7YWzpmybrx/+dSTfLrvY8qRmaY6zXTKWn6WQIjaAFw069icm6GVMNkgu0NzI4iPZUNw==",
+      "dev": true,
+      "license": "BSD-3-Clause",
+      "dependencies": {
+        "istanbul-lib-coverage": "^3.0.0",
+        "make-dir": "^4.0.0",
+        "supports-color": "^7.1.0"
+      },
+      "engines": {
+        "node": ">=10"
+      }
+    },
+    "node_modules/istanbul-lib-source-maps": {
+      "version": "5.0.6",
+      "resolved": "https://registry.npmjs.org/istanbul-lib-source-maps/-/istanbul-lib-source-maps-5.0.6.tgz",
+      "integrity": "sha512-yg2d+Em4KizZC5niWhQaIomgf5WlL4vOOjZ5xGCmF8SnPE/mDWWXgvRExdcpCgh9lLRRa1/fSYp2ymmbJ1pI+A==",
+      "dev": true,
+      "license": "BSD-3-Clause",
+      "dependencies": {
+        "@jridgewell/trace-mapping": "^0.3.23",
+        "debug": "^4.1.1",
+        "istanbul-lib-coverage": "^3.0.0"
+      },
+      "engines": {
+        "node": ">=10"
+      }
+    },
+    "node_modules/istanbul-reports": {
+      "version": "3.2.0",
+      "resolved": "https://registry.npmjs.org/istanbul-reports/-/istanbul-reports-3.2.0.tgz",
+      "integrity": "sha512-HGYWWS/ehqTV3xN10i23tkPkpH46MLCIMFNCaaKNavAXTF1RkqxawEPtnjnGZ6XKSInBKkiOA5BKS+aZiY3AvA==",
+      "dev": true,
+      "license": "BSD-3-Clause",
+      "dependencies": {
+        "html-escaper": "^2.0.0",
+        "istanbul-lib-report": "^3.0.0"
+      },
+      "engines": {
+        "node": ">=8"
+      }
+    },
+    "node_modules/jackspeak": {
+      "version": "3.4.3",
+      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-3.4.3.tgz",
+      "integrity": "sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==",
+      "dev": true,
+      "license": "BlueOak-1.0.0",
+      "dependencies": {
+        "@isaacs/cliui": "^8.0.2"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/isaacs"
+      },
+      "optionalDependencies": {
+        "@pkgjs/parseargs": "^0.11.0"
+      }
+    },
     "node_modules/js-yaml": {
       "version": "4.1.1",
       "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.1.tgz",
@@ -2284,6 +2603,13 @@
       "dev": true,
       "license": "MIT"
     },
+    "node_modules/lru-cache": {
+      "version": "10.4.3",
+      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz",
+      "integrity": "sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==",
+      "dev": true,
+      "license": "ISC"
+    },
     "node_modules/magic-string": {
       "version": "0.30.21",
       "resolved": "https://registry.npmjs.org/magic-string/-/magic-string-0.30.21.tgz",
@@ -2294,6 +2620,34 @@
         "@jridgewell/sourcemap-codec": "^1.5.5"
       }
     },
+    "node_modules/magicast": {
+      "version": "0.3.5",
+      "resolved": "https://registry.npmjs.org/magicast/-/magicast-0.3.5.tgz",
+      "integrity": "sha512-L0WhttDl+2BOsybvEOLK7fW3UA0OQ0IQ2d6Zl2x/a6vVRs3bAY0ECOSHHeL5jD+SbOpOCUEi0y1DgHEn9Qn1AQ==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "@babel/parser": "^7.25.4",
+        "@babel/types": "^7.25.4",
+        "source-map-js": "^1.2.0"
+      }
+    },
+    "node_modules/make-dir": {
+      "version": "4.0.0",
+      "resolved": "https://registry.npmjs.org/make-dir/-/make-dir-4.0.0.tgz",
+      "integrity": "sha512-hXdUTZYIVOt1Ex//jAQi+wTZZpUpwBj/0QsOzqegb3rGMMeJiSEu5xLHnYfBrRV4RH2+OCSOO95Is/7x1WJ4bw==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "semver": "^7.5.3"
+      },
+      "engines": {
+        "node": ">=10"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/sindresorhus"
+      }
+    },
     "node_modules/merge2": {
       "version": "1.4.1",
       "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
@@ -2334,6 +2688,16 @@
         "url": "https://github.com/sponsors/isaacs"
       }
     },
+    "node_modules/minipass": {
+      "version": "7.1.2",
+      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz",
+      "integrity": "sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==",
+      "dev": true,
+      "license": "ISC",
+      "engines": {
+        "node": ">=16 || 14 >=14.17"
+      }
+    },
     "node_modules/ms": {
       "version": "2.1.3",
       "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
@@ -2427,6 +2791,13 @@
         "url": "https://github.com/sponsors/sindresorhus"
       }
     },
+    "node_modules/package-json-from-dist": {
+      "version": "1.0.1",
+      "resolved": "https://registry.npmjs.org/package-json-from-dist/-/package-json-from-dist-1.0.1.tgz",
+      "integrity": "sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==",
+      "dev": true,
+      "license": "BlueOak-1.0.0"
+    },
     "node_modules/parent-module": {
       "version": "1.0.1",
       "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
@@ -2470,6 +2841,23 @@
         "node": ">=8"
       }
     },
+    "node_modules/path-scurry": {
+      "version": "1.11.1",
+      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz",
+      "integrity": "sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==",
+      "dev": true,
+      "license": "BlueOak-1.0.0",
+      "dependencies": {
+        "lru-cache": "^10.2.0",
+        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
+      },
+      "engines": {
+        "node": ">=16 || 14 >=14.18"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/isaacs"
+      }
+    },
     "node_modules/path-type": {
       "version": "4.0.0",
       "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
@@ -2737,6 +3125,19 @@
       "dev": true,
       "license": "ISC"
     },
+    "node_modules/signal-exit": {
+      "version": "4.1.0",
+      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
+      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
+      "dev": true,
+      "license": "ISC",
+      "engines": {
+        "node": ">=14"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/isaacs"
+      }
+    },
     "node_modules/slash": {
       "version": "3.0.0",
       "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
@@ -2771,6 +3172,76 @@
       "dev": true,
       "license": "MIT"
     },
+    "node_modules/string-width": {
+      "version": "5.1.2",
+      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
+      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "eastasianwidth": "^0.2.0",
+        "emoji-regex": "^9.2.2",
+        "strip-ansi": "^7.0.1"
+      },
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/sindresorhus"
+      }
+    },
+    "node_modules/string-width-cjs": {
+      "name": "string-width",
+      "version": "4.2.3",
+      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
+      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "emoji-regex": "^8.0.0",
+        "is-fullwidth-code-point": "^3.0.0",
+        "strip-ansi": "^6.0.1"
+      },
+      "engines": {
+        "node": ">=8"
+      }
+    },
+    "node_modules/string-width-cjs/node_modules/emoji-regex": {
+      "version": "8.0.0",
+      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
+      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
+      "dev": true,
+      "license": "MIT"
+    },
+    "node_modules/string-width/node_modules/ansi-regex": {
+      "version": "6.2.2",
+      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.2.2.tgz",
+      "integrity": "sha512-Bq3SmSpyFHaWjPk8If9yc6svM8c56dB5BAtW4Qbw5jHTwwXXcTLoRMkpDJp6VL0XzlWaCHTXrkFURMYmD0sLqg==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
+      }
+    },
+    "node_modules/string-width/node_modules/strip-ansi": {
+      "version": "7.1.2",
+      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.2.tgz",
+      "integrity": "sha512-gmBGslpoQJtgnMAvOVqGZpEz9dyoKTCzy2nfz/n8aIFhN/jCE/rCmcxabB6jOOHV+0WNnylOxaxBQPSvcWklhA==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "ansi-regex": "^6.0.1"
+      },
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
+      }
+    },
     "node_modules/strip-ansi": {
       "version": "6.0.1",
       "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
@@ -2784,6 +3255,20 @@
         "node": ">=8"
       }
     },
+    "node_modules/strip-ansi-cjs": {
+      "name": "strip-ansi",
+      "version": "6.0.1",
+      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
+      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "ansi-regex": "^5.0.1"
+      },
+      "engines": {
+        "node": ">=8"
+      }
+    },
     "node_modules/strip-json-comments": {
       "version": "3.1.1",
       "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
@@ -2810,6 +3295,43 @@
         "node": ">=8"
       }
     },
+    "node_modules/test-exclude": {
+      "version": "7.0.1",
+      "resolved": "https://registry.npmjs.org/test-exclude/-/test-exclude-7.0.1.tgz",
+      "integrity": "sha512-pFYqmTw68LXVjeWJMST4+borgQP2AyMNbg1BpZh9LbyhUeNkeaPF9gzfPGUAnSMV3qPYdWUwDIjjCLiSDOl7vg==",
+      "dev": true,
+      "license": "ISC",
+      "dependencies": {
+        "@istanbuljs/schema": "^0.1.2",
+        "glob": "^10.4.1",
+        "minimatch": "^9.0.4"
+      },
+      "engines": {
+        "node": ">=18"
+      }
+    },
+    "node_modules/test-exclude/node_modules/glob": {
+      "version": "10.5.0",
+      "resolved": "https://registry.npmjs.org/glob/-/glob-10.5.0.tgz",
+      "integrity": "sha512-DfXN8DfhJ7NH3Oe7cFmu3NCu1wKbkReJ8TorzSAFbSKrlNaQSKfIzqYqVY8zlbs2NLBbWpRiU52GX2PbaBVNkg==",
+      "deprecated": "Old versions of glob are not supported, and contain widely publicized security vulnerabilities, which have been fixed in the current version. Please update. Support for old versions may be purchased (at exorbitant rates) by contacting i@izs.me",
+      "dev": true,
+      "license": "ISC",
+      "dependencies": {
+        "foreground-child": "^3.1.0",
+        "jackspeak": "^3.1.2",
+        "minimatch": "^9.0.4",
+        "minipass": "^7.1.2",
+        "package-json-from-dist": "^1.0.0",
+        "path-scurry": "^1.11.1"
+      },
+      "bin": {
+        "glob": "dist/esm/bin.mjs"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/isaacs"
+      }
+    },
     "node_modules/text-table": {
       "version": "0.2.0",
       "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
@@ -2919,7 +3441,6 @@
       "integrity": "sha512-jl1vZzPDinLr9eUt3J/t7V6FgNEw9QjvBPdysz9KfQDD41fQrC2Y4vKQdiaUpFT4bXlb1RHhLpp8wtm6M5TgSw==",
       "dev": true,
       "license": "Apache-2.0",
-      "peer": true,
       "bin": {
         "tsc": "bin/tsc",
         "tsserver": "bin/tsserver"
@@ -2951,7 +3472,6 @@
       "integrity": "sha512-o5a9xKjbtuhY6Bi5S3+HvbRERmouabWbyUcpXXUA1u+GNUKoROi9byOJ8M0nHbHYHkYICiMlqxkg1KkYmm25Sw==",
       "dev": true,
       "license": "MIT",
-      "peer": true,
       "dependencies": {
         "esbuild": "^0.21.3",
         "postcss": "^8.4.43",
@@ -3138,6 +3658,107 @@
         "node": ">=0.10.0"
       }
     },
+    "node_modules/wrap-ansi": {
+      "version": "8.1.0",
+      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
+      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "ansi-styles": "^6.1.0",
+        "string-width": "^5.0.1",
+        "strip-ansi": "^7.0.1"
+      },
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
+      }
+    },
+    "node_modules/wrap-ansi-cjs": {
+      "name": "wrap-ansi",
+      "version": "7.0.0",
+      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
+      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "ansi-styles": "^4.0.0",
+        "string-width": "^4.1.0",
+        "strip-ansi": "^6.0.0"
+      },
+      "engines": {
+        "node": ">=10"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
+      }
+    },
+    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
+      "version": "8.0.0",
+      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
+      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
+      "dev": true,
+      "license": "MIT"
+    },
+    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
+      "version": "4.2.3",
+      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
+      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "emoji-regex": "^8.0.0",
+        "is-fullwidth-code-point": "^3.0.0",
+        "strip-ansi": "^6.0.1"
+      },
+      "engines": {
+        "node": ">=8"
+      }
+    },
+    "node_modules/wrap-ansi/node_modules/ansi-regex": {
+      "version": "6.2.2",
+      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.2.2.tgz",
+      "integrity": "sha512-Bq3SmSpyFHaWjPk8If9yc6svM8c56dB5BAtW4Qbw5jHTwwXXcTLoRMkpDJp6VL0XzlWaCHTXrkFURMYmD0sLqg==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
+      }
+    },
+    "node_modules/wrap-ansi/node_modules/ansi-styles": {
+      "version": "6.2.3",
+      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.3.tgz",
+      "integrity": "sha512-4Dj6M28JB+oAH8kFkTLUo+a2jwOFkuqb3yucU0CANcRRUbxS0cP0nZYCGjcc3BNXwRIsUVmDGgzawme7zvJHvg==",
+      "dev": true,
+      "license": "MIT",
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
+      }
+    },
+    "node_modules/wrap-ansi/node_modules/strip-ansi": {
+      "version": "7.1.2",
+      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.2.tgz",
+      "integrity": "sha512-gmBGslpoQJtgnMAvOVqGZpEz9dyoKTCzy2nfz/n8aIFhN/jCE/rCmcxabB6jOOHV+0WNnylOxaxBQPSvcWklhA==",
+      "dev": true,
+      "license": "MIT",
+      "dependencies": {
+        "ansi-regex": "^6.0.1"
+      },
+      "engines": {
+        "node": ">=12"
+      },
+      "funding": {
+        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
+      }
+    },
     "node_modules/wrappy": {
       "version": "1.0.2",
       "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
diff --git a/src/TaskQueueSystem.ts b/src/TaskQueueSystem.ts
new file mode 100644
index 0000000..b53d9ab
--- /dev/null
+++ b/src/TaskQueueSystem.ts
@@ -0,0 +1,617 @@
+import { randomUUID } from 'node:crypto';
+import type {
+  Task,
+  TaskOptions,
+  TaskStatus,
+  ProgressListener,
+  Middleware,
+  TaskHandler,
+  Schedule,
+  ScheduleOptions,
+  ShutdownOptions,
+  ShutdownResult,
+} from './types.js';
+
+export class TaskQueueSystem {
+  private tasks = new Map<string, Task>();
+  private taskSeq = new Map<string, number>();
+  private queueNames = new Set<string>();
+  private dlqs = new Map<string, Task[]>();
+  private concurrencyLimits = new Map<string, number>();
+  private middlewareStacks = new Map<string, Middleware[]>();
+  private handlers = new Map<string, TaskHandler>();
+  private progressListeners = new Map<string, Set<ProgressListener>>();
+  private schedules = new Map<string, Schedule>();
+  private shutdownCallbacks: Array<() => void | Promise<void>> = [];
+  private _isShuttingDown = false;
+  private _shutdownPromise: Promise<ShutdownResult> | null = null;
+  private _seq = 0;
+
+  // â”€â”€â”€ Phase 1: Basic FIFO Queue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  addTask<T = unknown>(payload: T, options: TaskOptions = {}): Task<T> {
+    if (this._isShuttingDown) {
+      throw new Error('System is shutting down, cannot add new tasks');
+    }
+
+    const queueName = options.queueName ?? 'default';
+    const priority = options.priority ?? 5;
+
+    if (!Number.isInteger(priority) || priority < 1 || priority > 10) {
+      throw new Error(
+        `Invalid priority: ${priority}. Must be an integer between 1 and 10.`,
+      );
+    }
+
+    const now = Date.now();
+    let availableAt = now;
+    if (options.delay != null && options.delay > 0) {
+      availableAt = now + options.delay;
+    } else if (options.availableAt != null) {
+      availableAt = options.availableAt;
+    }
+
+    // Validate dependencies exist
+    const dependencies = options.dependencies ?? [];
+    for (const depId of dependencies) {
+      if (!this.tasks.has(depId)) {
+        throw new Error(`Dependency task not found: ${depId}`);
+      }
+    }
+
+    const task: Task<T> = {
+      id: randomUUID(),
+      status: 'pending',
+      payload,
+      queueName,
+      priority,
+      createdAt: now,
+      availableAt,
+      maxRetries: options.maxRetries ?? 3,
+      backoffDelay: options.backoffDelay ?? 1000,
+      retryCount: 0,
+      attempts: 0,
+      dependencies: [...dependencies],
+      progress: { percentage: 0 },
+      metadata: {},
+    };
+
+    // Detect circular dependencies before adding
+    if (dependencies.length > 0) {
+      this.checkCircularDeps(task);
+    }
+
+    this.tasks.set(task.id, task);
+    this.taskSeq.set(task.id, this._seq++);
+    this.queueNames.add(queueName);
+
+    return task;
+  }
+
+  getNextTask(queueName = 'default'): Task | null {
+    // Phase 8: Check concurrency limit
+    const limit = this.concurrencyLimits.get(queueName);
+    if (limit != null) {
+      const active = this.countByStatus(queueName, 'processing');
+      if (active >= limit) return null;
+    }
+
+    const now = Date.now();
+    let best: Task | null = null;
+
+    for (const task of this.tasks.values()) {
+      if (task.queueName !== queueName) continue;
+      if (task.status !== 'pending') continue;
+      if (task.availableAt > now) continue;
+      if (!this.areDependenciesMet(task)) continue;
+
+      if (!best || this.compareTasks(task, best) < 0) {
+        best = task;
+      }
+    }
+
+    if (best) {
+      best.status = 'processing';
+      best.attempts++;
+      return best;
+    }
+
+    return null;
+  }
+
+  getTask(taskId: string): Task | null {
+    return this.tasks.get(taskId) ?? null;
+  }
+
+  getPendingCount(queueName = 'default'): number {
+    return this.countByStatus(queueName, 'pending');
+  }
+
+  // â”€â”€â”€ Phase 2: Named Queues â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  getQueueNames(): string[] {
+    return [...this.queueNames];
+  }
+
+  // â”€â”€â”€ Phase 5: Complete / Fail â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  completeTask(taskId: string): void {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+    if (task.status !== 'processing') {
+      throw new Error(
+        `Cannot complete task ${taskId}: status is '${task.status}'`,
+      );
+    }
+
+    task.status = 'completed';
+    task.progress = { percentage: 100 };
+  }
+
+  failTask(taskId: string, error?: string): void {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+    if (task.status !== 'processing') {
+      throw new Error(
+        `Cannot fail task ${taskId}: status is '${task.status}'`,
+      );
+    }
+
+    task.lastError = error;
+
+    if (task.retryCount < task.maxRetries) {
+      // Exponential backoff: baseDelay * 2^(attempt-1)
+      const delay = task.backoffDelay * Math.pow(2, task.retryCount);
+      task.retryCount++;
+      task.status = 'pending';
+      task.availableAt = Date.now() + delay;
+      task.progress = { percentage: 0 };
+    } else {
+      // Exhausted all retries â†’ dead letter queue
+      task.status = 'failed';
+      this.addToDeadLetterQueue(task);
+    }
+  }
+
+  // â”€â”€â”€ Phase 6: Dead Letter Queue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  getDeadLetterQueue(queueName = 'default'): Task[] {
+    return [...(this.dlqs.get(queueName) ?? [])];
+  }
+
+  retryDeadLetterTask(taskId: string): Task {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+    if (task.status !== 'failed') {
+      throw new Error(`Task ${taskId} is not in the dead letter queue`);
+    }
+
+    // Remove from DLQ
+    const dlq = this.dlqs.get(task.queueName);
+    if (dlq) {
+      const idx = dlq.indexOf(task);
+      if (idx !== -1) dlq.splice(idx, 1);
+    }
+
+    // Reset for fresh retry round
+    task.status = 'pending';
+    task.retryCount = 0;
+    task.attempts = 0;
+    task.availableAt = Date.now();
+    task.lastError = undefined;
+    task.progress = { percentage: 0 };
+    this.taskSeq.set(task.id, this._seq++);
+
+    return task;
+  }
+
+  clearDeadLetterQueue(queueName = 'default'): void {
+    this.dlqs.delete(queueName);
+  }
+
+  // â”€â”€â”€ Phase 7: Task Dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  getDependencyStatus(
+    taskId: string,
+  ): { total: number; completed: number; pending: string[] } {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+
+    const pending: string[] = [];
+    let completed = 0;
+
+    for (const depId of task.dependencies) {
+      const dep = this.tasks.get(depId);
+      if (dep?.status === 'completed') {
+        completed++;
+      } else {
+        pending.push(depId);
+      }
+    }
+
+    return { total: task.dependencies.length, completed, pending };
+  }
+
+  // â”€â”€â”€ Phase 8: Concurrency Control â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  setConcurrency(queueName: string, limit: number): void {
+    if (limit < 1) {
+      this.concurrencyLimits.delete(queueName);
+    } else {
+      this.concurrencyLimits.set(queueName, limit);
+    }
+  }
+
+  getConcurrency(
+    queueName: string,
+  ): { limit: number | null; active: number } {
+    return {
+      limit: this.concurrencyLimits.get(queueName) ?? null,
+      active: this.countByStatus(queueName, 'processing'),
+    };
+  }
+
+  // â”€â”€â”€ Phase 9: Progress & Cancellation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  updateProgress(
+    taskId: string,
+    percentage: number,
+    message?: string,
+  ): void {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+    if (task.status !== 'processing') {
+      throw new Error(
+        `Cannot update progress for task ${taskId}: status is '${task.status}'`,
+      );
+    }
+
+    task.progress = { percentage, message };
+
+    const listeners = this.progressListeners.get(taskId);
+    if (listeners) {
+      for (const listener of listeners) {
+        listener({ percentage, message });
+      }
+    }
+  }
+
+  onProgress(taskId: string, listener: ProgressListener): () => void {
+    if (!this.progressListeners.has(taskId)) {
+      this.progressListeners.set(taskId, new Set());
+    }
+    this.progressListeners.get(taskId)!.add(listener);
+
+    return () => {
+      this.progressListeners.get(taskId)?.delete(listener);
+    };
+  }
+
+  cancelTask(taskId: string): void {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+    if (task.status !== 'pending' && task.status !== 'processing') {
+      throw new Error(
+        `Cannot cancel task ${taskId}: status is '${task.status}'`,
+      );
+    }
+
+    task.status = 'cancelled';
+  }
+
+  // â”€â”€â”€ Phase 10: Recurring Tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  addSchedule(options: ScheduleOptions): Schedule {
+    const id = options.id ?? randomUUID();
+    const queueName = options.queueName ?? 'default';
+
+    // Validate cron expression
+    this.parseCron(options.cron);
+
+    const now = Date.now();
+    const nextRun = this.getNextCronTime(options.cron, now);
+
+    const schedule: Schedule = {
+      id,
+      cron: options.cron,
+      queueName,
+      payload: options.payload,
+      taskOptions: options.taskOptions,
+      nextRun,
+    };
+
+    this.schedules.set(id, schedule);
+    return schedule;
+  }
+
+  removeSchedule(scheduleId: string): boolean {
+    return this.schedules.delete(scheduleId);
+  }
+
+  getSchedules(): Schedule[] {
+    return [...this.schedules.values()];
+  }
+
+  tick(now = Date.now()): Task[] {
+    const created: Task[] = [];
+
+    for (const schedule of this.schedules.values()) {
+      if (now >= schedule.nextRun) {
+        const task = this.addTask(schedule.payload, {
+          queueName: schedule.queueName,
+          ...(schedule.taskOptions ?? {}),
+        });
+        created.push(task);
+        schedule.lastRun = now;
+        schedule.nextRun = this.getNextCronTime(schedule.cron, now);
+      }
+    }
+
+    return created;
+  }
+
+  // â”€â”€â”€ Phase 11: Middleware Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  addMiddleware(queueName: string, middleware: Middleware): void {
+    if (!this.middlewareStacks.has(queueName)) {
+      this.middlewareStacks.set(queueName, []);
+    }
+    this.middlewareStacks.get(queueName)!.push(middleware);
+  }
+
+  setHandler(queueName: string, handler: TaskHandler): void {
+    this.handlers.set(queueName, handler);
+  }
+
+  async processTask(taskId: string): Promise<void> {
+    const task = this.tasks.get(taskId);
+    if (!task) throw new Error(`Task not found: ${taskId}`);
+    if (task.status !== 'processing') {
+      throw new Error(
+        `Cannot process task ${taskId}: status is '${task.status}'`,
+      );
+    }
+
+    const middlewares = this.middlewareStacks.get(task.queueName) ?? [];
+    const handler = this.handlers.get(task.queueName);
+
+    let pipelineCompleted = false;
+    let index = 0;
+
+    const next = async (): Promise<void> => {
+      if (index < middlewares.length) {
+        const mw = middlewares[index++];
+        await mw(task, next);
+      } else {
+        if (handler) {
+          await handler(task);
+        }
+        pipelineCompleted = true;
+      }
+    };
+
+    try {
+      await next();
+      if (pipelineCompleted && task.status === 'processing') {
+        task.status = 'completed';
+        task.progress = { percentage: 100 };
+      }
+    } catch (err) {
+      if (task.status === 'processing') {
+        this.failTask(
+          taskId,
+          err instanceof Error ? err.message : String(err),
+        );
+      }
+    }
+  }
+
+  // â”€â”€â”€ Phase 12: Graceful Shutdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  onShutdown(callback: () => void | Promise<void>): void {
+    this.shutdownCallbacks.push(callback);
+  }
+
+  async shutdown(options: ShutdownOptions = {}): Promise<ShutdownResult> {
+    if (this._shutdownPromise) return this._shutdownPromise;
+
+    this._isShuttingDown = true;
+    this._shutdownPromise = this.performShutdown(options);
+    return this._shutdownPromise;
+  }
+
+  get isShuttingDown(): boolean {
+    return this._isShuttingDown;
+  }
+
+  // â”€â”€â”€ Private Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+  private compareTasks(a: Task, b: Task): number {
+    if (a.priority !== b.priority) return a.priority - b.priority;
+    if (a.availableAt !== b.availableAt) return a.availableAt - b.availableAt;
+    return (this.taskSeq.get(a.id) ?? 0) - (this.taskSeq.get(b.id) ?? 0);
+  }
+
+  private areDependenciesMet(task: Task): boolean {
+    for (const depId of task.dependencies) {
+      const dep = this.tasks.get(depId);
+      if (!dep || dep.status !== 'completed') return false;
+    }
+    return true;
+  }
+
+  private checkCircularDeps(newTask: Task): void {
+    const visited = new Set<string>();
+    const stack = [...newTask.dependencies];
+
+    while (stack.length > 0) {
+      const id = stack.pop()!;
+      if (id === newTask.id) {
+        throw new Error('Circular dependency detected');
+      }
+      if (visited.has(id)) continue;
+      visited.add(id);
+
+      const dep = this.tasks.get(id);
+      if (dep) {
+        for (const d of dep.dependencies) {
+          stack.push(d);
+        }
+      }
+    }
+  }
+
+  private countByStatus(queueName: string, status: TaskStatus): number {
+    let count = 0;
+    for (const task of this.tasks.values()) {
+      if (task.queueName === queueName && task.status === status) count++;
+    }
+    return count;
+  }
+
+  private addToDeadLetterQueue(task: Task): void {
+    if (!this.dlqs.has(task.queueName)) {
+      this.dlqs.set(task.queueName, []);
+    }
+    this.dlqs.get(task.queueName)!.push(task);
+  }
+
+  private parseCron(
+    cron: string,
+  ):
+    | { type: 'interval'; minutes: number }
+    | { type: 'hourly' }
+    | { type: 'daily' } {
+    const parts = cron.trim().split(/\s+/);
+    if (parts.length !== 5) {
+      throw new Error(`Invalid cron expression: ${cron}`);
+    }
+
+    const [minutePart, hourPart, dayPart, monthPart, weekdayPart] = parts;
+
+    if (
+      minutePart.startsWith('*/') &&
+      hourPart === '*' &&
+      dayPart === '*' &&
+      monthPart === '*' &&
+      weekdayPart === '*'
+    ) {
+      const n = parseInt(minutePart.slice(2), 10);
+      if (isNaN(n) || n < 1) {
+        throw new Error(`Invalid cron interval: ${cron}`);
+      }
+      return { type: 'interval', minutes: n };
+    }
+
+    if (
+      minutePart === '0' &&
+      hourPart === '*' &&
+      dayPart === '*' &&
+      monthPart === '*' &&
+      weekdayPart === '*'
+    ) {
+      return { type: 'hourly' };
+    }
+
+    if (
+      minutePart === '0' &&
+      hourPart === '0' &&
+      dayPart === '*' &&
+      monthPart === '*' &&
+      weekdayPart === '*'
+    ) {
+      return { type: 'daily' };
+    }
+
+    throw new Error(`Unsupported cron expression: ${cron}`);
+  }
+
+  private getNextCronTime(cron: string, after: number): number {
+    const parsed = this.parseCron(cron);
+    const date = new Date(after);
+
+    // Advance past current time to the next clean minute boundary
+    date.setSeconds(0, 0);
+    date.setMinutes(date.getMinutes() + 1);
+
+    switch (parsed.type) {
+      case 'interval': {
+        while (date.getMinutes() % parsed.minutes !== 0) {
+          date.setMinutes(date.getMinutes() + 1);
+        }
+        return date.getTime();
+      }
+      case 'hourly': {
+        date.setMinutes(0);
+        if (date.getTime() <= after) {
+          date.setHours(date.getHours() + 1);
+        }
+        return date.getTime();
+      }
+      case 'daily': {
+        date.setMinutes(0);
+        date.setHours(0);
+        if (date.getTime() <= after) {
+          date.setDate(date.getDate() + 1);
+        }
+        return date.getTime();
+      }
+    }
+  }
+
+  private async performShutdown(
+    options: ShutdownOptions,
+  ): Promise<ShutdownResult> {
+    const timeout = options.timeout ?? 30000;
+    const start = Date.now();
+
+    // Run shutdown callbacks
+    for (const cb of this.shutdownCallbacks) {
+      await cb();
+    }
+
+    // Snapshot processing tasks at shutdown time
+    const processingAtShutdown: string[] = [];
+    for (const task of this.tasks.values()) {
+      if (task.status === 'processing') {
+        processingAtShutdown.push(task.id);
+      }
+    }
+
+    if (processingAtShutdown.length === 0) {
+      return { completed: 0, forceCancelled: 0, elapsed: Date.now() - start };
+    }
+
+    // Poll until all done or timeout
+    const deadline = start + timeout;
+    while (Date.now() < deadline) {
+      let allDone = true;
+      for (const id of processingAtShutdown) {
+        const task = this.tasks.get(id);
+        if (task && task.status === 'processing') {
+          allDone = false;
+          break;
+        }
+      }
+      if (allDone) break;
+      await new Promise((resolve) => setTimeout(resolve, 50));
+    }
+
+    // Tally results
+    let completed = 0;
+    let forceCancelled = 0;
+
+    for (const id of processingAtShutdown) {
+      const task = this.tasks.get(id);
+      if (!task) continue;
+      if (task.status === 'processing') {
+        task.status = 'cancelled';
+        forceCancelled++;
+      } else {
+        completed++;
+      }
+    }
+
+    return { completed, forceCancelled, elapsed: Date.now() - start };
+  }
+}
diff --git a/src/index.ts b/src/index.ts
new file mode 100644
index 0000000..cacd5d5
--- /dev/null
+++ b/src/index.ts
@@ -0,0 +1,13 @@
+export { TaskQueueSystem } from './TaskQueueSystem.js';
+export type {
+  Task,
+  TaskOptions,
+  TaskStatus,
+  ProgressListener,
+  Middleware,
+  TaskHandler,
+  Schedule,
+  ScheduleOptions,
+  ShutdownOptions,
+  ShutdownResult,
+} from './types.js';
diff --git a/src/types.ts b/src/types.ts
new file mode 100644
index 0000000..448ab77
--- /dev/null
+++ b/src/types.ts
@@ -0,0 +1,63 @@
+export type TaskStatus = 'pending' | 'processing' | 'completed' | 'failed' | 'cancelled';
+
+export interface TaskOptions {
+  queueName?: string;
+  priority?: number;
+  delay?: number;
+  availableAt?: number;
+  maxRetries?: number;
+  backoffDelay?: number;
+  dependencies?: string[];
+}
+
+export interface Task<T = unknown> {
+  id: string;
+  status: TaskStatus;
+  payload: T;
+  queueName: string;
+  priority: number;
+  createdAt: number;
+  availableAt: number;
+  maxRetries: number;
+  backoffDelay: number;
+  retryCount: number;
+  attempts: number;
+  lastError?: string;
+  dependencies: string[];
+  progress: { percentage: number; message?: string };
+  metadata: Record<string, unknown>;
+}
+
+export type ProgressListener = (progress: { percentage: number; message?: string }) => void;
+
+export type Middleware = (task: Task, next: () => Promise<void>) => Promise<void>;
+
+export type TaskHandler = (task: Task) => Promise<void> | void;
+
+export interface ScheduleOptions {
+  id?: string;
+  cron: string;
+  queueName?: string;
+  payload?: unknown;
+  taskOptions?: Pick<TaskOptions, 'priority' | 'maxRetries' | 'backoffDelay'>;
+}
+
+export interface Schedule {
+  id: string;
+  cron: string;
+  queueName: string;
+  payload: unknown;
+  taskOptions?: Pick<TaskOptions, 'priority' | 'maxRetries' | 'backoffDelay'>;
+  lastRun?: number;
+  nextRun: number;
+}
+
+export interface ShutdownOptions {
+  timeout?: number;
+}
+
+export interface ShutdownResult {
+  completed: number;
+  forceCancelled: number;
+  elapsed: number;
+}
diff --git a/tests/task-queue.test.ts b/tests/task-queue.test.ts
new file mode 100644
index 0000000..7265aeb
--- /dev/null
+++ b/tests/task-queue.test.ts
@@ -0,0 +1,1048 @@
+import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
+import { TaskQueueSystem } from '../src/index.js';
+
+describe('Phase 1: Basic FIFO Queue', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('adds a task and returns it with correct properties', () => {
+    const task = q.addTask({ msg: 'hello' });
+    expect(task.id).toBeDefined();
+    expect(task.status).toBe('pending');
+    expect(task.payload).toEqual({ msg: 'hello' });
+    expect(task.createdAt).toBeGreaterThan(0);
+    expect(task.priority).toBe(5);
+  });
+
+  it('assigns unique IDs to each task', () => {
+    const t1 = q.addTask('a');
+    const t2 = q.addTask('b');
+    expect(t1.id).not.toBe(t2.id);
+  });
+
+  it('retrieves tasks in FIFO order', () => {
+    q.addTask('first');
+    q.addTask('second');
+    q.addTask('third');
+
+    expect(q.getNextTask()!.payload).toBe('first');
+    expect(q.getNextTask()!.payload).toBe('second');
+    expect(q.getNextTask()!.payload).toBe('third');
+  });
+
+  it('transitions task to processing on retrieval', () => {
+    q.addTask('data');
+    const task = q.getNextTask();
+    expect(task!.status).toBe('processing');
+  });
+
+  it('returns null when queue is empty', () => {
+    expect(q.getNextTask()).toBeNull();
+  });
+
+  it('does not return processing tasks again', () => {
+    q.addTask('only');
+    q.getNextTask();
+    expect(q.getNextTask()).toBeNull();
+  });
+
+  it('reports pending count', () => {
+    expect(q.getPendingCount()).toBe(0);
+    q.addTask('a');
+    q.addTask('b');
+    expect(q.getPendingCount()).toBe(2);
+    q.getNextTask();
+    expect(q.getPendingCount()).toBe(1);
+  });
+});
+
+describe('Phase 2: Named Queues', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('uses default queue when no name is given', () => {
+    q.addTask('data');
+    expect(q.getQueueNames()).toContain('default');
+    expect(q.getNextTask('default')!.payload).toBe('data');
+  });
+
+  it('supports multiple independent queues', () => {
+    q.addTask('email-job', { queueName: 'email' });
+    q.addTask('sms-job', { queueName: 'sms' });
+
+    expect(q.getNextTask('email')!.payload).toBe('email-job');
+    expect(q.getNextTask('sms')!.payload).toBe('sms-job');
+  });
+
+  it('queues operate independently', () => {
+    q.addTask('a', { queueName: 'q1' });
+    q.addTask('b', { queueName: 'q2' });
+
+    expect(q.getPendingCount('q1')).toBe(1);
+    expect(q.getPendingCount('q2')).toBe(1);
+
+    q.getNextTask('q1');
+    expect(q.getPendingCount('q1')).toBe(0);
+    expect(q.getPendingCount('q2')).toBe(1);
+  });
+
+  it('lists all queue names', () => {
+    q.addTask('a', { queueName: 'alpha' });
+    q.addTask('b', { queueName: 'beta' });
+    const names = q.getQueueNames();
+    expect(names).toContain('alpha');
+    expect(names).toContain('beta');
+  });
+
+  it('returns null for non-existent queue', () => {
+    expect(q.getNextTask('nonexistent')).toBeNull();
+  });
+
+  it('returns null for empty queue', () => {
+    q.addTask('a', { queueName: 'myq' });
+    q.getNextTask('myq');
+    expect(q.getNextTask('myq')).toBeNull();
+  });
+
+  it('is backward-compatible with Phase 1 (no queue name)', () => {
+    q.addTask('data');
+    expect(q.getNextTask()!.payload).toBe('data');
+  });
+});
+
+describe('Phase 3: Priority', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('defaults to priority 5', () => {
+    const task = q.addTask('data');
+    expect(task.priority).toBe(5);
+  });
+
+  it('returns higher-priority tasks first (lower number)', () => {
+    q.addTask('low', { priority: 10 });
+    q.addTask('high', { priority: 1 });
+    q.addTask('med', { priority: 5 });
+
+    expect(q.getNextTask()!.payload).toBe('high');
+    expect(q.getNextTask()!.payload).toBe('med');
+    expect(q.getNextTask()!.payload).toBe('low');
+  });
+
+  it('maintains FIFO within same priority', () => {
+    q.addTask('first', { priority: 3 });
+    q.addTask('second', { priority: 3 });
+    q.addTask('third', { priority: 3 });
+
+    expect(q.getNextTask()!.payload).toBe('first');
+    expect(q.getNextTask()!.payload).toBe('second');
+    expect(q.getNextTask()!.payload).toBe('third');
+  });
+
+  it('rejects invalid priorities', () => {
+    expect(() => q.addTask('x', { priority: 0 })).toThrow();
+    expect(() => q.addTask('x', { priority: 11 })).toThrow();
+    expect(() => q.addTask('x', { priority: 1.5 })).toThrow();
+    expect(() => q.addTask('x', { priority: -1 })).toThrow();
+  });
+
+  it('priority operates per-queue', () => {
+    q.addTask('q1-low', { queueName: 'q1', priority: 10 });
+    q.addTask('q1-high', { queueName: 'q1', priority: 1 });
+    q.addTask('q2-low', { queueName: 'q2', priority: 10 });
+
+    expect(q.getNextTask('q1')!.payload).toBe('q1-high');
+    expect(q.getNextTask('q2')!.payload).toBe('q2-low');
+  });
+
+  it('exposes priority on the task object', () => {
+    const task = q.addTask('data', { priority: 3 });
+    expect(task.priority).toBe(3);
+  });
+});
+
+describe('Phase 4: Delayed and Scheduled Tasks', () => {
+  let q: TaskQueueSystem;
+
+  beforeEach(() => {
+    vi.useFakeTimers();
+    q = new TaskQueueSystem();
+  });
+
+  afterEach(() => {
+    vi.useRealTimers();
+  });
+
+  it('delayed tasks are not returned before their time', () => {
+    q.addTask('delayed', { delay: 5000 });
+    expect(q.getNextTask()).toBeNull();
+  });
+
+  it('delayed tasks become available after the delay', () => {
+    q.addTask('delayed', { delay: 5000 });
+    vi.advanceTimersByTime(5000);
+    expect(q.getNextTask()!.payload).toBe('delayed');
+  });
+
+  it('supports availableAt as an absolute time', () => {
+    const future = Date.now() + 3000;
+    q.addTask('scheduled', { availableAt: future });
+    expect(q.getNextTask()).toBeNull();
+
+    vi.advanceTimersByTime(3000);
+    expect(q.getNextTask()!.payload).toBe('scheduled');
+  });
+
+  it('non-delayed tasks are preferred over not-yet-available delayed tasks', () => {
+    q.addTask('delayed', { delay: 5000 });
+    q.addTask('immediate');
+
+    expect(q.getNextTask()!.payload).toBe('immediate');
+    expect(q.getNextTask()).toBeNull(); // delayed not ready yet
+  });
+
+  it('indicates when a task becomes available', () => {
+    const before = Date.now();
+    const task = q.addTask('delayed', { delay: 5000 });
+    expect(task.availableAt).toBeGreaterThanOrEqual(before + 5000);
+  });
+
+  it('delayed tasks ordered by priority then availability', () => {
+    q.addTask('later-high', { delay: 100, priority: 1 });
+    q.addTask('sooner-low', { delay: 50, priority: 10 });
+
+    vi.advanceTimersByTime(200);
+
+    // Priority takes precedence
+    expect(q.getNextTask()!.payload).toBe('later-high');
+    expect(q.getNextTask()!.payload).toBe('sooner-low');
+  });
+
+  it('works correctly with named queues', () => {
+    q.addTask('q1-delayed', { queueName: 'q1', delay: 1000 });
+    q.addTask('q2-immediate', { queueName: 'q2' });
+
+    expect(q.getNextTask('q1')).toBeNull();
+    expect(q.getNextTask('q2')!.payload).toBe('q2-immediate');
+
+    vi.advanceTimersByTime(1000);
+    expect(q.getNextTask('q1')!.payload).toBe('q1-delayed');
+  });
+});
+
+describe('Phase 5: Retry with Backoff', () => {
+  let q: TaskQueueSystem;
+
+  beforeEach(() => {
+    vi.useFakeTimers();
+    q = new TaskQueueSystem();
+  });
+
+  afterEach(() => {
+    vi.useRealTimers();
+  });
+
+  it('completes a task successfully', () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    q.completeTask(task.id);
+    expect(task.status).toBe('completed');
+  });
+
+  it('fails a task and retries with backoff', () => {
+    const task = q.addTask('data', { maxRetries: 3, backoffDelay: 1000 });
+    const t = q.getNextTask()!;
+
+    // First failure â†’ retry after 1000ms
+    q.failTask(t.id, 'error1');
+    expect(t.status).toBe('pending');
+    expect(t.retryCount).toBe(1);
+    expect(q.getNextTask()).toBeNull(); // not yet available
+
+    vi.advanceTimersByTime(1000);
+    const retry1 = q.getNextTask()!;
+    expect(retry1.id).toBe(task.id);
+
+    // Second failure â†’ retry after 2000ms
+    q.failTask(retry1.id, 'error2');
+    expect(retry1.retryCount).toBe(2);
+    vi.advanceTimersByTime(2000);
+    const retry2 = q.getNextTask()!;
+    expect(retry2.id).toBe(task.id);
+
+    // Third failure â†’ retry after 4000ms
+    q.failTask(retry2.id, 'error3');
+    expect(retry2.retryCount).toBe(3);
+    vi.advanceTimersByTime(4000);
+    const retry3 = q.getNextTask()!;
+    expect(retry3.id).toBe(task.id);
+
+    // Fourth failure â†’ exhausted, goes to failed
+    q.failTask(retry3.id, 'error4');
+    expect(retry3.status).toBe('failed');
+  });
+
+  it('tracks attempt count', () => {
+    q.addTask('data', { maxRetries: 1, backoffDelay: 100 });
+    const task = q.getNextTask()!;
+    expect(task.attempts).toBe(1);
+
+    q.failTask(task.id);
+    vi.advanceTimersByTime(100);
+
+    const retry = q.getNextTask()!;
+    expect(retry.attempts).toBe(2);
+  });
+
+  it('retried tasks keep original queue and priority', () => {
+    q.addTask('data', { queueName: 'myq', priority: 2, maxRetries: 1, backoffDelay: 100 });
+    const task = q.getNextTask('myq')!;
+    q.failTask(task.id);
+
+    vi.advanceTimersByTime(100);
+    const retry = q.getNextTask('myq')!;
+    expect(retry.queueName).toBe('myq');
+    expect(retry.priority).toBe(2);
+  });
+
+  it('configurable maxRetries and backoff per task', () => {
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    q.failTask(task.id, 'fail');
+    expect(task.status).toBe('failed');
+  });
+
+  it('preserves error information', () => {
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    q.failTask(task.id, 'something went wrong');
+    expect(task.lastError).toBe('something went wrong');
+  });
+
+  it('cannot complete a non-processing task', () => {
+    const task = q.addTask('data');
+    expect(() => q.completeTask(task.id)).toThrow();
+  });
+
+  it('cannot fail a non-processing task', () => {
+    const task = q.addTask('data');
+    expect(() => q.failTask(task.id)).toThrow();
+  });
+});
+
+describe('Phase 6: Dead Letter Queue', () => {
+  let q: TaskQueueSystem;
+
+  beforeEach(() => {
+    vi.useFakeTimers();
+    q = new TaskQueueSystem();
+  });
+
+  afterEach(() => {
+    vi.useRealTimers();
+  });
+
+  it('moves permanently failed tasks to DLQ', () => {
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    q.failTask(task.id, 'fail');
+
+    const dlq = q.getDeadLetterQueue();
+    expect(dlq).toHaveLength(1);
+    expect(dlq[0].id).toBe(task.id);
+  });
+
+  it('retains error information in DLQ', () => {
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    q.failTask(task.id, 'permanent failure');
+
+    const dlq = q.getDeadLetterQueue();
+    expect(dlq[0].lastError).toBe('permanent failure');
+    expect(dlq[0].retryCount).toBe(0);
+  });
+
+  it('retries a dead-lettered task (fresh round)', () => {
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    q.failTask(task.id, 'fail');
+
+    const retried = q.retryDeadLetterTask(task.id);
+    expect(retried.status).toBe('pending');
+    expect(retried.retryCount).toBe(0);
+    expect(retried.lastError).toBeUndefined();
+
+    expect(q.getDeadLetterQueue()).toHaveLength(0);
+
+    const retrieved = q.getNextTask()!;
+    expect(retrieved.id).toBe(task.id);
+  });
+
+  it('clears all dead-lettered tasks', () => {
+    q.addTask('a', { maxRetries: 0 });
+    q.addTask('b', { maxRetries: 0 });
+    q.failTask(q.getNextTask()!.id, 'fail');
+    q.failTask(q.getNextTask()!.id, 'fail');
+
+    expect(q.getDeadLetterQueue()).toHaveLength(2);
+    q.clearDeadLetterQueue();
+    expect(q.getDeadLetterQueue()).toHaveLength(0);
+  });
+
+  it('each queue has its own independent DLQ', () => {
+    q.addTask('a', { queueName: 'q1', maxRetries: 0 });
+    q.addTask('b', { queueName: 'q2', maxRetries: 0 });
+
+    q.failTask(q.getNextTask('q1')!.id, 'fail');
+    q.failTask(q.getNextTask('q2')!.id, 'fail');
+
+    expect(q.getDeadLetterQueue('q1')).toHaveLength(1);
+    expect(q.getDeadLetterQueue('q2')).toHaveLength(1);
+
+    q.clearDeadLetterQueue('q1');
+    expect(q.getDeadLetterQueue('q1')).toHaveLength(0);
+    expect(q.getDeadLetterQueue('q2')).toHaveLength(1);
+  });
+});
+
+describe('Phase 7: Task Dependencies', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('blocks tasks with unmet dependencies', () => {
+    const dep = q.addTask('dependency');
+    q.addTask('dependent', { dependencies: [dep.id] });
+
+    // Only the dependency is available
+    const next = q.getNextTask()!;
+    expect(next.id).toBe(dep.id);
+    expect(q.getNextTask()).toBeNull(); // dependent is blocked
+  });
+
+  it('unblocks tasks when dependencies complete', () => {
+    const dep = q.addTask('dependency');
+    const dependent = q.addTask('dependent', { dependencies: [dep.id] });
+
+    const d = q.getNextTask()!;
+    q.completeTask(d.id);
+
+    const next = q.getNextTask()!;
+    expect(next.id).toBe(dependent.id);
+  });
+
+  it('rejects dependencies on non-existent tasks', () => {
+    expect(() =>
+      q.addTask('dependent', { dependencies: ['nonexistent-id'] }),
+    ).toThrow();
+  });
+
+  it('detects circular dependencies', () => {
+    // Direct circular dependency isn't possible with our addTask model
+    // since you can only depend on existing tasks. But we test the check.
+    const a = q.addTask('a');
+    const b = q.addTask('b', { dependencies: [a.id] });
+    // c depends on b, which depends on a - this is a valid chain
+    const c = q.addTask('c', { dependencies: [b.id] });
+    expect(c.dependencies).toContain(b.id);
+  });
+
+  it('failed dependency keeps dependents blocked', () => {
+    const dep = q.addTask('dependency', { maxRetries: 0 });
+    q.addTask('dependent', { dependencies: [dep.id] });
+
+    const d = q.getNextTask()!;
+    q.failTask(d.id, 'failed');
+
+    expect(q.getNextTask()).toBeNull(); // dependent stays blocked
+  });
+
+  it('inspects dependency status', () => {
+    const dep1 = q.addTask('dep1');
+    const dep2 = q.addTask('dep2');
+    const dependent = q.addTask('dependent', {
+      dependencies: [dep1.id, dep2.id],
+    });
+
+    let status = q.getDependencyStatus(dependent.id);
+    expect(status.total).toBe(2);
+    expect(status.completed).toBe(0);
+    expect(status.pending).toHaveLength(2);
+
+    q.completeTask(q.getNextTask()!.id); // complete dep1
+
+    status = q.getDependencyStatus(dependent.id);
+    expect(status.completed).toBe(1);
+    expect(status.pending).toHaveLength(1);
+  });
+
+  it('supports multiple dependencies', () => {
+    const dep1 = q.addTask('dep1');
+    const dep2 = q.addTask('dep2');
+    const dependent = q.addTask('dependent', {
+      dependencies: [dep1.id, dep2.id],
+    });
+
+    // Complete dep1
+    q.completeTask(q.getNextTask()!.id);
+    // dependent still blocked (dep2 not done)
+    const next = q.getNextTask()!;
+    expect(next.id).toBe(dep2.id); // dep2 is next
+    expect(q.getNextTask()).toBeNull(); // dependent still blocked
+
+    q.completeTask(next.id);
+    const final = q.getNextTask()!;
+    expect(final.id).toBe(dependent.id);
+  });
+});
+
+describe('Phase 8: Concurrency Control', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('limits concurrent processing tasks', () => {
+    q.setConcurrency('default', 2);
+    q.addTask('a');
+    q.addTask('b');
+    q.addTask('c');
+
+    expect(q.getNextTask()).not.toBeNull();
+    expect(q.getNextTask()).not.toBeNull();
+    expect(q.getNextTask()).toBeNull(); // limit reached
+  });
+
+  it('frees slots when tasks complete', () => {
+    q.setConcurrency('default', 1);
+    q.addTask('a');
+    q.addTask('b');
+
+    const task = q.getNextTask()!;
+    expect(q.getNextTask()).toBeNull(); // limit
+
+    q.completeTask(task.id);
+    expect(q.getNextTask()).not.toBeNull(); // slot freed
+  });
+
+  it('frees slots when tasks fail', () => {
+    q.setConcurrency('default', 1);
+    q.addTask('a', { maxRetries: 0 });
+    q.addTask('b');
+
+    const task = q.getNextTask()!;
+    expect(q.getNextTask()).toBeNull();
+
+    q.failTask(task.id, 'err');
+    expect(q.getNextTask()).not.toBeNull();
+  });
+
+  it('unlimited by default', () => {
+    q.addTask('a');
+    q.addTask('b');
+    q.addTask('c');
+
+    expect(q.getNextTask()).not.toBeNull();
+    expect(q.getNextTask()).not.toBeNull();
+    expect(q.getNextTask()).not.toBeNull();
+  });
+
+  it('reports concurrency info', () => {
+    q.setConcurrency('default', 5);
+    q.addTask('a');
+
+    const info = q.getConcurrency('default');
+    expect(info.limit).toBe(5);
+    expect(info.active).toBe(0);
+
+    q.getNextTask();
+    expect(q.getConcurrency('default').active).toBe(1);
+  });
+
+  it('still respects priority ordering under concurrency', () => {
+    q.setConcurrency('default', 1);
+    q.addTask('low', { priority: 10 });
+    q.addTask('high', { priority: 1 });
+
+    const task = q.getNextTask()!;
+    expect(task.payload).toBe('high');
+  });
+});
+
+describe('Phase 9: Progress Tracking and Cancellation', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('reports progress on a processing task', () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    q.updateProgress(task.id, 50, 'halfway');
+
+    expect(task.progress.percentage).toBe(50);
+    expect(task.progress.message).toBe('halfway');
+  });
+
+  it('queries task progress', () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    q.updateProgress(task.id, 75);
+
+    const retrieved = q.getTask(task.id)!;
+    expect(retrieved.progress.percentage).toBe(75);
+  });
+
+  it('notifies progress listeners', () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+
+    const updates: Array<{ percentage: number; message?: string }> = [];
+    q.onProgress(task.id, (p) => updates.push(p));
+
+    q.updateProgress(task.id, 25, 'starting');
+    q.updateProgress(task.id, 75, 'almost');
+
+    expect(updates).toHaveLength(2);
+    expect(updates[0].percentage).toBe(25);
+    expect(updates[1].percentage).toBe(75);
+  });
+
+  it('supports unsubscribe from progress', () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+
+    const updates: number[] = [];
+    const unsub = q.onProgress(task.id, (p) => updates.push(p.percentage));
+
+    q.updateProgress(task.id, 25);
+    unsub();
+    q.updateProgress(task.id, 75);
+
+    expect(updates).toEqual([25]); // only received before unsubscribe
+  });
+
+  it('cancels a pending task', () => {
+    const task = q.addTask('data');
+    q.cancelTask(task.id);
+
+    expect(task.status).toBe('cancelled');
+    expect(q.getNextTask()).toBeNull();
+  });
+
+  it('cancels a processing task', () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    q.cancelTask(task.id);
+
+    expect(task.status).toBe('cancelled');
+  });
+
+  it('cancelled tasks are never retried', () => {
+    q.addTask('data', { maxRetries: 3 });
+    const task = q.getNextTask()!;
+    q.cancelTask(task.id);
+
+    expect(task.status).toBe('cancelled');
+    // Cannot fail a cancelled task (no retry path)
+    expect(() => q.failTask(task.id)).toThrow();
+  });
+
+  it('cannot cancel completed or failed tasks', () => {
+    q.addTask('a');
+    const task = q.getNextTask()!;
+    q.completeTask(task.id);
+
+    expect(() => q.cancelTask(task.id)).toThrow();
+  });
+});
+
+describe('Phase 10: Recurring Tasks', () => {
+  let q: TaskQueueSystem;
+
+  beforeEach(() => {
+    vi.useFakeTimers();
+    q = new TaskQueueSystem();
+  });
+
+  afterEach(() => {
+    vi.useRealTimers();
+  });
+
+  it('creates a schedule', () => {
+    const schedule = q.addSchedule({
+      cron: '*/5 * * * *',
+      payload: { type: 'cleanup' },
+    });
+
+    expect(schedule.id).toBeDefined();
+    expect(schedule.cron).toBe('*/5 * * * *');
+    expect(schedule.nextRun).toBeGreaterThan(Date.now());
+  });
+
+  it('tick enqueues tasks when schedules are due', () => {
+    const schedule = q.addSchedule({
+      cron: '*/5 * * * *',
+      payload: { type: 'job' },
+    });
+
+    // Advance to the next scheduled time
+    vi.setSystemTime(schedule.nextRun);
+    const created = q.tick(schedule.nextRun);
+
+    expect(created).toHaveLength(1);
+    expect(created[0].payload).toEqual({ type: 'job' });
+  });
+
+  it('tick does not enqueue if not yet due', () => {
+    q.addSchedule({
+      cron: '*/5 * * * *',
+      payload: 'job',
+    });
+
+    // Tick at current time (before nextRun)
+    const created = q.tick();
+    expect(created).toHaveLength(0);
+  });
+
+  it('removes a schedule to stop future occurrences', () => {
+    const schedule = q.addSchedule({
+      cron: '*/5 * * * *',
+      payload: 'job',
+    });
+
+    q.removeSchedule(schedule.id);
+    expect(q.getSchedules()).toHaveLength(0);
+
+    vi.setSystemTime(schedule.nextRun);
+    const created = q.tick(schedule.nextRun);
+    expect(created).toHaveLength(0);
+  });
+
+  it('lists active schedules', () => {
+    q.addSchedule({ cron: '*/5 * * * *', payload: 'a' });
+    q.addSchedule({ cron: '0 * * * *', payload: 'b' });
+
+    expect(q.getSchedules()).toHaveLength(2);
+  });
+
+  it('enqueued tasks are regular tasks subject to queue rules', () => {
+    const schedule = q.addSchedule({
+      cron: '*/5 * * * *',
+      payload: 'job',
+      queueName: 'myq',
+      taskOptions: { priority: 2 },
+    });
+
+    vi.setSystemTime(schedule.nextRun);
+    const [task] = q.tick(schedule.nextRun);
+
+    expect(task.queueName).toBe('myq');
+    expect(task.priority).toBe(2);
+    expect(task.status).toBe('pending');
+  });
+
+  it('rejects invalid cron expressions', () => {
+    expect(() => q.addSchedule({ cron: 'invalid', payload: 'x' })).toThrow();
+    expect(() => q.addSchedule({ cron: '* * *', payload: 'x' })).toThrow();
+  });
+
+  it('supports hourly and daily cron patterns', () => {
+    const hourly = q.addSchedule({ cron: '0 * * * *', payload: 'hourly' });
+    const daily = q.addSchedule({ cron: '0 0 * * *', payload: 'daily' });
+
+    expect(hourly.nextRun).toBeGreaterThan(Date.now());
+    expect(daily.nextRun).toBeGreaterThan(Date.now());
+  });
+});
+
+describe('Phase 11: Middleware Pipeline', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('runs middleware in order before handler', async () => {
+    const order: string[] = [];
+
+    q.addMiddleware('default', async (_task, next) => {
+      order.push('mw1-before');
+      await next();
+      order.push('mw1-after');
+    });
+
+    q.addMiddleware('default', async (_task, next) => {
+      order.push('mw2-before');
+      await next();
+      order.push('mw2-after');
+    });
+
+    q.setHandler('default', async () => {
+      order.push('handler');
+    });
+
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+
+    expect(order).toEqual([
+      'mw1-before',
+      'mw2-before',
+      'handler',
+      'mw2-after',
+      'mw1-after',
+    ]);
+    expect(task.status).toBe('completed');
+  });
+
+  it('middleware can skip processing by not calling next', async () => {
+    const handlerCalled = vi.fn();
+
+    q.addMiddleware('default', async () => {
+      // Don't call next â†’ skip
+    });
+
+    q.setHandler('default', handlerCalled);
+
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+
+    expect(handlerCalled).not.toHaveBeenCalled();
+    expect(task.status).toBe('processing'); // not completed
+  });
+
+  it('middleware can modify the task', async () => {
+    q.addMiddleware('default', async (task, next) => {
+      task.metadata.enriched = true;
+      await next();
+    });
+
+    q.setHandler('default', async () => {});
+
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+
+    expect(task.metadata.enriched).toBe(true);
+  });
+
+  it('marks task as failed when middleware throws', async () => {
+    q.addMiddleware('default', async () => {
+      throw new Error('middleware error');
+    });
+
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+
+    expect(task.status).toBe('failed');
+    expect(task.lastError).toBe('middleware error');
+  });
+
+  it('marks task as failed when handler throws', async () => {
+    q.setHandler('default', async () => {
+      throw new Error('handler error');
+    });
+
+    q.addTask('data', { maxRetries: 0 });
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+
+    expect(task.status).toBe('failed');
+    expect(task.lastError).toBe('handler error');
+  });
+
+  it('auto-completes task after successful pipeline', async () => {
+    q.setHandler('default', async () => {
+      // success
+    });
+
+    q.addTask('data');
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+
+    expect(task.status).toBe('completed');
+    expect(task.progress.percentage).toBe(100);
+  });
+
+  it('each queue has independent middleware', async () => {
+    const q1calls: string[] = [];
+    const q2calls: string[] = [];
+
+    q.addMiddleware('q1', async (_task, next) => {
+      q1calls.push('q1-mw');
+      await next();
+    });
+    q.addMiddleware('q2', async (_task, next) => {
+      q2calls.push('q2-mw');
+      await next();
+    });
+    q.setHandler('q1', async () => { q1calls.push('q1-handler'); });
+    q.setHandler('q2', async () => { q2calls.push('q2-handler'); });
+
+    q.addTask('a', { queueName: 'q1' });
+    q.addTask('b', { queueName: 'q2' });
+
+    const t1 = q.getNextTask('q1')!;
+    const t2 = q.getNextTask('q2')!;
+
+    await q.processTask(t1.id);
+    await q.processTask(t2.id);
+
+    expect(q1calls).toEqual(['q1-mw', 'q1-handler']);
+    expect(q2calls).toEqual(['q2-mw', 'q2-handler']);
+  });
+});
+
+describe('Phase 12: Graceful Shutdown', () => {
+  let q: TaskQueueSystem;
+  beforeEach(() => { q = new TaskQueueSystem(); });
+
+  it('prevents adding new tasks after shutdown', async () => {
+    await q.shutdown();
+    expect(() => q.addTask('data')).toThrow(/shutting down/i);
+  });
+
+  it('completes immediately when no tasks are processing', async () => {
+    const result = await q.shutdown();
+    expect(result.completed).toBe(0);
+    expect(result.forceCancelled).toBe(0);
+    expect(result.elapsed).toBeGreaterThanOrEqual(0);
+  });
+
+  it('waits for processing tasks to complete', async () => {
+    q.addTask('data');
+    const task = q.getNextTask()!;
+
+    const shutdownPromise = q.shutdown({ timeout: 5000 });
+
+    // Complete the task while shutdown is waiting
+    q.completeTask(task.id);
+
+    const result = await shutdownPromise;
+    expect(result.completed).toBe(1);
+    expect(result.forceCancelled).toBe(0);
+  });
+
+  it('force-cancels tasks that exceed timeout', async () => {
+    q.addTask('slow-task');
+    q.getNextTask(); // move to processing, don't complete
+
+    const result = await q.shutdown({ timeout: 100 });
+    expect(result.forceCancelled).toBe(1);
+  });
+
+  it('runs shutdown callbacks', async () => {
+    const called = vi.fn();
+    q.onShutdown(called);
+
+    await q.shutdown();
+    expect(called).toHaveBeenCalledOnce();
+  });
+
+  it('returns the same result on multiple shutdown calls', async () => {
+    const r1 = q.shutdown();
+    const r2 = q.shutdown();
+
+    const result1 = await r1;
+    const result2 = await r2;
+    expect(result1).toBe(result2);
+  });
+
+  it('shutdown result includes elapsed time', async () => {
+    const result = await q.shutdown();
+    expect(typeof result.elapsed).toBe('number');
+  });
+
+  it('reports isShuttingDown', async () => {
+    expect(q.isShuttingDown).toBe(false);
+    const p = q.shutdown();
+    expect(q.isShuttingDown).toBe(true);
+    await p;
+  });
+});
+
+describe('Cross-phase integration', () => {
+  let q: TaskQueueSystem;
+
+  beforeEach(() => {
+    vi.useFakeTimers();
+    q = new TaskQueueSystem();
+  });
+
+  afterEach(() => {
+    vi.useRealTimers();
+  });
+
+  it('priority + delay: priority wins among available tasks', () => {
+    q.addTask('low-immediate', { priority: 10 });
+    q.addTask('high-delayed', { priority: 1, delay: 100 });
+
+    // Before delay: only low-immediate is available
+    expect(q.getNextTask()!.payload).toBe('low-immediate');
+
+    vi.advanceTimersByTime(100);
+    expect(q.getNextTask()!.payload).toBe('high-delayed');
+  });
+
+  it('dependencies + priority: respects both', () => {
+    const dep = q.addTask('dep', { priority: 5 });
+    q.addTask('blocked-high', { priority: 1, dependencies: [dep.id] });
+    q.addTask('free-low', { priority: 10 });
+
+    // dep has higher priority than free-low
+    const first = q.getNextTask()!;
+    expect(first.payload).toBe('dep');
+
+    // blocked-high can't run yet, so free-low is next
+    const second = q.getNextTask()!;
+    expect(second.payload).toBe('free-low');
+
+    q.completeTask(first.id);
+    const third = q.getNextTask()!;
+    expect(third.payload).toBe('blocked-high');
+  });
+
+  it('concurrency + priority: highest priority within limit', () => {
+    q.setConcurrency('default', 1);
+    q.addTask('low', { priority: 10 });
+    q.addTask('high', { priority: 1 });
+
+    const first = q.getNextTask()!;
+    expect(first.payload).toBe('high');
+    expect(q.getNextTask()).toBeNull(); // concurrency limit
+
+    q.completeTask(first.id);
+    expect(q.getNextTask()!.payload).toBe('low');
+  });
+
+  it('retry + middleware: failed middleware triggers retry', async () => {
+    let callCount = 0;
+
+    q.addMiddleware('default', async (_task, next) => {
+      callCount++;
+      if (callCount === 1) throw new Error('transient');
+      await next();
+    });
+    q.setHandler('default', async () => {});
+
+    q.addTask('data', { maxRetries: 3, backoffDelay: 100 });
+
+    // First attempt: middleware throws â†’ task retried
+    const task = q.getNextTask()!;
+    await q.processTask(task.id);
+    expect(task.status).toBe('pending');
+
+    // Advance past backoff
+    vi.advanceTimersByTime(100);
+
+    // Second attempt: middleware succeeds
+    const retry = q.getNextTask()!;
+    await q.processTask(retry.id);
+    expect(retry.status).toBe('completed');
+    expect(callCount).toBe(2);
+  });
+
+  it('cancel prevents retry even with retries remaining', () => {
+    q.addTask('data', { maxRetries: 5 });
+    const task = q.getNextTask()!;
+    q.cancelTask(task.id);
+
+    expect(task.status).toBe('cancelled');
+    expect(q.getNextTask()).toBeNull();
+  });
+});
